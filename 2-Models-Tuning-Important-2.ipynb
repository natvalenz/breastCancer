{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Diagnostic\n",
    "## The goal of this project is to build a model able to predict the diagnosis of breast cancer tissues as malignant or benign. \n",
    "\n",
    "- Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. \n",
    "\n",
    "- Class distribution: 357 benign, 212 malignant. More info about this dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (roc_auc_score, confusion_matrix, recall_score, precision_score, RocCurveDisplay, \n",
    "                             accuracy_score, plot_confusion_matrix, auc, classification_report)\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "X= pd.read_csv(\"X.csv\")\n",
    "y=pd.read_csv(\"y.csv\")\n",
    "y=y.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Important Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random=42\n",
    "impX=['radius_worst',\n",
    "'concave points_worst',\n",
    "'texture_worst',\n",
    "'texture_mean',\n",
    "'smoothness_worst',\n",
    "'compactness_worst',\n",
    "'area_worst',\n",
    "'area_se',\n",
    "'concavity_mean',\n",
    "'smoothness_mean',\n",
    "'concave points_mean',\n",
    "'compactness_se',\n",
    "'compactness_mean',\n",
    "'concavity_se',\n",
    "'symmetry_worst',\n",
    "'concavity_worst',\n",
    "'symmetry_mean'\n",
    "]\n",
    "\n",
    "Ximp=X[impX].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Ximp, y, test_size=0.30, random_state=random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.957286432160804\n",
      "Test Accuracy:  0.9707602339181286\n",
      "Training ROC_AUC:  0.9510390555510634\n",
      "Test ROC_AUC:  0.966931216931217\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(random_state=random, max_iter=5000)\n",
    "lr= lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "print(\"Training Accuracy: \", lr.score(X_train, y_train))\n",
    "print(\"Test Accuracy: \", lr.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000, max_iter=5000, random_state=42, solver='newton-cg')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9954910052910052"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models and parameters\n",
    "# define grid search\n",
    "param_grid={'solver': ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "            'penalty':['l2'],\n",
    "            'C':[100, 10, 1.0, 0.1, 0.01, 1000],\n",
    "           'max_iter': [5000]}\n",
    "\n",
    "#why? keep the balance in the splits\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(lr, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.275688</td>\n",
       "      <td>0.027673</td>\n",
       "      <td>0.005616</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995491</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.461630</td>\n",
       "      <td>0.174784</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995135</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.254861</td>\n",
       "      <td>0.082912</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>100</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100, 'max_iter': 5000, 'penalty': 'l2', ...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992995</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.467136</td>\n",
       "      <td>0.328002</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>100</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100, 'max_iter': 5000, 'penalty': 'l2', ...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992899</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.011834</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991758</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.515443</td>\n",
       "      <td>0.179684</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>10</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'max_iter': 5000, 'penalty': 'l2', '...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991656</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.202230</td>\n",
       "      <td>0.036876</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>10</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10, 'max_iter': 5000, 'penalty': 'l2', '...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991567</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011967</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>100</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'max_iter': 5000, 'penalty': 'l2', ...</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991025</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009760</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>10</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'max_iter': 5000, 'penalty': 'l2', '...</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.990325</td>\n",
       "      <td>0.011127</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.217584</td>\n",
       "      <td>0.067845</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1.0, 'max_iter': 5000, 'penalty': 'l2', ...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.989657</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "15       0.275688      0.027673         0.005616        0.000568    1000   \n",
       "16       0.461630      0.174784         0.006600        0.002776    1000   \n",
       "0        0.254861      0.082912         0.007234        0.002500     100   \n",
       "1        0.467136      0.328002         0.006600        0.001943     100   \n",
       "17       0.011834      0.001753         0.005534        0.000670    1000   \n",
       "4        0.515443      0.179684         0.006700        0.002854      10   \n",
       "3        0.202230      0.036876         0.005434        0.000990      10   \n",
       "2        0.011967      0.001683         0.006591        0.002626     100   \n",
       "5        0.009760      0.000843         0.005377        0.000741      10   \n",
       "6        0.217584      0.067845         0.007918        0.003191       1   \n",
       "\n",
       "   param_max_iter param_penalty param_solver  \\\n",
       "15           5000            l2    newton-cg   \n",
       "16           5000            l2        lbfgs   \n",
       "0            5000            l2    newton-cg   \n",
       "1            5000            l2        lbfgs   \n",
       "17           5000            l2    liblinear   \n",
       "4            5000            l2        lbfgs   \n",
       "3            5000            l2    newton-cg   \n",
       "2            5000            l2    liblinear   \n",
       "5            5000            l2    liblinear   \n",
       "6            5000            l2    newton-cg   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "15  {'C': 1000, 'max_iter': 5000, 'penalty': 'l2',...           1.000000  ...   \n",
       "16  {'C': 1000, 'max_iter': 5000, 'penalty': 'l2',...           1.000000  ...   \n",
       "0   {'C': 100, 'max_iter': 5000, 'penalty': 'l2', ...           0.994667  ...   \n",
       "1   {'C': 100, 'max_iter': 5000, 'penalty': 'l2', ...           0.994667  ...   \n",
       "17  {'C': 1000, 'max_iter': 5000, 'penalty': 'l2',...           0.984000  ...   \n",
       "4   {'C': 10, 'max_iter': 5000, 'penalty': 'l2', '...           0.989333  ...   \n",
       "3   {'C': 10, 'max_iter': 5000, 'penalty': 'l2', '...           0.989333  ...   \n",
       "2   {'C': 100, 'max_iter': 5000, 'penalty': 'l2', ...           0.984000  ...   \n",
       "5   {'C': 10, 'max_iter': 5000, 'penalty': 'l2', '...           0.970667  ...   \n",
       "6   {'C': 1.0, 'max_iter': 5000, 'penalty': 'l2', ...           0.978667  ...   \n",
       "\n",
       "    split23_test_score  split24_test_score  split25_test_score  \\\n",
       "15            0.986667            1.000000            0.997333   \n",
       "16            0.986667            0.997333            0.994667   \n",
       "0             0.978667            0.994667            0.992000   \n",
       "1             0.978667            0.997333            0.992000   \n",
       "17            0.981333            1.000000            0.994667   \n",
       "4             0.973333            0.992000            0.994667   \n",
       "3             0.973333            0.992000            0.994667   \n",
       "2             0.973333            1.000000            0.994667   \n",
       "5             0.973333            0.994667            0.989333   \n",
       "6             0.976000            0.992000            0.997333   \n",
       "\n",
       "    split26_test_score  split27_test_score  split28_test_score  \\\n",
       "15            1.000000                 1.0            0.974286   \n",
       "16            0.992000                 1.0            0.974286   \n",
       "0             0.992000                 1.0            0.974286   \n",
       "1             0.992000                 1.0            0.971429   \n",
       "17            0.984000                 1.0            0.974286   \n",
       "4             0.992000                 1.0            0.968571   \n",
       "3             0.992000                 1.0            0.968571   \n",
       "2             0.989333                 1.0            0.968571   \n",
       "5             0.984000                 1.0            0.971429   \n",
       "6             0.997333                 1.0            0.957143   \n",
       "\n",
       "    split29_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15            1.000000         0.995491        0.007645                1  \n",
       "16            1.000000         0.995135        0.007519                2  \n",
       "0             1.000000         0.992995        0.008493                3  \n",
       "1             1.000000         0.992899        0.008634                4  \n",
       "17            1.000000         0.991758        0.010439                5  \n",
       "4             1.000000         0.991656        0.010300                6  \n",
       "3             1.000000         0.991567        0.010308                7  \n",
       "2             1.000000         0.991025        0.011046                8  \n",
       "5             0.997222         0.990325        0.011127                9  \n",
       "6             0.994444         0.989657        0.011893               10  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874371859296482\n",
      "0.9766081871345029\n",
      "Training ROC_AUC:  0.9845691490795396\n",
      "Test ROC_AUC:  0.974867724867725\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(C=1000, max_iter=5000, random_state=42, solver='newton-cg')\n",
    "lr= lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "print(lr.score(X_train, y_train))\n",
    "print(lr.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 97.66\n",
      "precision : 96.83\n",
      "recall : 96.83\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Accuracy :', round(accuracy_score(y_test,y_test_pred)*100,2))\n",
    "print('precision :', round(precision_score(y_test,y_test_pred)*100,2))\n",
    "print('recall :', round(recall_score(y_test,y_test_pred)*100,2))\n",
    "plot_confusion_matrix(lr, X_test, y_test, cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'False Positive Rate')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_test_pred)\n",
    "auc_sc = auc(fpr, tpr)\n",
    "# Draw ROC curve:\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, label=\"AUC = %0.2f\"%auc_sc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Receiver Operating Characteristic(ROC) for Support Vector Machine\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100, max_iter=5000, penalty='l1', random_state=42,\n",
      "                   solver='liblinear')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9931000000000002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models and parameters\n",
    "# define grid search\n",
    "param_grid={'solver': ['liblinear'], \n",
    "            'penalty':['l1'],\n",
    "            'C':[100, 10, 1.0, 0.1, 0.01, 1000],\n",
    "           'max_iter': [5000]}\n",
    "\n",
    "#why? keep the balance in the splits\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(lr, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107648</td>\n",
       "      <td>0.114180</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>100</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'max_iter': 5000, 'penalty': 'l1', ...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993100</td>\n",
       "      <td>0.009812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.079659</td>\n",
       "      <td>0.050617</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>10</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'max_iter': 5000, 'penalty': 'l1', '...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991834</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.039731</td>\n",
       "      <td>0.018786</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000, 'max_iter': 5000, 'penalty': 'l1',...</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.917333</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988836</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048938</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.0, 'max_iter': 5000, 'penalty': 'l1', ...</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.986887</td>\n",
       "      <td>0.016355</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 5000, 'penalty': 'l1', ...</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888571</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.973270</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013131</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 5000, 'penalty': 'l1',...</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.980556</td>\n",
       "      <td>0.946587</td>\n",
       "      <td>0.041572</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.107648      0.114180         0.007351        0.002005     100   \n",
       "1       0.079659      0.050617         0.006867        0.001648      10   \n",
       "5       0.039731      0.018786         0.005800        0.000792    1000   \n",
       "2       0.048938      0.010064         0.006066        0.001237       1   \n",
       "3       0.021367      0.004300         0.006902        0.002724     0.1   \n",
       "4       0.013131      0.002505         0.006208        0.000915    0.01   \n",
       "\n",
       "  param_max_iter param_penalty param_solver  \\\n",
       "0           5000            l1    liblinear   \n",
       "1           5000            l1    liblinear   \n",
       "5           5000            l1    liblinear   \n",
       "2           5000            l1    liblinear   \n",
       "3           5000            l1    liblinear   \n",
       "4           5000            l1    liblinear   \n",
       "\n",
       "                                              params  split0_test_score  ...  \\\n",
       "0  {'C': 100, 'max_iter': 5000, 'penalty': 'l1', ...           0.986667  ...   \n",
       "1  {'C': 10, 'max_iter': 5000, 'penalty': 'l1', '...           0.992000  ...   \n",
       "5  {'C': 1000, 'max_iter': 5000, 'penalty': 'l1',...           0.936000  ...   \n",
       "2  {'C': 1.0, 'max_iter': 5000, 'penalty': 'l1', ...           0.944000  ...   \n",
       "3  {'C': 0.1, 'max_iter': 5000, 'penalty': 'l1', ...           0.901333  ...   \n",
       "4  {'C': 0.01, 'max_iter': 5000, 'penalty': 'l1',...           0.872000  ...   \n",
       "\n",
       "   split23_test_score  split24_test_score  split25_test_score  \\\n",
       "0            0.989333            0.960000            0.986667   \n",
       "1            0.978667            0.997333            0.997333   \n",
       "5            0.992000            0.917333            0.984000   \n",
       "2            0.973333            0.994667            0.989333   \n",
       "3            0.960000            0.981333            0.984000   \n",
       "4            0.954667            0.928000            0.946667   \n",
       "\n",
       "   split26_test_score  split27_test_score  split28_test_score  \\\n",
       "0            1.000000            1.000000            0.980000   \n",
       "1            0.989333            1.000000            0.968571   \n",
       "5            0.997333            1.000000            0.982857   \n",
       "2            0.976000            1.000000            0.954286   \n",
       "3            0.973333            1.000000            0.888571   \n",
       "4            0.968000            0.989333            0.814286   \n",
       "\n",
       "   split29_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            1.000000         0.993100        0.009812                1  \n",
       "1            1.000000         0.991834        0.009663                2  \n",
       "5            1.000000         0.988836        0.020482                3  \n",
       "2            0.994444         0.986887        0.016355                4  \n",
       "3            0.988889         0.973270        0.029094                5  \n",
       "4            0.980556         0.946587        0.041572                6  \n",
       "\n",
       "[6 rows x 42 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.9849246231155779\n",
      "Test Score:  0.9707602339181286\n",
      "Training ROC_AUC:  0.9825611169510257\n",
      "Test ROC_AUC:  0.966931216931217\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(penalty='l1', C=100, solver='liblinear', random_state=random)\n",
    "lr= lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "print(\"Training Score: \",lr.score(X_train, y_train))\n",
    "print(\"Test Score: \", lr.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 97.08\n",
      "precision : 96.77\n",
      "recall : 95.24\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Accuracy :', round(accuracy_score(y_test,y_test_pred)*100,2))\n",
    "print('precision :', round(precision_score(y_test,y_test_pred)*100,2))\n",
    "print('recall :', round(recall_score(y_test,y_test_pred)*100,2))\n",
    "plot_confusion_matrix(lr, X_test, y_test, cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>area_se</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>resid</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>13.01</td>\n",
       "      <td>0.08278</td>\n",
       "      <td>29.15</td>\n",
       "      <td>21.26</td>\n",
       "      <td>0.16990</td>\n",
       "      <td>0.21960</td>\n",
       "      <td>518.1</td>\n",
       "      <td>16.41</td>\n",
       "      <td>0.05133</td>\n",
       "      <td>0.08759</td>\n",
       "      <td>0.01899</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.06575</td>\n",
       "      <td>0.02443</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>0.31200</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.053291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>14.55</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>29.16</td>\n",
       "      <td>22.54</td>\n",
       "      <td>0.13490</td>\n",
       "      <td>0.44020</td>\n",
       "      <td>639.3</td>\n",
       "      <td>15.09</td>\n",
       "      <td>0.08705</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.05102</td>\n",
       "      <td>0.03041</td>\n",
       "      <td>0.14830</td>\n",
       "      <td>0.02526</td>\n",
       "      <td>0.4128</td>\n",
       "      <td>0.31620</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>15.85</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>19.85</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.13160</td>\n",
       "      <td>0.27350</td>\n",
       "      <td>766.9</td>\n",
       "      <td>21.20</td>\n",
       "      <td>0.08487</td>\n",
       "      <td>0.09970</td>\n",
       "      <td>0.05532</td>\n",
       "      <td>0.02297</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.03114</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.31030</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.089082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>15.53</td>\n",
       "      <td>0.17080</td>\n",
       "      <td>23.19</td>\n",
       "      <td>15.86</td>\n",
       "      <td>0.15360</td>\n",
       "      <td>0.47910</td>\n",
       "      <td>614.9</td>\n",
       "      <td>12.96</td>\n",
       "      <td>0.11690</td>\n",
       "      <td>0.10780</td>\n",
       "      <td>0.06987</td>\n",
       "      <td>0.03575</td>\n",
       "      <td>0.15350</td>\n",
       "      <td>0.03980</td>\n",
       "      <td>0.3527</td>\n",
       "      <td>0.48580</td>\n",
       "      <td>0.1942</td>\n",
       "      <td>0.135887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>15.77</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>22.13</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.09983</td>\n",
       "      <td>0.24720</td>\n",
       "      <td>767.3</td>\n",
       "      <td>77.11</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08757</td>\n",
       "      <td>0.06602</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.16760</td>\n",
       "      <td>0.09960</td>\n",
       "      <td>0.2272</td>\n",
       "      <td>0.22200</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.192154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>16.34</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>18.24</td>\n",
       "      <td>15.24</td>\n",
       "      <td>0.12770</td>\n",
       "      <td>0.30890</td>\n",
       "      <td>803.6</td>\n",
       "      <td>42.76</td>\n",
       "      <td>0.09966</td>\n",
       "      <td>0.11320</td>\n",
       "      <td>0.07064</td>\n",
       "      <td>0.04412</td>\n",
       "      <td>0.13390</td>\n",
       "      <td>0.04436</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.26040</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.206410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>14.20</td>\n",
       "      <td>0.11800</td>\n",
       "      <td>31.31</td>\n",
       "      <td>23.97</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.34540</td>\n",
       "      <td>624.0</td>\n",
       "      <td>18.51</td>\n",
       "      <td>0.05438</td>\n",
       "      <td>0.07903</td>\n",
       "      <td>0.02036</td>\n",
       "      <td>0.02294</td>\n",
       "      <td>0.07529</td>\n",
       "      <td>0.03016</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>0.39110</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.246446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>14.80</td>\n",
       "      <td>0.14530</td>\n",
       "      <td>27.20</td>\n",
       "      <td>18.89</td>\n",
       "      <td>0.14280</td>\n",
       "      <td>0.25700</td>\n",
       "      <td>675.2</td>\n",
       "      <td>19.29</td>\n",
       "      <td>0.08580</td>\n",
       "      <td>0.10590</td>\n",
       "      <td>0.05381</td>\n",
       "      <td>0.01957</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.03304</td>\n",
       "      <td>0.2666</td>\n",
       "      <td>0.34380</td>\n",
       "      <td>0.1806</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>16.51</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>32.29</td>\n",
       "      <td>25.42</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.13760</td>\n",
       "      <td>826.4</td>\n",
       "      <td>27.41</td>\n",
       "      <td>0.04105</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.03027</td>\n",
       "      <td>0.01172</td>\n",
       "      <td>0.07214</td>\n",
       "      <td>0.01947</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.16110</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.270530</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>12.40</td>\n",
       "      <td>0.08946</td>\n",
       "      <td>18.99</td>\n",
       "      <td>17.36</td>\n",
       "      <td>0.13590</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>472.4</td>\n",
       "      <td>48.84</td>\n",
       "      <td>0.05929</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.07404</td>\n",
       "      <td>0.01489</td>\n",
       "      <td>0.07210</td>\n",
       "      <td>0.01267</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.07153</td>\n",
       "      <td>0.2015</td>\n",
       "      <td>0.309022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>16.39</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>22.07</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>0.32620</td>\n",
       "      <td>826.0</td>\n",
       "      <td>35.74</td>\n",
       "      <td>0.09789</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.05246</td>\n",
       "      <td>0.02679</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.03119</td>\n",
       "      <td>0.3068</td>\n",
       "      <td>0.32090</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>-0.633185</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>17.80</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>28.03</td>\n",
       "      <td>22.41</td>\n",
       "      <td>0.13010</td>\n",
       "      <td>0.32990</td>\n",
       "      <td>973.1</td>\n",
       "      <td>19.53</td>\n",
       "      <td>0.05375</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.03263</td>\n",
       "      <td>0.01395</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.01774</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>-0.646597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>15.75</td>\n",
       "      <td>0.08219</td>\n",
       "      <td>40.54</td>\n",
       "      <td>27.85</td>\n",
       "      <td>0.10810</td>\n",
       "      <td>0.24260</td>\n",
       "      <td>764.0</td>\n",
       "      <td>29.96</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.08223</td>\n",
       "      <td>0.04408</td>\n",
       "      <td>0.02845</td>\n",
       "      <td>0.10390</td>\n",
       "      <td>0.03850</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.659567</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10.31</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>22.65</td>\n",
       "      <td>17.33</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.43650</td>\n",
       "      <td>324.7</td>\n",
       "      <td>17.67</td>\n",
       "      <td>0.31300</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.08606</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.30380</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>1.25200</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.996764</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>16.57</td>\n",
       "      <td>0.13830</td>\n",
       "      <td>20.86</td>\n",
       "      <td>15.79</td>\n",
       "      <td>0.14110</td>\n",
       "      <td>0.35420</td>\n",
       "      <td>812.4</td>\n",
       "      <td>23.35</td>\n",
       "      <td>0.07789</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.05069</td>\n",
       "      <td>0.02065</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>0.01759</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.27790</td>\n",
       "      <td>0.1662</td>\n",
       "      <td>-0.997239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_worst  concave points_worst  texture_worst  texture_mean  \\\n",
       "109         13.01               0.08278          29.15         21.26   \n",
       "208         14.55               0.11260          29.16         22.54   \n",
       "148         15.85               0.15990          19.85         15.18   \n",
       "81          15.53               0.17080          23.19         15.86   \n",
       "290         15.77               0.10210          22.13         19.73   \n",
       "89          16.34               0.13970          18.24         15.24   \n",
       "228         14.20               0.11800          31.31         23.97   \n",
       "396         14.80               0.14530          27.20         18.89   \n",
       "542         16.51               0.10950          32.29         25.42   \n",
       "275         12.40               0.08946          18.99         17.36   \n",
       "255         16.39               0.13740          22.07         17.05   \n",
       "184         17.80               0.12260          28.03         22.41   \n",
       "238         15.75               0.08219          40.54         27.85   \n",
       "68          10.31               0.17500          22.65         17.33   \n",
       "73          16.57               0.13830          20.86         15.79   \n",
       "\n",
       "     smoothness_worst  compactness_worst  area_worst  area_se  concavity_mean  \\\n",
       "109           0.16990            0.21960       518.1    16.41         0.05133   \n",
       "208           0.13490            0.44020       639.3    15.09         0.08705   \n",
       "148           0.13160            0.27350       766.9    21.20         0.08487   \n",
       "81            0.15360            0.47910       614.9    12.96         0.11690   \n",
       "290           0.09983            0.24720       767.3    77.11         0.13620   \n",
       "89            0.12770            0.30890       803.6    42.76         0.09966   \n",
       "228           0.12270            0.34540       624.0    18.51         0.05438   \n",
       "396           0.14280            0.25700       675.2    19.29         0.08580   \n",
       "542           0.10600            0.13760       826.4    27.41         0.04105   \n",
       "275           0.13590            0.08368       472.4    48.84         0.05929   \n",
       "255           0.15120            0.32620       826.0    35.74         0.09789   \n",
       "184           0.13010            0.32990       973.1    19.53         0.05375   \n",
       "238           0.10810            0.24260       764.0    29.96         0.11030   \n",
       "68            0.14820            0.43650       324.7    17.67         0.31300   \n",
       "73            0.14110            0.35420       812.4    23.35         0.07789   \n",
       "\n",
       "     smoothness_mean  concave points_mean  compactness_se  compactness_mean  \\\n",
       "109          0.08759              0.01899         0.01557           0.06575   \n",
       "208          0.10020              0.05102         0.03041           0.14830   \n",
       "148          0.09970              0.05532         0.02297           0.10210   \n",
       "81           0.10780              0.06987         0.03575           0.15350   \n",
       "290          0.08757              0.06602         0.10640           0.16760   \n",
       "89           0.11320              0.07064         0.04412           0.13390   \n",
       "228          0.07903              0.02036         0.02294           0.07529   \n",
       "396          0.10590              0.05381         0.01957           0.11470   \n",
       "542          0.08275              0.03027         0.01172           0.07214   \n",
       "275          0.12250              0.07404         0.01489           0.07210   \n",
       "255          0.10960              0.05246         0.02679           0.12790   \n",
       "184          0.09057              0.03263         0.01395           0.10520   \n",
       "238          0.08223              0.04408         0.02845           0.10390   \n",
       "68           0.10660              0.04375         0.08606           0.14130   \n",
       "73           0.10070              0.05069         0.02065           0.12800   \n",
       "\n",
       "     concavity_se  symmetry_worst  concavity_worst  symmetry_mean     resid  \\\n",
       "109       0.02443          0.2829          0.31200         0.1487  0.053291   \n",
       "208       0.02526          0.4128          0.31620         0.1850  0.065718   \n",
       "148       0.03114          0.2691          0.31030         0.1724  0.089082   \n",
       "81        0.03980          0.3527          0.48580         0.1942  0.135887   \n",
       "290       0.09960          0.2272          0.22200         0.1714  0.192154   \n",
       "89        0.04436          0.3151          0.26040         0.2116  0.206410   \n",
       "228       0.03016          0.2826          0.39110         0.1514  0.246446   \n",
       "396       0.03304          0.2666          0.34380         0.1806  0.248300   \n",
       "542       0.01947          0.2722          0.16110         0.1840  0.270530   \n",
       "275       0.01267          0.2220          0.07153         0.2015  0.309022   \n",
       "255       0.03119          0.3068          0.32090         0.1908 -0.633185   \n",
       "184       0.01774          0.3175          0.36300         0.1727 -0.646597   \n",
       "238       0.03850          0.1890          0.30640         0.1342  0.659567   \n",
       "68        0.30380          0.4228          1.25200         0.2111  0.996764   \n",
       "73        0.01759          0.2589          0.27790         0.1662 -0.997239   \n",
       "\n",
       "     y_true  y_pred  \n",
       "109       0       0  \n",
       "208       0       0  \n",
       "148       0       0  \n",
       "81        0       0  \n",
       "290       0       0  \n",
       "89        0       0  \n",
       "228       0       0  \n",
       "396       0       0  \n",
       "542       0       0  \n",
       "275       0       0  \n",
       "255       1       0  \n",
       "184       1       0  \n",
       "238       0       1  \n",
       "68        0       1  \n",
       "73        1       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last 5 are what was predicted incorrectly\n",
    "residuals = lr.predict_proba(X_test)[:,1] - y_test\n",
    "sortIdx=np.argsort(np.abs(residuals))\n",
    "residDF=X_test.iloc[sortIdx].copy()\n",
    "residDF[\"resid\"]=residuals[sortIdx]\n",
    "residDF['y_true']=y_test[sortIdx]\n",
    "residDF['y_pred']=y_test_pred[sortIdx]\n",
    "# print(residDF.std())\n",
    "outliers=residDF.tail(15)\n",
    "outliers\n",
    "# outliers.std()\n",
    "#sns.regplot(x = residuals, y = y_test_pred, scatter = True, color = 'red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>area_se</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>resid</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_true</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.188380</td>\n",
       "      <td>0.073641</td>\n",
       "      <td>23.808611</td>\n",
       "      <td>18.094167</td>\n",
       "      <td>0.125902</td>\n",
       "      <td>0.183516</td>\n",
       "      <td>541.462963</td>\n",
       "      <td>20.851676</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.093203</td>\n",
       "      <td>0.025749</td>\n",
       "      <td>0.021112</td>\n",
       "      <td>0.079677</td>\n",
       "      <td>0.024923</td>\n",
       "      <td>0.276775</td>\n",
       "      <td>0.166156</td>\n",
       "      <td>0.176876</td>\n",
       "      <td>0.034390</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.436032</td>\n",
       "      <td>0.189681</td>\n",
       "      <td>29.965079</td>\n",
       "      <td>22.163333</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0.408268</td>\n",
       "      <td>1453.939683</td>\n",
       "      <td>72.096508</td>\n",
       "      <td>0.168397</td>\n",
       "      <td>0.104290</td>\n",
       "      <td>0.091669</td>\n",
       "      <td>0.033734</td>\n",
       "      <td>0.153177</td>\n",
       "      <td>0.041532</td>\n",
       "      <td>0.324095</td>\n",
       "      <td>0.477278</td>\n",
       "      <td>0.193902</td>\n",
       "      <td>-0.037147</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        radius_worst  concave points_worst  texture_worst  texture_mean  \\\n",
       "y_true                                                                    \n",
       "0          13.188380              0.073641      23.808611     18.094167   \n",
       "1          21.436032              0.189681      29.965079     22.163333   \n",
       "\n",
       "        smoothness_worst  compactness_worst   area_worst    area_se  \\\n",
       "y_true                                                                \n",
       "0               0.125902           0.183516   541.462963  20.851676   \n",
       "1               0.147222           0.408268  1453.939683  72.096508   \n",
       "\n",
       "        concavity_mean  smoothness_mean  concave points_mean  compactness_se  \\\n",
       "y_true                                                                         \n",
       "0             0.045052         0.093203             0.025749        0.021112   \n",
       "1             0.168397         0.104290             0.091669        0.033734   \n",
       "\n",
       "        compactness_mean  concavity_se  symmetry_worst  concavity_worst  \\\n",
       "y_true                                                                    \n",
       "0               0.079677      0.024923        0.276775         0.166156   \n",
       "1               0.153177      0.041532        0.324095         0.477278   \n",
       "\n",
       "        symmetry_mean     resid    y_pred  \n",
       "y_true                                     \n",
       "0            0.176876  0.034390  0.018519  \n",
       "1            0.193902 -0.037147  0.952381  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residDF.groupby('y_true').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqcElEQVR4nO2deZAc9ZXnv6+rL3Wr75ZaotEFITACS4AbhLC5BDKSGFncp+fwzgTBhpnwTMQS9oQjZn3Exs7sxOzaE9jDsizh8WIQiFMCyQLMbXGoxSEkECDEJSR09H13V9XbP16lK6tV3V3dXVV51PcTkVFVmVlVL6uyvvXy/d7vPVFVEEIICT5FXhtACCEkO1DQCSEkJFDQCSEkJFDQCSEkJFDQCSEkJBR79caNjY26cOFCr96eEEICyc6dO4+p6qx02zwT9IULF6K1tdWrtyeEkEAiIp+NtY0hF0IICQkUdEIICQkUdEIICQkUdEIICQkUdEIICQkTCrqI3CsiR0Rk9xjbRUT+TUT2icguETk7+2YSkmW2bgVWrgQWLQKWLbPboiJA5PiF+B/397lypT0OG4ljXAp8faxdMvHQfwNg9Tjb1wBYnFhuBfDvk7GRkLyzdStw++3AoUNAJALs3g18+ikwVuVRirq/cX+f9fV2e/vt4RJ11zHGgOhYu00o6Kr6EoD2cXZZD+C3arwGoFZE5k7eYkLyxL/8C1BaClRWAkeOeG0NmS7u71PEbktLbX1YcB/jOGQjht4M4AvX4wOJdcchIreKSKuItB49ejQLb03IFPjkE6Ciwu4PDY3tmZNg4P4+HSoq7KorLKQ7xjRkQ9DTXY+m/YWo6t2q2qKqLbNmpZ25SkjuWbQI6O+3+2VlDKkEHff36dDfD4SptEi6Y0xDNgT9AIB5rscnAjiYhdclJDfccQcwPAz09QGzZ3ttDZku7u9T1W6Hh219WHAf4zhkQ9A3AfiLRLbLeQC6VPVQFl6XkNywZg1w553A3LlAPA6ccYZ5c2N56gzJ+Bv399nRYbd33mnrw4LrGCPj1OCSiXqKisgDAC4G0AjgMID/CqAEAFT1LhERAHfCMmH6AXxPVSesutXS0qIszkUIIZNDRHaqaku6bRNWW1TVmybYrgC+P0XbCCGEZAnOFCWEkJBAQSeEkJBAQSeEkJBAQSeEkJBAQSeEkJBAQSeEkJBAQSeEkJBAQSeEkJBAQSeEkJBAQSeEkJBAQSeEkJBAQSeEkJAwYXEuQgghHhKNWnMLZxkHCjohhPgJVWBgwMS7r8/aJGYIBZ0QQrwmFjPx7u01IY/Hp/QyFHRCCPGC4WET8N5eYHAwKy/pnaCzrRchpNAYHEyK+PBw1l/eO0EfGQH27wdmzrRlxgx2XyeEhI/BQaCnx5ZoNKdv5W3IJRoFOjttiUSAykqgqgqoqKC4E0KCy9BQUsRHRvL2tv6JocdiQHe3LUVF5rVT3AkhQWFkxAS8uzsn4ZRM8I+gu4nHk+IeiZi4V1dbWIYQQvyCqol4V5elGnqMPwXdTSxmH1ZXF1BcbMJeXQ2UlnptGSGkUBkZsVBxd7dplE/wv6C7iUaB9nZbysqAmhoLy0QiXltGCCkEBgaAjg7LUvEhwRJ0N0NDwJEjwNGjyZBMZaXXVhFCwkhPjzmSk5i16QXBFXQHJ4bV02MhmZoaW4qDf2iEEA9xtKW93bNBzskSLtWLRoG2NlsqK4HaWnrthJDJoWqx8fb2vKYcZoNwCbqbvj5biotN2GtqGGsnhIxNgIXcIbyC7hCNAseOmddeVWXiXl7utVWEEL+gahkrHR05n8mZa8Iv6A7Ov293twl6XZ0JPCGkMInHTcQ7O32VejgdCkfQ3QwOAocOWYZMXZ2FY4rYvImQgiAWSwr5FMvU+pXCFHSHaNREva3NRL2ujtkxhISVWMzi452doa32mpFbKiKrReQDEdknIj9Ks71GRDaLyDsiskdEvpd9U3OIc+n1ySfAV18FJkWJEJIBsZg5bvv32+88pGIOZOChi0gEwK8ArAJwAMAOEdmkqu+5dvs+gPdUdZ2IzALwgYj8TlWDpYzuOPvMmUB9PQdQCQkqIQ6tjEUm8YVzAexT1f0AICIbAKwH4BZ0BVAlIgJgJoB2AMEeLnaK0FdUAA0NLAxGSFCIx03E29sLRsgdMhH0ZgBfuB4fALB81D53AtgE4CCAKgA3qOpxn6SI3ArgVgCY39w8FXvzj9Npe8YME/aKCq8tIoSkQ9WK+LW1hSZrZbJkEkNPV4x8dBDqcgBvAzgBwJkA7hSR6uOepHq3qraoasus+vpJmuoxAwPAgQPAF1/YhCVCiH/o6QE+/dTqOxWomAOZCfoBAPNcj0+EeeJuvgfgUTX2AfgEwNeyY6LPGBgAvvwS+Pxz31ZcI6RgGBiw3+KhQ4Gd3ZlNMhH0HQAWi8giESkFcCMsvOLmcwCXAoCINAE4FcD+bBrqOwYHgYMHzSvo7vbaGkIKi5ERE/EvvrDfIgGQQQxdVaMicjuAbQAiAO5V1T0iclti+10Afg7gNyLyLixE80NVPZZDu/3D8LClOra3W1ZMVRVb5hGSK+Jx+62FPP1wqmQ0i0ZVtwDYMmrdXa77BwF8O7umBQxH2NvabPC0+rghBELIdOjpsXzygNdbySWcFpltRkYo7IRkE6eZjQ96dvodCnqucIS9vd2EnYXACJkc8bg5RiGeqp9tKOi5ZnjYBm/a24HGRjbcICQT+vqAw4cZXpkkFPR8MTRk6Y4zZpiwc+YpIccTjVp4hSnBU4KCnm8GBizVqrLShL2szGuLCPEHnZ3WjKbAputnEwq6Vzgt8qqrTdhZtpcUKkNDFl5hPvm0oYp4TXe3pWM1NFg9duawk0KBg55Zh4LuB1TtUrO7G2hqYnydhJ+BAcsC43T9rMK+a35ieNji60eO0GMh4aW93QrdUcyzDj10P9LZaSV758xhgw0SHqJR88r7+722JLRQ0P3K8LBVkauvt/g6Y+skyHR1WVixgEvb5gMKut9pb09666WlXltDyOQYHrYMFk7bzwsU9CAwOGje+qxZQE2N19YQMjGqVhGxrY3jQdlAFXj/fWDz5nF3o6AHhXjcPJ2+PsuEiUS8toiQ9AwO2rk6NOS1JcHnwAHgySdNyPftm3B3CnrQ6O21H8zcuUxvJP5C1UKEbW1eWxJsurqAbduAJ54AWltTty1caE11xoCCHkSiUUtv5IAp8QtOByHO9pwaw8PAyy+biD/3XGpKZ2MjcMUVwLp1wBlnAF8bu7snBT3ItLebx870RuIl3d02d4I1WCaHKrB7t4n4k0/amIPDjBnAqlXAd74DrFiRcWkQCnrQcdIb6+rsn5zeOskXzrhOT4/XlgSLw4dNxB9/HPj44+R6EeD8803EV62aUqltCnpY6OiwAVN66yQfcOr+5BgcBJ59FnjsMWD79tSrmcWLgSuvtJBKU9O03oaCHiborZN80NFhk4SYjjg+qsDbb5uIP/VUao33ujrgz/4MuOoqYMmSrP1WKehhhN46yQWqFi7o7vbaEn/jhFQefRT45JPk+uJi4OKLTcQvvDAnEwUp6GHFKfRVV8dMGDJ9olHruMXc8vQMDwMvvAA88gjw0kupIZXTTgOuvto88vr6nJpBQQ8zTl5wX5/lrbN0AJkKTvtE9vc8no8+MhF/4gn7rTnU1trg5jXXjJtmmG0o6IXA0BDw2WcWV6+r89oaEiT6+iy/nCmJSXp7LSb+8MPArl3J9UVFwAUXmDe+cqUnDhQFvVBQBY4eTcbW2fKOTERHh50zxH4/b75pIr51a2qxsQULTMSvumraWSrThb/qQqO/37z12bOBqiqvrSF+JBazgT13Vkah0t5u+eIbNwL79yfXl5cDq1dbSOWcc3wzRkVBL0RiMbuM7uszYS9i4yqSoL/f8ssLOV4ejwOvvgo89BDwhz+k5tqffjpw3XU2wOlDh4iCXsh0d9ul49y5TG8k5o0eO+a1Fd5x5IilGm7caFUOHaqqbIDz2mstZ9zHUNALnZERm4zU0GALKTzicfPKCzHEEosBr7xi3vjzz6d2VGppMW989erAODwUdGK0tSU7I5WUeG0NyRdDQxZ+Gx722pL8cviwpRs+/LClZDrU1toA57XXAief7Jl5UyUjQReR1QB+CSAC4B5V/ac0+1wM4BcASgAcU9WLsmYlyQ8DA8kB0+pqr60huaaz07JYCmUKfzxu3viDDx7vjZ93HnDDDcBllwV6vsaEgi4iEQC/ArAKwAEAO0Rkk6q+59qnFsCvAaxW1c9FZHaO7CW5xrn8djojccA0fBRaFsvRo+aNP/RQqjdeV2fe+PXXW+OIEJCJh34ugH2quh8ARGQDgPUA3nPtczOAR1X1cwBQ1SPZNpTkmZ6eZGekgMQPSQYUShaLKvDaa8CGDVbl0H28y5cDN94YeG88HZkIejOAL1yPDwBYPmqfUwCUiMgLAKoA/FJVfzv6hUTkVgC3AsD85uap2EvyyciI1YPhDNPg40ws6+z02pLc0tFheeMbNqS2aquttYk/118PnHSSR8blnkwEPV3G/OigWzGAbwC4FMAMAK+KyGuq+mHKk1TvBnA3ALQsXVoggbuA4wjBwACbUweVsA98OmVqN2wAtmxJPc6zzzZvfPVqoKzMMxPzRSaCfgDAPNfjEwEcTLPPMVXtA9AnIi8BWAbgQ5BwwObUwcRp2hzGgc++PmDzZuCBB4C9e5PrKyutYcQNNwCnnuqZeV6QiaDvALBYRBYB+BLAjbCYuZsnANwpIsUASmEhmf+VTUOJD3CaUzc25rwMKJkmIyMWK3fXHAkLH31kIv744ybqDkuWADfdZA2Vp9C+LQxMKOiqGhWR2wFsg6Ut3quqe0TktsT2u1T1fRH5PYBdAOKw1MbduTSceMixY8mcdRb58h9hbNo8PGyDm/ffD+zYkVxfVgasXWtCvnSpb2qqeIWoR5diLUuXauvDD3vy3iRLRCIWgqmo8NoSApiAHzkSro5Chw5ZbPzhh1PLEixcaLHxq66yAc8CQk49daeqtqTbRveKTJ1YzGpeOF2RmLPuHWFq2uwUx7r/fuC555JXGkVFwKWXmje+YgXPtzRQ0Mn06eiwvPWmpoKNXXpKW5stQae724pjPfBAasphY6OlG15/vV0RkjGhoJPs4PScnDnTSgcwtp57RkYsJDE46LUl0+P9980b37w5dRD3nHOAm28O5QSgXMFfHckuvb2WedDQYKGYAh+kyhl9fRZicdcjCRLDw8C2bcDvfge89VZyfUUFsH69hVUKLOUwG1DQSfZRtQGsri7z1hmGyS5BDrF89ZUNcm7cmDrIedJJwC23WP74zJmemRd0KOgkd4yMWBimstKEnWV5p0c8nuw0FSRUgddft7DKs88mryoiERvkvPlmq3bIq7lpQ0Enuaevzwa56utt4Q938gwNAQcPBiuLpbcX2LTJwir79iXXNzTYAOcNN3CQM8tQ0El+ULUwQXc3MGsWL6snQ0+PhSqCMn1//37zxh99NPVq4qyzLKxy+eUc5MwRFHSSX0ZGzNOsrDTvjLnEYxON2kShINQtj8WAF14wb/yPf0yuLysD1q0zIfd5P84wQEEn3tDXZ71Mm5sZWx+NquX2t7f7f/p+R4fN4nzggdTmEfPmWWz86qsLbianl1DQiXcMD5uon3ACKzg6DA5aN6GhIa8tGZ/du80bf+qpVFsvvNC88QsuYKllD6CgE29xygc0NRV2H9N43NL4/NyAYngY+P3vTcjffju5vqrKPPGbbw5NK7egQkEn3qNqg35DQzZgWmj09FgTEb+2hXNyxx96KDX//ZRTzBtft45zDXwCBZ34h44O8wILZbB0ZMQGPf2YV64KtLYC990HPPNMau74ZZeZkJ97LlNQfQYFnfiLvj7gs88sBBPWsrzxuA14dnT4LxWxv99qqtx3H/Chq+FYQwNw3XU2JX/OHO/sI+NCQSf+Y2TE4urV1RaCCcvgmqqVQ2hr818Nls8+s9zxRx6xEJDDsmXAd79rPTmZO+57KOjEv3R3m8fe3AyUl3ttzfSIRi3/3k+VEeNx4OWXzRt/6aXk+tJSa+N2883WBYgEBgo68TdOFswJJwQ3BDMwYGLuF6+8q8tmcd5/v6WNOpxwgoVUrr2WPWMDCgWd+J943CatzJ0bvJIBXV028OmHWPneveaNb96ceqWwYoWFVS65JDzhrQKFgk6CgapVGqyvtzrrfs+C6e21WLnXE4Sc5sr33Qfs3JlcX1GRzB0/+WTv7CNZhYJOgoNT4KujA6ipMWH3U2ekWMyEvLPTeyE/fNjyxh980HLcHVh3PNT46NdASIbE4ybqnZ0m6vX13nns8bgN3vb0pLZP8wJ37vizzyYnKhUVAStXWliFdcdDDQWdBBdVy+d2SvJWVeXvvaNR+0Pp7PS+gFZfn9Udv//+1Nzx+vpk3fETTvDOPpI3KOgk+ESjFl8/fNjSG2fMsBhxLgp+9ffbQGdvr/cDnR9/bFUOH3sstcTumWdabHzNGuaOFxgUdBIe4nET3P5+i7XPmGFe6nTrjMRi5ol3d3vfMSgaBZ57zrzxV19Nri8rs9zxW24BzjjDO/uIp1DQSXgZGLB0x7Iyq8ldVZU+1q5qQu2OOUciSSHv6fHeGz961BorP/igFctymDfPcsevvtrGE0hBQ0En4WdoyMIxR45YZkdZmaXzjYzYrV8m/IzGGeS8/37g6aeTfzgiwEUXWVjlggv8n8JJ8gYFnRQOquZtu2uV+JHeXuCJJyw+/tFHyfW1tcA115hHPm+eZ+YR/0JBJ8Qv7N1rIr5pk40DOCxblhzkLCvzzj7ieyjohHiJ0wXogQeAN99Mri8vt8YRN90EnH66d/aRQEFBJ8QLPv/cugA9+qhNknJYtMhE/MorbTYsIZMgI0EXkdUAfgkgAuAeVf2nMfY7B8BrAG5Q1YezZiUhYSAaBV54wbzxV15Jri8uBi691IScMznJNJhQ0EUkAuBXAFYBOABgh4hsUtX30uz3zwC25cJQQgLLV19ZyuHGjZZt4zBnjs3kvO46YPZs7+wjoSETD/1cAPtUdT8AiMgGAOsBvDdqv78F8AiAc7JqISFBJBYzL3zDBvPKnfIAIpZqeNNNwIUX+qu4GAk8mZxNzQC+cD0+AGC5ewcRaQZwFYCVGEfQReRWALcCwPzm5snaSoj/OXLE2rht3GiTmhwaGqxxxHXXMeWQ5IxMBD1dQG/0tLlfAPihqsZknPifqt4N4G4AaFm61AcV/wnJAvE4sH27zeJ87rnkBCDAYuI33mgxctZVITkmE0E/AMDtUpwI4OCofVoAbEiIeSOAtSISVdXHs2EkIb7kyBHLUtm40drkOdTW2lT866+3rBVC8kQmgr4DwGIRWQTgSwA3ArjZvYOq/umsFZHfAHiSYk5CiRMb37jRvHF32YBzz7VStatWcQIQ8YQJBV1VoyJyOyx7JQLgXlXdIyK3JbbflWMbCfGeQ4csNv7II9bw2aG2FrjqKvPGTzrJM/MIATLMQ1fVLQC2jFqXVshV9a+mbxYhPmBkxDJUNm4EXn45tZHF8uVJb5yxceITmDNFyGg++QR4+GHg8ceBY8eS6xsbzRu/7jpgwQLPzCNkLCjohABWDGvbNhPy1tbk+qIiyxu/7jrg4ouBkhLPTCRkIijopHBRBXbtMhF/6inrzenQ3GyZKtdcA8yd652NhEwCCjopPI4dsxK1jzwC7NuXXF9SAlx2mXnjK1awcQQJHBR0UhiMjAAvvmh54y++mDr559RTbRbnunVs40YCDQWdhJsPPgAee8w88ra25PrqahPwq6+2euOscEhCAAWdhI/2douJP/YYsGdPcr0I8M1vWqYKJ/+QEEJBJ+FgeBh46SUT8RdftBCLw4IFJuJXXskBThJqKOgkuKgCu3dbQ+Unn0zt/FNZCaxda0J+9tkMqZCCgIJOgsfBg8DmzSbkH3+cXF9UBJx/vnnil10GzJjhmYmEeAEFnQSDnh6b+PPEE8Abb6RuW7zYRHzdOqCpyRPzCPEDFHTiX4aHrYbKpk1W2XB4OLmtoQG44goT8iVLGFIhBBR04jficWDnTgup/P73QFdXclt5uTWKWL/eslXYvo2QFPiLIN6javnimzdbuuGhQ8ltRUXW9Wf9eouLz5zpnZ2E+BwKOvGOzz+37JSnnkqdgg/YZJ/vfMcyVWbP9sa+dIjYn4xqajldQnwABZ3kl6++ArZuNRF/993UbQsXWlz8iiuAk0/Ov22VlTbZyBFrEat17iyRyPGx+ljMygj09trArTvOT0ieoaCT3HP0qGWobNli8XE3TU3mha9dC3z96/kf3BSxMgB1dVNrVBGJ2FJWZgO1Q0MW9+/upgdP8g4FneSG9nbg6adNxHfsSBW3ujrg8svNE29p8a6qYXW1Na3I5uBqWZmFiBobTdg7O1NnrRKSQyjoJHu0tQHPPGPZKa+/niri1dU2qLl2rQ1yetkowhHdXE48KiqyP666OgvFtLeb905IDqGgk+lx9KiJ+LZtNuHHLeKVlZZmuHatpRl63XtzxgwT2HxnylRV2dLXZ+Le28twDMkJFHQyeQ4dsnDK009bTFw1ua2yEli5ElizBvjWt/xR0bCqyoS8vNxbOyorbVE1cW9ro9dOsgoFnWTGZ5+ZF/7MM9a2zU1VlXnil19unrgfRHy6g525RMSuEiorLRTT3p76p0jIFKGgk/SoAu+9ZwL+hz8AH36Yur221mLi3/62tWvzi2hGIkBNjdnn95mkIpYZM3MmcOQIMDDgtUUk4Pj8jCd5JRq1jvfPPmsifvBg6vbZs60xxKpVwDnn+Eswy8qA+noTx6DVdSkrA+bNs5z2vr7kwjg7mSQ++kUST+jtBV55xYpfvfiipdm5WbDAPPFVq4Bly/zXONnJ/w5DSYBIxMJE1dX2eGAA6O83cR8c9NY2Eggo6IXIwYPA88+biL/++vF50mecYSJ+6aVWmtaPHm9JieV6V1V5bUnumDHDloYG8977+5NZMoSkgYJeCMTjNs3++edt2bs3dXtJCbB8uWWnrFzp7zZtRUUWWqmr8+cfTa6IRJLpjx0dli5KyCgo6GGlpwf44x8tjPLii6kd7wEbNLzwQuCSS+w2CCGLykorFeCn2L0XOJk7hw4xzk5SKPBfRohQtXZsL74IvPAC8OabNsjp5uSTgYsvNhE/66zgCGNRkQ3IOrFlYn9u8+ebt97bayEZUvAE5BdN0tLbC7z2mnW7f+UV4MsvU7c7oRTHE58/3xs7p0NVFTBrVnD+fPJJaaldsTQ12QBqb68NoLLiY8GS0a9ERFYD+CWACIB7VPWfRm2/BcAPEw97AfxnVX0nm4YSmBe+d6+1ZXv5ZeCtt44f0JwzB7joIhPxFSvMkwsilZU26OmHSUpBwBlAnTXLzom+Pqv4yOyYgmJCQReRCIBfAVgF4ACAHSKySVXfc+32CYCLVLVDRNYAuBvA8lwYXHAcPQps324e+PbtwLFjqduLi4GzzzYBv/BC4JRTgj1YOHOmDXp6PU0/yJSU2BhJba15611dtjDeHnoy8dDPBbBPVfcDgIhsALAewJ8EXVW3u/Z/DcCJ2TSyoBgYsHKz27fboOboGZoA0NwMXHCBLeedF4wBzfEQsdmddXXeVmEMI6Wl5rU3NNgcg44OxttDTCaC3gzgC9fjAxjf+/5rAFvTbRCRWwHcCgDzm5szNDHkRKPA7t3Aq6+aiKcLo1RUWCz8m9+0glcLFwbbC3dTVWWhFQp5bnHSPWtrKewhJhNBT6ccaSsJicglMEH/Vrrtqno3LByDlqVLC7MaUTxuXvdrr9myY8fxE0WKimxyz/nnm4ifeaZ/aqVki4oKE3KGVvKLO4+/q8sKg43OhiKBJRNBPwBgnuvxiQAOjt5JRJYCuAfAGlVtG729YFEF9u838X79dasZ3tFx/H4LF5qAr1gBnHuueVJhhDFyfyBi51hNjc1Z6OhgKd8QkImg7wCwWEQWAfgSwI0AbnbvICLzATwK4M9VNU3Qt4BQtQ72b7xh3vcbbxw/qQewVLPzzjMBP+88f8/OzAYVFRbLZdaKv3DKDFdXW2ZMezurPgaYCQVdVaMicjuAbbC0xXtVdY+I3JbYfheAfwTQAODXYrHdqKq25M5sHxGLAR98YOLd2mq36TzwxkbzvJcvNwFfsCA8cfDxKC42IQ9zzZWw4DTgGBxMTlhinfZAkVEeuqpuAbBl1Lq7XPf/BsDfZNc0nzI4aHVRdu40AX/rrfTFkhobrcSsI+InnVQYAu7gTp0rpOMOA+XldsUYjdoAalcXB1ADAqffTURbm4n2zp12u3t3+i7uc+daB/uWFhPxRYsKU8gqK03EgzqhiSQpLjbHpKHBJil1djLO7nMo6G5iMeCjj4C337blzTet9Vo6TjrJxPsb37DbEws49b6kxAbXqqs5RT+MOPMEamosvt7ZyXCMTynsX197u/XHdAR81y4bGBpNSYmlEZ59tgn4WWdZpkahU16e7BJECgOnxEAslpyBmu6KlXhC4Qj64CDw/vsm2rt2Ae+8A3zxRfp9GxtNtM8800T89NOZneGmosKEvKLCa0uIV0Qidg7U15sT1NVlt/TaPSWcgh6NWurgu+9azPvddy0TJd0EiuJi4LTTTLyXLbPbE08szPj3RFRWWjyVOeTEjZMdE4tZrL2rixUfPSL4gh6L2cSdPXtMvHfvNk98rCpzzc0m3MuWAUuXAkuWUKDGo6jIYuM1NbxKIeMTidgM1Lo6+/11ddmkJRYFyxvBEvThYWvisGePifaePVZOdqyJEPX1wNe/bsvSpXbL2HdmlJebiFdV+a8xNPE/5eW2zJ5tA6g9PQzJ5AH/CnpPj4VJ3n8feO89E+6PPhp7AKamxmLdZ5yRXE44gaGTyVBenuxbyWwVkg1EkudULGbi3t3N2ag5wvtfbTwOHDhggv3BB3a7d6+tG4v6eguVnH66LUuWMO49FURsYLOy0jJVKOIkl0QiyfTHaNSctp4eNuHIIt79gr/8Erj+evO6+/vH3q+52QT7tNPsdskSu4yjeE+NSCQp4BUVDKcQbyguTsbbR0aSYRmK+7TwTtDb221xKC8HFi8Gvva15HLqqawBkg3Ky5OZCBwAJn6jpCQp7tGoiXtvr4VlGHOfFN4JenU18N3vmmifcooVq4pEPDMndJSVJWOXbB5BgkJxcbIGUCxmA6l9fZyZmiHeCfqCBcAPfuDZ24eSSCRZCpUphiTouM/neDwp7BT3MeEoWNBxYuJVVRYT59gCCSNFRckrTtWksPf1Mc/dBQU9iJSVJbNTZsygiJPCwp0KqWpJFY7AF3iZXwp6ECgqSs1M4VgDIYZIcsC/qcnK+/b3m+c+OFhw3jsF3a+UlCRPVIZSCMmMsjJb6urs8dCQZcsMDtptyCtDUtD9goiFTxwRLy312iJCgo8j8A6xmIm7ewlRmIaC7iVOLNxZ6IUTklucJAJ3R62REfPkHYEfGgqsyFPQ80lZmXnhFRV2y1g4Id5TUmKLu1FLNJoq8gHx5CnouUIkWXGuosJuKeCEBIPiYlvcnnw0murF+1DkKejZIhIxr7u8PHnLEAoh4aG42Lx4tyc/MpIq8h6HayjoU0EkGT5xvHBOryek8HDCNe6aU05M3r3kKbuGgj4RkYiJd2mpCbdzn943ISQd6WLy8bg16BkaSr1N1xZzGlDQARPnkhITamdxHjPuTQiZLkVFyat5N47Qj15GRqZUr6ZwBL2oKPnP6Yi1+zEhhOSbsYQeMFF3FkfkJwjdhEfQRWzQwi3SbvFmIwdCSJCYgrMZHEGPRJKpRM7iHLDzmHFtQkgB462gRyLJpbj4+PuOUEciFGtCCJkA7wS9tBQ4+WTP3p4QQsIGA8uEEBISMhJ0EVktIh+IyD4R+VGa7SIi/5bYvktEzp7wRd99F1i5Eti6dQpmB4StW+0Y58yxcp5NTeE/5qAjkn6JROyqsqkp2VSkqMjmJcyZY9/rz35mt4sWHf89O+dCum1unP2amuyccV7bvf/Pfmbbiovt9rvfnf77klAgOkGuo4hEAHwIYBWAAwB2ALhJVd9z7bMWwN8CWAtgOYBfqury8V63pbJSW+fPt3ScO+8E1qyZ3pH4ja1bgdtvt+M7fDg5BjB7tglDGI856ExnnKahAejqMgGePduaLDjnNmDnQmmp1fVxb3OfA+5z5sgRW6dq4u6cMzt2AD//uf2ZRCK2bywGNDYC8+dP7X1JoBCRnaraknZbBoK+AsBPVPXyxON/AABV/e+uff43gBdU9YHE4w8AXKyqh8Z63ZbKSm097TTrLDJ3LvDcc5M9Ln+zciVw6BDw5ZeWO1pUZD+80lKguTmcxxx0piPozoB+WRlwyim2zjm3ATsX3IWe0p337nNmeNheLx63TC7nnHnrLRPm4sTwl9OVJxIBzjxzau9LAsV4gp5JyKUZwBeuxwcS6ya7D0TkVhFpFZHWo86U14oK4NNPMzAjYHzyiR3b0FAyB76oyB6H9ZgLmVjMRHVoKLnO+Z6dc8FNunMgk3Ompyd19rLjkLkLQk32fUloyETQ07kto936TPaBqt6tqi2q2jLL8TD6+4GFCzMwI2AsWmTHVlaW7GsYj9vjsB5zIROJmKi6u+M437NzLrhJdw5kcs5UVaWKt3NV4Rb5yb4vCQ2ZCPoBAPNcj08EcHAK+xxPX59dWt5xRwZmBIw77rBjq6mxH2A0at5UTU14j7mQqa018a2pse/ZfW4750Jf3/Hb3LjPGVU7Z2Kx1HPm7//e3sc5nxxBr6ub+vuS8KCq4y6wXPX9ABYBKAXwDoDTR+1zBYCtME/9PABvTPS63ygtVb3kEtUtWzS0bNlix9jUpFpba7dhP+agY9J3/FJUpFpSojp7tmp5ua0TUS0tTX6vP/2p3S5adPz37JwL6ba5yeSc+elPbVtxsd3ecsv035cEBgCtOoauTjgoCvwpi+UXACIA7lXV/yYityX+EO4SEQFwJ4DVAPoBfE9VW8d7zZaWFm1tHXcXQgghoxhvUDSjmaKqugXAllHr7nLdVwDfn46RhBBCpgdnihJCSEigoBNCSEigoBNCSEigoBNCSEjIKMslJ28schTAZ568+eRoBHDMayMygHZmF9qZXWhn9ligqrPSbfBM0IOCiLSOlSLkJ2hndqGd2YV25geGXAghJCRQ0AkhJCRQ0Cfmbq8NyBDamV1oZ3ahnXmAMXRCCAkJ9NAJISQkUNAJISQkFLygi0i9iDwjIh8lbuvS7HOqiLztWrpF5O8S234iIl+6tq31ys7Efp+KyLsJW1on+/x82Cki80TkeRF5X0T2iMgPXNty+nlOp+H5RM/Ns523JOzbJSLbRWSZa1vac8AjOy8WkS7X9/mPmT43z3be4bJxt4jERKQ+sS1vn+e0GauubqEsAP4HgB8l7v8IwD9PsH8EwFew5H4A+AmA/+IXOwF8CqBxuseZSzsBzAVwduJ+FawJ+ZJcf56J7+5jACchWdt/yah91iK1tv/rmT43z3aeD6AucX+NY+d454BHdl4M4MmpPDefdo7afx2A5/L9eWZjKXgPHcB6AP+RuP8fAK6cYP9LAXysqvme5TpZO7P9/Ky9j6oeUtU3E/d7ALyPND1oc8C5APap6n5VHQawIWGvm/UAfqvGawBqRWRuhs/Nm52qul1VOxIPX4N1Ccs30/lMfPV5juImAA/kyJacQkEHmlT1EGBCA2D2BPvfiOO/7NsTl7735iqUgcztVABPi8hOEbl1Cs/Pl50AABFZCOAsAK+7Vufq85xOw/OMGqFnicm+11/DriocxjoHsk2mdq4QkXdEZKuInD7J52aDjN9LRCpgjXoeca3O1+c5bTJqcBF0RORZAHPSbPrxJF+nFMB3APyDa/W/A/g57Ev/OYB/BfCfPLTzm6p6UERmA3hGRPaq6ktTsWcssvh5zoT9cP5OVbsTq7P2eaZ7yzTrMm14nlEj9CyR8XuJyCUwQf+Wa3XOz4FJ2PkmLDzZmxgPeRzA4gyfmy0m817rAPxRVdtd6/L1eU6bghB0Vb1srG0iclhE5qrqocSl9ZFxXmoNgDdV9bDrtf90X0T+D4AnvbRTVQ8mbo+IyGOwy82XAEzmOHNup4iUwMT8d6r6qOu1s/Z5pmE6Dc9LM3hutsio6bqILAVwD4A1qtrmrB/nHMi7na4/aqjqFhH5tYg0ZvLcfNrp4rgr8Dx+ntOGIRdgE4C/TNz/SwBPjLPvcbG1hGg5XAVgd1atSzKhnSJSKSJVzn0A33bZM5njzLWdAuD/AnhfVf/nqG25/Dx3AFgsIosSV1s3Jux1swnAXySyXc4D0JUIHWXy3LzZKSLzATwK4M9V9UPX+vHOAS/snJP4viEi58I0py2T5+bTzoR9NQAuguuczfPnOX28HpX1egHQAOAPAD5K3NYn1p8AYItrvwrYiVgz6vn/D8C7AHbBTpK5XtkJG8V/J7HsAfDjiZ7vkZ3fgl3y7gLwdmJZm4/PE5bF8iEs6+HHiXW3AbgtcV8A/Cqx/V0ALeM9N4fn5UR23gOgw/X5tU50Dnhk5+0JO96BDd6e78fPM/H4rwBsGPW8vH6e01049Z8QQkICQy6EEBISKOiEEBISKOiEEBISKOiEEBISKOiEEBISKOiEEBISKOiEEBIS/j/V6/yQE01LcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x = residuals, y = y_test_pred, logistic=True, scatter = True, color = 'red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.residplot(x=resid, y=y, lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9371859296482412\n",
      "0.9239766081871345\n",
      "Training ROC_AUC:  0.9309317808145332\n",
      "Test ROC_AUC:  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#normal data helped this\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "y_train_pred=gnb.predict(X_train)\n",
    "y_test_pred=gnb.predict(X_test)\n",
    "print(gnb.score(X_train, y_train))\n",
    "print(gnb.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6256281407035176\n",
      "0.631578947368421\n",
      "Training ROC_AUC:  0.5\n",
      "Test ROC_AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=5.336699231206302e-08)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9903783068783069"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'var_smoothing': np.logspace(0,-9, num=100)\n",
    "        }\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(gnb, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var_smoothing is a stability calculation to widen (or smooth) the curve and therefore account for more samples that are further away from the distribution mean. In this case, np.logspace returns numbers spaced evenly on a log scale, starts from 0, ends at -9, and generates 100 samples.\n",
    "from https://medium.com/analytics-vidhya/how-to-improve-naive-bayes-9fa698e14cba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>5.3367e-08</td>\n",
       "      <td>{'var_smoothing': 5.336699231206302e-08}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.990378</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>6.57933e-08</td>\n",
       "      <td>{'var_smoothing': 6.579332246575682e-08}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.990288</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>4.32876e-08</td>\n",
       "      <td>{'var_smoothing': 4.3287612810830526e-08}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>0.012301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>8.11131e-08</td>\n",
       "      <td>{'var_smoothing': 8.111308307896873e-08}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.989828</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>3.51119e-08</td>\n",
       "      <td>{'var_smoothing': 3.5111917342151277e-08}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.989741</td>\n",
       "      <td>0.013120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>2.84804e-08</td>\n",
       "      <td>{'var_smoothing': 2.848035868435799e-08}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.989741</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.004434</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>2.31013e-08</td>\n",
       "      <td>{'var_smoothing': 2.310129700083158e-08}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.989366</td>\n",
       "      <td>0.012831</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>{'var_smoothing': 1e-07}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.989271</td>\n",
       "      <td>0.011303</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>1.23285e-07</td>\n",
       "      <td>{'var_smoothing': 1.232846739442066e-07}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.988925</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.005517</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>1.87382e-08</td>\n",
       "      <td>{'var_smoothing': 1.873817422860383e-08}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.988823</td>\n",
       "      <td>0.013219</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "80       0.004858      0.001144         0.005572        0.001084   \n",
       "79       0.005134      0.001284         0.005401        0.000840   \n",
       "81       0.004229      0.000950         0.004737        0.001124   \n",
       "78       0.005034      0.000912         0.005205        0.000982   \n",
       "82       0.004005      0.000852         0.004762        0.000993   \n",
       "83       0.003800      0.000791         0.004001        0.000931   \n",
       "84       0.004668      0.001399         0.004434        0.001022   \n",
       "77       0.005235      0.000957         0.005233        0.000957   \n",
       "76       0.004069      0.001211         0.004032        0.000913   \n",
       "85       0.005517      0.001114         0.005500        0.001118   \n",
       "\n",
       "   param_var_smoothing                                     params  \\\n",
       "80          5.3367e-08   {'var_smoothing': 5.336699231206302e-08}   \n",
       "79         6.57933e-08   {'var_smoothing': 6.579332246575682e-08}   \n",
       "81         4.32876e-08  {'var_smoothing': 4.3287612810830526e-08}   \n",
       "78         8.11131e-08   {'var_smoothing': 8.111308307896873e-08}   \n",
       "82         3.51119e-08  {'var_smoothing': 3.5111917342151277e-08}   \n",
       "83         2.84804e-08   {'var_smoothing': 2.848035868435799e-08}   \n",
       "84         2.31013e-08   {'var_smoothing': 2.310129700083158e-08}   \n",
       "77               1e-07                   {'var_smoothing': 1e-07}   \n",
       "76         1.23285e-07   {'var_smoothing': 1.232846739442066e-07}   \n",
       "85         1.87382e-08   {'var_smoothing': 1.873817422860383e-08}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "80                1.0           1.000000           1.000000   \n",
       "79                1.0           1.000000           1.000000   \n",
       "81                1.0           1.000000           1.000000   \n",
       "78                1.0           1.000000           0.997333   \n",
       "82                1.0           1.000000           1.000000   \n",
       "83                1.0           0.997333           1.000000   \n",
       "84                1.0           0.997333           1.000000   \n",
       "77                1.0           0.997333           0.997333   \n",
       "76                1.0           0.997333           0.997333   \n",
       "85                1.0           0.997333           1.000000   \n",
       "\n",
       "    split3_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "80                1.0  ...            0.968000                 1.0   \n",
       "79                1.0  ...            0.968000                 1.0   \n",
       "81                1.0  ...            0.968000                 1.0   \n",
       "78                1.0  ...            0.968000                 1.0   \n",
       "82                1.0  ...            0.968000                 1.0   \n",
       "83                1.0  ...            0.970667                 1.0   \n",
       "84                1.0  ...            0.973333                 1.0   \n",
       "77                1.0  ...            0.965333                 1.0   \n",
       "76                1.0  ...            0.968000                 1.0   \n",
       "85                1.0  ...            0.968000                 1.0   \n",
       "\n",
       "    split25_test_score  split26_test_score  split27_test_score  \\\n",
       "80            0.978667            0.992000                 1.0   \n",
       "79            0.973333            0.992000                 1.0   \n",
       "81            0.978667            0.992000                 1.0   \n",
       "78            0.976000            0.992000                 1.0   \n",
       "82            0.978667            0.989333                 1.0   \n",
       "83            0.978667            0.986667                 1.0   \n",
       "84            0.973333            0.986667                 1.0   \n",
       "77            0.981333            0.992000                 1.0   \n",
       "76            0.984000            0.997333                 1.0   \n",
       "85            0.973333            0.986667                 1.0   \n",
       "\n",
       "    split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "80            0.985714            0.991667         0.990378        0.011856   \n",
       "79            0.988571            0.991667         0.990288        0.011656   \n",
       "81            0.982857            0.991667         0.990096        0.012301   \n",
       "78            0.982857            0.991667         0.989828        0.011584   \n",
       "82            0.982857            0.991667         0.989741        0.013120   \n",
       "83            0.982857            0.994444         0.989741        0.012479   \n",
       "84            0.980000            0.994444         0.989366        0.012831   \n",
       "77            0.980000            0.991667         0.989271        0.011303   \n",
       "76            0.980000            0.991667         0.988925        0.011723   \n",
       "85            0.977143            0.991667         0.988823        0.013219   \n",
       "\n",
       "    rank_test_score  \n",
       "80                1  \n",
       "79                2  \n",
       "81                3  \n",
       "78                4  \n",
       "82                5  \n",
       "83                6  \n",
       "84                7  \n",
       "77                8  \n",
       "76                9  \n",
       "85               10  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447236180904522\n",
      "0.9649122807017544\n",
      "Training ROC_AUC:  0.9302175143527127\n",
      "Test ROC_AUC:  0.958994708994709\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(var_smoothing=5.336699231206302e-08)\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "y_train_pred=gnb.predict(X_train)\n",
    "y_test_pred=gnb.predict(X_test)\n",
    "print(gnb.score(X_train, y_train))\n",
    "print(gnb.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'False Positive Rate')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHwCAYAAAC2blbYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABUmElEQVR4nO3dd5hU1f3H8feXLSy9WwARFCyADRE0sWMvIBbERjHGrjExGmOaP2NMMYkxicbYxQIiKqJiSaJYYtcoAopiQVBUBKXDTjm/P87dZRhmZmfZnblTPq/n2Wd3Zu7M/c7dmfnMOffcc805h4iIiBSfFmEXICIiIptGIS4iIlKkFOIiIiJFSiEuIiJSpBTiIiIiRUohLiIiUqQU4iExs9lmtn/YdRQKM7vczG4Jad13mNlVYay7uZnZKWb21CbeN+vXpJlNNLNjNmU9m8rMhpvZpAaW2d7M/mdmK8zswnzVJsXFzD4xs4PS3LaPmc3Nd02bSiFO/T90jZmtNLMvgg/1trlcp3NugHNuRi7XUcfMWprZb83s0+B5fmBml5iZ5WP9KerZ38wWJl7nnLvaOXdGjtZnZnahmc0ys1VmttDM7jeznXKxvk1lZleY2d1NeQzn3D3OuUOyWNdGX1yyfU2a2c7ALsDDweVxZhYL3j/LzextMzsq6T5ZvQbN7FAzey4I4cVm9qyZDQ/qmwYMDNafzqXADOdcO+fcXxt6Llk8145mdlvwubDCzN43s5809XFzoYFg6mFmUTPbNsVtD5nZH5uwXmdmfTf1/iker3fwmG8mXd/VzGrN7JPmWlcqzrnnnXPb53IdzUkhvt7Rzrm2wK7AbsBPwy2n8cysMs1N9wPDgCOAdsBpwJnAdTmowcys0F5X1wE/AC4EOgPbAVOBI5t7RRn+BzmXx3WfBdzjNpwp6qXg/dMRuAGYZGYdE25v8DVoZscHy00AegKbA78Ejk54nInB/dLZGpi9KU8qzfa7FmgL7Ah0AIYDH27K4+dKNv9359xnwH/w2z3xvp3x/5M7c1NdZg3U3sbMBiZcPhn4OMclFR/nXNn/AJ8AByVc/gPwWMLlPYEXgW+Bt4H9E27rDNwOfA58A0xNuO0o4K3gfi8COyevE+gOrAE6J9y2G/A1UBVcPh14N3j8J4GtE5Z1wHnAB8DHKZ7bMGAtsFXS9UOBGNA3uDwD+C3wKrAM38rqnOU2mAH8Bvhv8Fz6AuODmlcAHwFnBcu2CZaJAyuDn+7AFcDdwTK9g+c1Fvg02BY/S1hfK/yHzjfBOi4FFqb53/YLnueQDP//O4DrgceCel8Btk24/TpgAbAceAPYJ+G2K4ApwN3B7WcAQ4CXgm21CPg7UJ1wnwHAv4ClwJfA5cBhQC0QCbbJ28GyHYBbg8f5DLgKqAhuGxds82uDx7oquO6F4HYLbvsq+J/OBAbiQzASrG8l8Ejy+wCoCOr6MNgmbxC8hoL/594Jz6d+ncHl1sH/b49sX4NBrZ8ClzTwXv0uKV7nwW1PB4+3Nnhe2wXbbwKwGJgP/BxokW77pXjMWcAxadbXO3ielUnvhTOSHv9vwfZ/DxiWtGym99xw/BeSb4Nld0z6/PhJ8D9dh/9yE8e/t1YCl6ao92Tgw6TrzgXeDP7uDjwQbKuPgQsTlkv5egCeC7bBqmC9JwbLfx+YF2zXaUD3Rnxm1W3XnwPXJFz/OvAz4JOE6y5LqGkOMDLpsb7P+s+hOcCghO3342D7LQPuA2qC2/Yn4fMk07INfc7n4yeU0Cy0Hzb88OoJvANcF1zuASzBf1ttARwcXO4W3P5Y8E/tBFQB+wXXD8J/eA4N3gBjg/W0TLHOp4HvJ9RzDXBj8PcxwZthR6AyeGG/mPSG+Bf+y0SrFM/td8CzaZ73fNaH6wx8SAzEB+0DrA/VhrbBDPwH8ICgxip8K3db/IfzfsDqhDfQBm+S4Lor2DjEb8YH9i74D6odE59TsM17Bm+udCF+NjC/gf//HfgPmyFB/fcAkxJuPxXoEtx2MfAF69/wV+AD8Zhg27QCdsd/6akMnsu7wEXB8u3wgXwxUBNcHpq8DRLWPRX4Z/A/2Qz/gV/3PxsHRIELgnW1YsMQPxT/Ydsx+D/sCGyZ8JyvSlrXJ6x/TV6Cfx9sH9x3l2AbtAn+N90S7pe4zgr8B3QtsFm2r0Fgh+Bx+zTwv+ocLNc+ze0zCEI0uDwBH47tgv/F+8D30m2/FI93Cz5IxwP9km7rTcMhHgV+iH9PnIgPgc5ZvOe2wwfjwcF9L8V/DlQn/K/ewgdpq+T/X5pt0ypYf+IXsJeAi/Cv3TfwPR/VwDb4L2uHZno9JHwG9U14zAPxX7wHAS3xX2Kea8RnVt127Y3/8lyBf+3OxTd8PklY9gT8l48WwfZdxfrX+AnB9t0jqLkvQQMo2FavBvftjH+Pnp3q86mBZTN+zufjJ/QALYSfYKOvxH9bc/hup47BbT8B7kpa/sngn7Ul/ttvpxSP+Q/g10nXzWV9yNe/4fCtt6eDvy144e4bXH6c4EMnuNwCH4h1L0YHHJjhud1CQiAl3fYyQQsX/4Hyu4Tb+uM/iCsybYOE+17ZwDaeCvwg+HuDN0lw3RVsHOI9E25/FRgd/F3/4ZKw/dKF+M+Alxuo7Q7gloTLRwDvZVj+G2CXhLqfa+DxLwIeCv4+CfhfmuXqt0FweXP8l5dWCdedBDwT/D0O+DTpMcaxPlAPxIfWngStz6TnnCnE5wIjUtTYI/jf1CStM4pviUTwrcFRjXkN4lvYGzxumuWrguV6pbl9ButDtCLYfv0Tbj8Lv8885fZL8Xit8C3QN4LnNg84POl1minEPwcs6XV8WhbvuV8AkxNua4EPpP0T/lenp/v/ZXg+twA3BX/3C9a3GT6Ekl9LPwVuz/R6CG5LDvFbgT8kXG4bbLveCctn+syq367Av/FfRn8XvE42CPEU932rrk78Z9QP0iz3CXBqwuU/sL7htD8bh3i6ZTN+zufjp9D2XYbpGOdcO/w/cAega3D91sAJZvZt3Q+wNz7AtwKWOue+SfF4WwMXJ91vK/y3uWRTgL3MrDuwL/4F/HzC41yX8BhL8UHfI+H+CzI8r6+DWlPZMrg91ePMx39gdiXzNkhZg5kdbmYvm9nSYPkjWL9Ns/VFwt+r8R8G4Ldh4voyPf8lpH/+2awLM7vYzN41s2XBc+nAhs8l+blvZ2aPBoOhlgNXJyy/FdnvU90a/z9YlLDd/4n/0E257kTOuafxXfnXA1+a2U1m1j7Ldaer89vgd7uk6192znXE945MA/ZJuC2b1+CShMuZ1K3320wLBbriW5XzE66bT/bvHZxza5wfdLk7vidiMnB/sC85G5+54JM9Yf2JnwHp3nPdE+t2zsWDZbOuPY07gVFmVoPfP/6Ec+4r/Gute9J7/HL8F0lo3Os2ufaV+P/vptQ+Af9l6CT8LqsNmNkYM3sroeaBZP9eS/ueb8SyjfmczwmFeBLn3LP4VkrdaM0F+FZox4SfNs653wW3dU4awEPC/X6TdL/WzrmJKdb5LfAUMAq/32piwht/Ab77NPFxWjnnXkx8iAxP6d/AUDPbKvFKMxuCf7E9nXB14jK98N+ev25gG2xUg5m1xHcN/hHYPPhwn47/8tFQvdlYhO9GT1V3sv8APc1s8KasyMz2wfdEjML3uHTEd0kmjqpOfj7/wO//7Oeca4//MKxbfgF+N0MqyY+zAN+S7Jqw3ds75wZkuM+GD+jcX4MAGoDvor0km/ulq9M5twr/wbhdmvWtxO9nPc3MdguuzuY1ODdY53EN1LUjviW2vIHlwL92I/gP2jq98C3a+pKzeBy/oF/n1fiu7z74rlvwYwDqbJF0tx5JI/B74VvnddK95z5PrDt4jK0aqL3B5+Kcex4fqCPwu4kmBDctwO+fTnyPt3POHZFwe7rXbbLk2tvgvwBtynZ/AL9r7iPnXOKXMcxsa/wut/PxXfsd8WMYsnmvNZesP+dzRSGe2l+Ag81sV/y3v6ODQ18qzKzG/CFSPZ1zi/Dd3TeYWSczqzKzfYPHuBk428yGBiO225jZkWaW3IKpcy8wBv8hdm/C9TcCPzWzAQBm1sHMTsj2iTjn/o0PsgfMbEDwHPbE7/f9h3Pug4TFTzWz/mbWGrgSmOKci2XaBmlWW43fF7YYiJrZ4UDiYU9fAl3MrEO2zyPJZPw26WRmPfBv4pSC53cDMDGouTqof7SZXZbFutrhu4oXA5Vm9kugodZsO/wgt5VmtgNwTsJtjwJbmNlF5g+7amdmQ4PbvgR6143uD15fTwF/MrP2ZtbCzLY1s/2yqBsz2yN4/VXhA2ctfuBX3bq2yXD3W4Bfm1m/4PW7s5l1CW6bjh/nkJJzbklw/18Glxt8DQZfWn8E/MLMxic8373N7KaEh98P/55rUPDanQz8JtjOWwfryPowPjP7RbAdq4PW6w/wvQBznXOL8cF0avCcTmfj0NgMuDD4bDgB/yVkesLt6d5zk4EjzWxY8P+7GP+F7kXSa+h/WmcC8Hv8WIlHguteBZab2U/MrFXwfAaa2R7B7ZleD8nrvRcYb2a7Bl/orwZecc59kkVtGwi+NB6I32WWrG58xmIAMxuPb4nXuQX4sZntHtTcN3gNNKfGfs43O4V4CsGbcwLwC+fcAvy31svxL5YF+NZM3bY7Df/t+T38AIeLgsd4HT8y8u/4fajz8N1C6UzD76P60jn3dkItD+HfcJPMd83OAg5v5FM6DngGeAK/7/9u/H6rC5KWuwvfC/EFftDVhUENDW2DDTjnVgT3nYx/7icHz6/u9vfwo2k/Mt8F1diupyuBhfgRtP/G745Yl2H5C1nfrfwtviU5kvUfYJk8iQ+N9/FdhGtpuCvwx/jnvAL/Jr+v7oZg2xyMP2zqC/wI3QOCm+8Pfi+x9cfIjsF/KZqD35ZTyG73APgvGzcH95uPb4HV9TDdCvQPtv/UFPf9M/7/9xT+C8mt+P3DADcBpyS1MJP9BTjC1h/T3eBr0Dk3BT846XR8a+5L/Ij7hxMe9yT8LoVsXYD/AvMR8AI+YG5rxP0d/uiTutbxwcCRQY8D+Pf4JfhtO4CNQ/YV/Pv6a/wRHMcHX3LqpHvPzcW3lP8W3Pdo/GGwtRlq/S3w8+B/+uMMy03At/rvc86tC9YXC9axK/599TU+BOu+aGd6PVwB3Bmsd5Rz7j/4ffoP4HvNtgVGZ6gnI+fc6865jbrFnXNzgD/hB+d9CeyEPxqg7vb78dv8Xvx7cSp+YFqz2YTP+WZnG+6ukXJlZjPwg6pCmTWtKczsHPygt6xaqNJ0ZnYvfuDV1Dyu82j8oLBR+VpnU5jZOPwgt73T3D6DIn3PSeEIbWIKkU1lZlviu+9ewrdyLsZ/E5Y8cc6dHMI6HyG73hORsqEQl2JUje9S7YPvHp+E3+8tIlJW1J0uIiJSpDSwTUREpEgpxEVERIpU0e0T79q1q+vdu3fYZYiIiOTNG2+88bVzrlvy9UUX4r179+b1118PuwwREZG8MbP5qa5Xd7qIiEiRUoiLiIgUKYW4iIhIkVKIi4iIFCmFuIiISJFSiIuIiBQphbiIiEiRUoiLiIgUKYW4iIhIkVKIi4iIFCmFuIiISJFSiIuIiBQphbiIiEiRUoiLiIgUqZyFuJndZmZfmdmsNLebmf3VzOaZ2UwzG5SrWkREREpRLlvidwCHZbj9cKBf8HMm8I8c1iIiIlJychbizrnngKUZFhkBTHDey0BHM9syV/WIiIjkWiQWZ+mqWpxzeVlfZV7WkloPYEHC5YXBdYvCKUdERMpdLO5YsTbC8jVRlq+NsGxNhOVrIixPuM5fjm5024q16zg/fi+PxvZk8hVn06Zl7iM2zBC3FNel/OpiZmfiu9zp1atXLmsSEZEiFo87VqyLbhCuy+r/9uG7QSgn3bZyXTTj47cwaN+qivY1VbRvVUn7miq26dqW9q0qOeTb+zho4SPstV0PWliqiGt+YYb4QmCrhMs9gc9TLeicuwm4CWDw4MH56aMQEZG8c86xcl10fdimafWuD94IyxLCeOW6KJl6ss2gXcvKDYK4V+fWG1zuUP93Fe1rgmWDv9u2rMTSBfSaXvBOH3bd4wy/ojwIM8SnAeeb2SRgKLDMOaeudBGRIuacY3VtLHXYrk7REl4bSei2jrJibYR4A021ti0rNwjXHh1bseOW7TYI3g71wbu+xdy+VRVtW1ZS0aIZAzYWhZevhyFnQatOMOT7zffYWchZiJvZRGB/oKuZLQR+BVQBOOduBKYDRwDzgNXA+FzVIiIi2XHOsTYS3yB8N94/nCKI1wS3r40SayCFW1dXbNDq3bxdDf02a7c+mFO2iP11bVtWUllRIFOcxCLwwBkwZyp02AoGHpv3EnIW4s65kxq43QHn5Wr9IiLlam0kVUs4mtD9vPFtKxJCuTYWz/j4NVUtNmj1dmlTTZ+ubTZq9bavqQpaxOuva1dTSVWhhHBTRNfB/eNh7mNwyG9CCXAItztdRERSqI3G0w/ESmr1Jg/MWr4mwrpo5hCurmgRdEVX1gdtr86tN2oJ1wVvh4R9w+1qKmlZWZGnLVGgImth8mnwwVNw+DUw9MzQSlGIi4g0s2gszoq1iaOio43qnl4TiWV8/MoWlrDP14dr9w6tNgjmDQZlJbWIa6rKPISbatlC+OxNOOovMDjcPcEKcRGRJLG4Y+Xaho8TXt8i3vC2VbWZQ7iihW3U6t2sXVsftq2rGmgRV1FT1SL9CGnJneg6qKiGrn3hgjegVcewK1KIi0jpiccdK2vrDlHKfJxw4m0rgttWNHCssBkbBmxNFb27tk7Z/VzfKk7oum5dXaEQLjZrl8M9J8C2B8D+lxVEgINCXEQKkHOOVbWxjcM27XHCG163ooFjhQHa1WzY7bxV59YbBHNyd3X9ba2qaFtdSYvmPExJCtuab+Hu42DRW7Dn2WFXswGFuIg0O+ccayKx9GGb4TjhuuUbOla4TXXFBscCd+9Yww417VJM0JEUzDVVtK1p5mOFpXStXgp3HQNfzoFRE2CHI8OuaAMKcRHZiHOOddH4hjNi1YVxliOmow2kcKuqig2OBd6sXQ19u228LzjVpB3tagroWGEpXbGoD/Cv3oPR98J2h4Rd0UYU4iIlal00uSWc+Tjh5PmkGzpWuGVliw1mx+rUppqtu7TZ6DjhVNNYtquporpSISwFrqIS9jof2nSFbQ8Mu5qUFOIiBSoSi2fR6k0/YrqhY4WrKqw+XNsFg7F6dmqVclR08jSW7WoqdZiSlK7ln8NX70LfYbDzqLCryUghLpIjdccKb8pxwsvXRljdwGFKlS1so4FXW3ZolfY44eQWcctKHaYkspFvF8CdR8O65fCDmdCybdgVZaQQF0kj8ZSGmVq96Y4h3tRTGiZPU5luGstWVTpMSaRZLf0Y7hwOa5fBaQ8WfICDQlxKWDzuWFXrT2noz56UvtWbqkXc1FMabhTGCSOmO7Sqoo2OFRYpHEs+9C3wyGoY+zB03y3sirKiEJeClXxKww2PE84wacfa7E9pWBfC7YKATT6l4caTdiScyKGljhUWKRlvT4ToWhj7CGyxU9jVZE0hLjmT6pSGDY2KTp5ZK5tTGnZICNgt2tew3ebrT2nYIeUgrQI8paGIhMM53622/+Ww+3jo0CPsihpFIS4ZpTql4cZnT0q/nzgSyxzCdac0rBv53LVtNdt02/CUhqmOEy6pUxqKSDgWvQ0Pn+cncem8TdEFOCjES166UxpmbhGvn9yjthGnNOzQqoqOaU5pmHycsE5pKCKh+uwNuGskVLejwTl6C5hCvMBF6g5TauRxwnVBvTaSOYRTntKwY6sGjxPWKQ1FpGgteNXPhd6qk98H3mnrsCvaZArxHIvFHSs28TjhTT2l4ebt22Z1nLBOaSgiZeezN30LvO3mMHYadOgZdkVNohBvQOKxwo05n3BTT2mYqvs58bjhutt1SkMRkUbo2g92PBqG/Qrabxl2NU2mEM/gykfmcPuLH2/yKQ3THiec0Cpuo1Maiojk3qevwBYDoWU7GHlj2NU0G4V4Bu989i09O7Vi7F69dUpDEZFiNfcJmHwaDBoLR/4x7GqalUI8g0jM0btLG87YZ5uwSxERkU3x7iNw/3jfCj/g8rCraXY6yDaDaDxOtY5DFhEpTrMehMljofuuMOZhaN057IqanRIqg2jMUVmhrnIRkaJTuxqevBy2GgqnPQQ1HcKuKCfUnZ5BJBbXtJwiIsWoujWMfdSPQK9uE3Y1OaOEyiASc1Rp0JqISPF47VZ46hd+FraufUs6wEEhnlFULXERkeLx8o3w2I/g6/chnnmOjlKhhMogEnc6wYaISDH471/hiZ/ADkfBqLugoirsivJCCZVBNBanSgPbREQK2/N/hn/9AgYcCyfcAZXVYVeUNwrxDKIxR2ULbSIRkYLWuQ/segoce3PZtMDraHR6BrVqiYuIFCbn4MvZfhKXASP9TxlSMzODaFzHiYuIFBzn/DHgN+0Hi94Ou5pQqSWehnOOWFzd6SIiBSUeh8cvgddugaFnwxY7h11RqBTiaURi/tRl1ZUKcRGRghCPw6M/gDcnwHcuhIOv9OdzLmMK8TSi8TgAlZrsRUSkMMyZ6gN830vggJ+VfYCDQjytSNS3xDXZi4hIgRgwEmraQ9+Dwq6kYCih0ogELXGNThcRCVEsAo/+EL7+wLe8FeAbUEs8jWiwT1wD20REQhJdB/ePg7nT/QC2rv3CrqjgKMTTiMTUEhcRCU1kDdx3Gsz7FxzxRxg8PuyKCpJCPI1o3LfENXe6iEie1a6GSSfBR8/C0X+F3ceGXVHBUoinUdcS12QvIiL55iAeg2P+AbueFHYxBU0hnkZ9iGufuIhIfqxd7gevtWwHY6aBPn8bpC2URt3ANu0TFxHJgzXfwF3HwKST/bSqCvCsaCulEa0/xEybSEQkp1YvhTuHwxfvwNBzNIlLI6g7PY26aVe1T1xEJIdWLoYJI2DJPBg9EfrpOPDGUIinsf4QM7XERURy5qEzYelHcPJ9sO0BYVdTdBTiaayf7EUtcRGRnDnij7DiC+j93bArKUpqZqahlriISI58+yk8+wc/gK3LtgrwJlBLPA1N9iIikgNLP4Y7j/aHk+18InTaOuyKippCPA1N9iIi0sy+nucDPLoGxk5TgDcDhXgadaPTq3SsoohI0331HkwY7mdiG/sobDEw7IpKgkI8jaha4iIizefbT6FFlZ+JbbMdwq6mZCjE04jEdZy4iEiTrV0ONe1hu0PggjegqibsikqK+orTqGuJV2tgm4jIpln4Bly3C7z7iL+sAG92Sqg06o8TV4iLiDTep6/4mdhatoMtdwm7mpKlhEqjtv4sZupOFxFplE/+C3eNhLabwfjHoWOvsCsqWQrxNNafxUybSEQka0s/hruPgw49Yfx06NAj7IpKmga2pRGNxzGDCrXERUSy16k3HPQrGHg8tO0WdjUlT83MNCIxp1a4iEi25j4BX872pxHd8xwFeJ4opdKIxuJUqRUuItKwOQ/DfafAf64Mu5KyoxBPIxKLa2S6iEhD3pkC94+HHrvDsTeFXU3ZUUqlEYk7qjTRi4hIem9NhAe/D732hFMfgJoOYVdUdjSwLY1oLE6l5k0XEUnNOXjnfui9D5w0EarbhF1RWVKIpxGNOaoq1RIXEdlILAIVVXDi3X4gW1WrsCsqW2pqphGJO53BTEQk2cv/gNsO83OiV7dWgIdMKZVGJBrXyU9ERBK98Bd44jJo3x0qNQ96IVB3ehrRuPaJi4jUe/YP8MxvYOBxMPImqFB8FAKlVBp+she1xEVEeOl6H+A7j4Zjb1aAFxD9J9KIxuOasU1EBGCHI2HVYjjwF9CiIuxqJIFSKo1IzGmfuIiUL+dg1gMQjwfzoV+hAC9AOQ1xMzvMzOaa2TwzuyzF7R3M7BEze9vMZpvZ+FzW0xiRmFriIlKm4nF47GKYcjq890jY1UgGOUspM6sArgcOB/oDJ5lZ/6TFzgPmOOd2AfYH/mRm1bmqqTGiMadziYtI+YnH4JEL4fVb4bsXwY7Dw65IMshlU3MIMM8595FzrhaYBIxIWsYB7czMgLbAUiCaw5qyprnTRaTsxKIw9Vz4312w76W+C93UmClkuRzY1gNYkHB5ITA0aZm/A9OAz4F2wInOuXgOa8paNO6oVoiLSDn5ajbMfggO+Dnsd0nY1UgWchniqb6+uaTLhwJvAQcC2wL/MrPnnXPLN3ggszOBMwF69erV/JWmEI1pshcRKRPO+Rb3lrvAea9A5z5hVyRZymVTcyGwVcLlnvgWd6LxwIPOmwd8DOyQ/EDOuZucc4Odc4O7dcvPieYjMafJXkSk9EXXwaRT4K17/WUFeFHJZUq9BvQzsz7BYLXR+K7zRJ8CwwDMbHNge+CjHNaUNT86XS1xESlhkTUw8SSY+xhEVoddjWyCnHWnO+eiZnY+8CRQAdzmnJttZmcHt98I/Bq4w8zewXe//8Q593WuamqMaFzHiYtICatdBRNHw8fPw/C/waAxYVckmyCnM7Y556YD05OuuzHh78+BQ3JZw6aK6HziIlKqorVw9/Gw4GUYeSPsMjrsimQTadrVNKIxR3WlQlxESlBlNWx7IAw5w5/QRIqWQjwNfxYzdaeLSAlZ8w0s+wy2GKhDyEqEmpopOOeCudO1eUSkRKxaAnceDXcf5we0SUlQSzyFaNwfzl6llriIlIKVX8GEEbD0IzjxHqhqFXZF0kwU4ilEYz7E1RIXkaK3fBFMGA7fLoCT74Nt9g+7ImlGCvEUInE/86uOExeRovf8n/x+8FMfgN7fDbsaaWYK8RTqWuI6FamIFL1DroLdx8IWO4VdieSAUiqFSMy3xDXZi4gUpaUfwb2jYfVSqKpRgJcwtcRTqAvxKk32IiLF5usP/Cj06DpYsQhadw67IskhhXgK6we2qSUuIkXkq/d8gONg3KOw+YCwK5IcU1MzhWj9wDZtHhEpEl/OhjuOBGsB4x5TgJcJpVQKkfqBbWqJi0iRqOkA3baH8dP9bykL6k5PoX5gm/aJi0ih+/oD6LwNdOjpW+Cmxkc5UUqlENE+cREpBvNfgpsOgGd+4y8rwMuOQjyFaEz7xEWkwH38vJ8Hvd3msMcZYVcjIVFKpVA/d7pCXEQK0YfPwD0nQMetYNx0aN897IokJNonnoImexGRgrVuBUwZ7/eDj3kY2nYLuyIJkUI8hfrR6RrYJiKFpmU7OGkSdN1OE7mIutNTiaolLiKFZs7D8Prt/u9eeyrABVCIpxSJ6zhxESkg70yB+8fDzMkQj4VdjRQQhXgKGp0uIgXjrXvhwe9Dr73glPuhRUXYFUkBUUqlsH7udG0eEQnRG3fC1HOhz74+wFu2DbsiKTBKqRRq689ipu50EQnR2m+h70Fw0n1Q3TrsaqQAKcRTWD+wTZtHREKw4kv/+7s/gJPv8+cEF0lBKZVC3WQvGp0uInn3/J/h74Nh8fv+svaBSwYK8RTqjhOvVktcRPLFOZjxe/jP/0G/Q/xkLiIN0GQvKdR3p2ufuIjkg3Pw9K/h+T/BLifDiL+rBS5ZUVMzhbppVysU4iKSDzMn+wAfNBZGXK8Al6ypJZ5CJO6oqjBMp/UTkXwYeCxE18BuY0DTPUsj6NWSQjQWp1JvJBHJpXgcnr0GVi6GiirYfZwCXBpNr5gUIjGnKVdFJHfiMZh2ATxzFcx6IOxqpIipOz2FaDyuKVdFJDdiUZh6DrwzGfa7DIaeFXZFUsQU4ilEok7HiItI84tF4IEzYM5UOPAXsO+Pw65IipxCPIVIXPvERSQH1i6HL2fDIVfBdy4IuxopAQrxFKLaJy4izSmyFlpUQpsucNZzmgddmo2amylon7iINJva1TDpJJh6tp/URQEuzUhJlUIk5nTyExFputpVcO8o+PAZ2GZ/0NwT0szUnZ5CJBZXd7qINM3a5T7AF7wCI/8Ju5wYdkVSghTiKURjTvOmi8imcw4mj4EFr8Jxt/oZ2URyQCGeQiQWV3e6iGw6M9jvUtjjDNjxqLCrkRKmEE8hGne0qtIJCESkkVZ9DfP+47vOt/5O2NVIGVCIpxCNxams0aYRkUZY+RXcORy++QT67APtu4ddkZQBJVUKtTGnyV5EJHvLF8GE4bBsIZx8nwJc8kYhnkJUo9NFJFvLFsKdR/uW+KkPqBtd8kohnkI0ruPERSRLHz0Lq5bAaQ/BVkPCrkbKjEI8hUgsTpUOMRORTGJRqKiE3U6BfodA225hVyRlSM3NFPzc6do0IpLG4vfhhqHw6cv+sgJcQqKWeAr+OHG1xEUkhS/nwIQRgIOW7cOuRsqcmpsp+GlXtWlEJMkX78CdR4G1gHHTYfP+YVckZU5JlUI0rmlXRSTJkg/hjqOgsgbGT4du24VdkYi601OJ6ixmIpKs49aw68kw9Czo1DvsakQAhfhGnHNE4nGqtU9cRAAWvAYdekL7LeGw34ZdjcgG1NxMEos7nEMtcRGBj5/3g9geuzjsSkRSUlIlicYdgEani5S7D5+Ge06AjlvBUdeGXY1ISgrxJJFYHIAqzZ0uUr7efwruHQ1d+sK4x6Dd5mFXJJKS9oknicbUEhcpa/E4PHMVbLajn0q1deewKxJJSyGeJBIPWuLaJy5SfpyDFi3glClQUQ2tOoZdkUhGSqokkaAlrrOYiZSZmZPh/rEQi0DbzRTgUhQU4kmiwT5xnU9cpIz872548ExYvRRitWFXI5I1JVWSiPaJi5SX12+Dh8+DbfaHkydDdZuwKxLJmkI8SVT7xEXKx+u3waM/hH6HwkmToLp12BWJNIqSKkm0fp+4No1IydtiF9h5NJx4N1TVhF2NSKMpqZLUHSeu7nSRErbgVf+75+5w7D+hsjrcekQ2kUI8Sf3odA1sEyk9zsEzv4VbD/YTuogUOR0nniSqlrhIaXIO/vN/8MK1sOsp0HdY2BWJNJlCPEkkruPERUqOc/Dkz+Dl62H38XDkn/2kLiJFTq/iJHUtcQ1sEykhC171AT7kLH8yEwW4lAi1xJPUHyeuN7lI6eg1FE5/CrYaAqZeNikdSqok9WcxU3e6SHGLx/wx4B8/5y/3GqoAl5KjEE9SN9lLpbrTRYpXLAoPneUnc1n4WtjViORM1kllZo2ei9DMDjOzuWY2z8wuS7PM/mb2lpnNNrNnG7uO5ra+O13f2EWKUiwCD3wP3rkfhv0S9rk47IpEcqbBEDez75jZHODd4PIuZnZDFverAK4HDgf6AyeZWf+kZToCNwDDnXMDgBMa/QyaWd2MbdWVaomLFJ1oLdw/DuZMhUN+owCXkpdNUl0LHAosAXDOvQ3sm8X9hgDznHMfOedqgUnAiKRlTgYedM59Gjz2V9kWniv13elqiYsUnxaV0LI9HH4NfOf8sKsRybmsRqc75xbYhgNCYlncrQewIOHyQmBo0jLbAVVmNgNoB1znnJuQTU25UhvVPnGRolO7GtZ+C+27wzE3aACblI1sQnyBmX0HcGZWDVxI0LXegFTvIpdi/bsDw4BWwEtm9rJz7v0NHsjsTOBMgF69emWx6k0X1WQvIsVl3UqYOBqWfw7nvgSVLcOuSCRvsmlung2ch29ZLwR2Bc7N4n4Lga0SLvcEPk+xzBPOuVXOua+B54Bdkh/IOXeTc26wc25wt27dslj1pqufdlXHiYsUvrXL4e7jYP5/Yf+fKsCl7GSTVNs7505xzm3unNvMOXcqsGMW93sN6GdmfYIW/GhgWtIyDwP7mFmlmbXGd7dn08rPmfoToKglLlLY1nwLd42Ez16H42+DnUMfFyuSd9mE+N+yvG4DzrkocD7wJD6YJzvnZpvZ2WZ2drDMu8ATwEzgVeAW59ysbIvPhWg8TmULw7RPTaSwPfkzWPQ2jJoAA0aGXY1IKNLuEzezvYDvAN3M7EcJN7UHKrJ5cOfcdGB60nU3Jl2+Brgm24JzLRJzOoOZSDE45New8yjYZr+wKxEJTaaWeDXQFh/07RJ+lgPH5760cERicZ1LXKRQrfgSpl8K0XXQurMCXMpe2pa4c+5Z4Fkzu8M5Nz+PNYUqqpa4SGFa/jnceTQsXwS7nQJbbjQGVqTsZHOI2WozuwYYANTUXemcOzBnVYUoGo/rNKQihebbBT7AV30Npz2oABcJZJNW9wDvAX2A/wM+wY88L0mRmFOIixSSbz6BO46A1UthzFTotWfYFYkUjGzSqotz7lYg4px71jl3OlCy76JILK7udJFCsnY5WAWMfRh6Dg67GpGCkk13eiT4vcjMjsRP2NIzdyWFKxpzmjddpBCsWgJtusCWO8P5r0NFVrNEi5SVbFriV5lZB+Bi4MfALcBFuSwqTJGY9omLhO7LOXDDUHjpen9ZAS6SUoPvDOfco8Gfy4ADAMzsu7ksKkzRuPaJi4Rq0UyYMMJPodrvkLCrESlomSZ7qQBG4edMf8I5N8vMjgIux5+sZLf8lJhf2icuEqLP3vRTqVa3hbHToMu2YVckUtAytcRvxZ/A5FXgr2Y2H9gLuMw5NzUPtYVCk72IhGTNNz7AazrA2Eeg09ZhVyRS8DKF+GBgZ+dc3MxqgK+Bvs65L/JTWjiiMUd1pUJcJO9adYKjroWthkCHkh07K9KsMoV4rXMuDuCcW2tm75d6gANE4o7W2icukj8fPQuxCPQ7CAYeG3Y1IkUlU4jvYGYzg78N2Da4bIBzzu2c8+pCEI3FqdIhZiL5Me/fMOkU2Kw/bHsgaFeWSKNkCvFszhlecqKasU0kP+Y+AZNPg27bwylTFOAimyDTCVDK5qQniTQ6XSQP3n0E7h8PWwyEUx/0ZyQTkUbTDApJIjoBikjuffQsdN8NTp3iR6OLyCZRiCfRtKsiORRZA1Wt4PA/QHQNVLcJuyKRopZVk9PMWpnZ9rkuphBEYo5KtcRFmt+bd8H1Q2DZZ37/twJcpMkaTCszOxp4C3giuLyrmU3LcV2hicbjVGufuEjzeu1WmHY+dOmn/d8izSibJucVwBDgWwDn3FtA71wVFLZINK6WuEhzevlGeOxHsN1hMPpe350uIs0im7SKOueW5bySAhGJO41OF2kuMyfDEz+BHY6CUXdBVU3YFYmUlGwGts0ys5OBCjPrB1wIvJjbssIT1dzpIs1nu0Nh30thv0uhoirsakRKTjZpdQEwAFgH3Is/JelFOawpNPG4I+5QS1ykKZyD/93jR6LXdIADf6YAF8mRbFri2zvnfgb8LNfFhC0SjwPoOHGRTeUc/Of/4IVrYd1y2POcsCsSKWnZpNWfzew9M/u1mQ3IeUUhisQcAFVqiYs0nnPw5M98gA8+HYacFXZFIiWvwRB3zh0A7A8sBm4ys3fM7Oe5LiwM0ZhviVdqn7hI48TjMP0SePl6GHo2HPlnzYUukgdZvcucc1845/4KnI0/ZvyXuSwqLGqJi2yiFYtg9oPwnQvgsN+B6T0kkg8N7hM3sx2BE4HjgSXAJODiHNcVimiwT1zHiYtkKR73gd2hB5zzIrTdXAEukkfZDGy7HZgIHOKc+zzH9YQqWt8SV4iLNCgWhYfOgk5bw7BfQrstwq5IpOxks098T+fcdaUe4AC1sbrR6WpJiGQUrYUp42HWFGjZLuxqRMpW2pa4mU12zo0ys3cAl3gT4JxzO+e8ujyra4lrYJtIBtF1cP84mDsdDr0a9jov7IpEylam7vQfBL+PykchhSBSNzpdLXGR1JyDyWPh/cfhiD/CkO+HXZFIWUvb5HTOLQr+PNc5Nz/xBzg3P+XlVzSu0ekiGZnBTsfD0dcpwEUKQDb9xgenuO7w5i6kEERjmrFNJKV1K+Hj5/3fOx0Pu48LtRwR8dKmlZmdE+wP397MZib8fAzMzF+J+VOryV5ENrZ2Gdx9LNxzAqz8KuxqRCRBpn3i9wKPA78FLku4foVzbmlOqwpJVJO9iGxozTdw17HwxUw4/jZou1nYFYlIgkwh7pxzn5jZRkNPzaxzKQa5JnsRSbB6KUwYAYvf8+cC3+GIsCsSkSQNtcSPAt7AH2KW2Dx1wDY5rCsUkfpDzNQSF+F/d8HiuTB6IvQ7KOxqRCSFtCHunDsq+N0nf+WEq647vbpSLXERvnMh9DsUNtsh7EpEJI0G08rMvmtmbYK/TzWzP5tZr9yXln/1x4mrJS7lavnncMdRsORDfziZAlykoGXT5PwHsNrMdgEuBeYDd+W0qpBEdIiZlLNvP4XbD4fP34LVS8KuRkSykE1aRZ1zDhgBXOecuw4oycmS6yZ70YxtUnaWfgy3HwGrv4ExD8NWQ8KuSESykM1ZzFaY2U+B04B9zKwCqMptWeGI6jhxKUd1AR5dA2OnQfddw65IRLKUTVqdCKwDTnfOfQH0AK7JaVUhqRudXq3udCknbbpBj0Ew9lEFuEiRyeZUpF8A9wAdzOwoYK1zbkLOKwuBToAiZWXx+3461ZZtYfQ9sMXAsCsSkUbKZnT6KOBV4ARgFPCKmR2f68LCoH3iUjYWvQ23HQqPXhR2JSLSBNnsE/8ZsIdz7isAM+sG/BuYksvCwlA/Ol37xKWULXwD7h4JLdvDAZeHXY2INEE2adWiLsADS7K8X9GJxhwtDFroOHEpVZ++4qdSrekI46dD55KbeFGkrGTTEn/CzJ4EJgaXTwSm566k8ETicR0jLqUrFoWHz/UnMRn7CHToEXZFItJEDYa4c+4SMzsW2Bs/f/pNzrmHcl5ZCKIxpxCX0lVR6edBr2kP7bYIuxoRaQZpQ9zM+gF/BLYF3gF+7Jz7LF+FhSESi2tQm5SeD/4NnzwPB10B3bYLuxoRaUaZmp23AY8Cx+HPZPa3vFQUokjMaaIXKS1zH4dJJ8GH/4HaVWFXIyLNLFN3ejvn3M3B33PN7M18FBSmaCxOlVriUirmPAxTToctdobTHvTHg4tISckU4jVmthvrzyPeKvGyc67kQj0a1z5xKRHvTIEHz4Seg+GU+6GmQ9gViUgOZArxRcCfEy5/kXDZAQfmqqiwaJ+4lIzKltB7bz8TW8uSPF+RiJAhxJ1zB+SzkEIQicU10YsUt2/mQ6etYcejYYej/DnBRaRkKbESRGNOLXEpXq/eDH/bHT55wV9WgIuUPIV4gkjcUal94lKMXroBpv8Y+h4EPfcIuxoRyRMlVoJoLE6VplyVYvPCX+DJn8KOw2HUBL8/XETKQjZnMTMzO9XMfhlc7mVmQ3JfWv5pxjYpOh89C//+FQw8Do6/HSqrw65IRPIom8S6AdgLOCm4vAK4PmcVhahWo9Ol2PTZF467FY692U+rKiJlJZsQH+qcOw9YC+Cc+wYoya/7UZ0ARYqBc/DsH+Cr9/zgtZ2OhxYVYVclIiHIJrEiZlaBPza87nzi8ZxWFZJozFGpfeJSyJyDJ34Kz/wG3rk/7GpEJGTZhPhfgYeAzczsN8ALwNU5rSokkZha4lLA4nF47GJ45R+w57lw4M/DrkhEQpbNqUjvMbM3gGH4KVePcc69m/PKQuCnXVVLXApQPAaP/AD+dxd89yJ/RjIdBy5S9hoMcTPrBawGHkm8zjn3aS4LC0MkGtdx4lKYYrXwzSew309g/58qwEUEyCLEgcfw+8MNqAH6AHOBATmsKxQRtcSl0MQiEF3r5z8/9UEdQiYiG8imO32nxMtmNgg4K2cVhSgai+t84lI4orUwZTysWgzjHlOAi8hGGp1YwSlIS3JeR82dLgUjug4mnwbvPQoDRkJFVdgViUgBymaf+I8SLrYABgGLc1ZRiCLxONXaJy5hi6yBSafAh/+BI/8Ee5wRdkUiUqCySax2CT8t8fvIR2Tz4GZ2mJnNNbN5ZnZZhuX2MLOYmR2fzePmSkQtcSkEj/4QPnwahv9NAS4iGWVsiQeTvLR1zl3S2AcO7ns9cDCwEHjNzKY55+akWO73wJONXUdzcs4RizvtE5fw7XuJPxvZTqF+pxWRIpA2scys0jkXw3efb4ohwDzn3EfOuVpgEqlb8BcADwBfbeJ6mkUk5gA0Ol3CsXYZvPh3PyNbl20V4CKSlUwt8VfxAf6WmU0D7gdW1d3onHuwgcfuASxIuLwQGJq4gJn1AEYCBxLyYLlo3M8kq+PEJe/WfAN3HQtfzPQnNNly57ArEpEikc1x4p2BJfigrTte3AENhXiqJq1LuvwX4CfOuZhlmLzCzM4EzgTo1atXFiU33vqWuEJc8mjVErjrGFj8Hpx4twJcRBolU4hvFoxMn8X68K6THMapLAS2SrjcE/g8aZnBwKQgwLsCR5hZ1Dk3NXEh59xNwE0AgwcPzmbdjRaJ+Za4utMlb1YuhgkjYOmHMHoi9Dso7IpEpMhkCvEKoC3ZtahTeQ3oZ2Z9gM+A0cDJGzyIc33q/jazO4BHkwM8X6JBS1wD2yRvvpoNyxfCyffBNvuHXY2IFKFMIb7IOXflpj6wcy5qZufjR51XALc552ab2dnB7Tdu6mPnQl1LXIeYSc5F10FlSx/cF70DNR3CrkhEilSmEG9ymjnnpgPTk65LGd7OuXFNXV9TROManS558M18vw/8gJ/5EegKcBFpgkwhPixvVRSAaP0+cXWnS44s/QjuHA7rlkPnPg0vLyLSgLQh7pxbms9CwlZb152ufeKSC19/AHce7bvSxz4CW+4SdkUiUgKyOcSsLEQ12Yvkyqqv4fYjAAfjHoXNS+4sviISEoV4QJO9SM606Qp7nQfbHw7dtg+7GhEpIQrxQP1kLy3UEpdm8vlb0KICttgJ9r4o7GpEpASp2Rmo706v1CaRZrDwdT+IbdoFfj50EZEcUGIF6o8TV0tcmmr+SzDhGGjdCUZNgAxTCouINIVCPBDRIWbSHD5+Hu4+DtptDuMfh465metfRAS0T7xe3WQvmrFNmuTVf0LHrWDMNB/kIiI5pBAPRHScuDRFPA4tWsCxN0PtamjTJeyKRKQMKLECdQPbqtWdLo313mNw+2Gw5luoaqUAF5G8UWIFdAIU2SSzp8LkMRCPhl2JiJQhhXggon3i0lgz74cpp0OPwXDaVGjVMeyKRKTMKMQD9SdA0T5xycbsh+ChM2Hr78CpD0BN+7ArEpEypMQK1O0TV0tcstJ9EOxyEpw8GVq2DbsaESlTCvFAJK7jxCULHz7jR6J32hqOuQGqW4ddkYiUMSVWIBKtO4uZNomk8dL1cNcx8MbtYVciIgIoxOtF43HMoELTrkoqz/8Znrwc+o+AQWPCrkZEBNBkL/UiMadBbZLajN/DjKthpxPgmBuhQm8bESkMSq1ANBbXoDbZ2NKP4YU/wy4nw8h/KsBFpKDoEykQjTvtD5eNde4DZ/wHNuvvp1UVESkg+lQK1MbiVKklLuDP//34ZfDmXf7yFgMV4CJSkPTJFIjG4jr5ifjDxx79IbzyD1j8XtjViIhkpO70QDTmtE+83MVjMO1CeOtu2PuHMOxXYVckIpKRQjwQ0T7x8uYcTD0HZt4H+10G+18Gpi91IlLYFOKBqPaJlzcz6NoPDvw57HtJ2NWIiGRFIR6IaJ94eYrWwjcfQ7ftFd4iUnSUWoFIzKklXm4ia2HyaXDrIbB6adjViIg0mlrigWg8TqX2iZePyBqYdDJ8+DQcdS207hx2RSIijaYQD0RijkrNm14ealfBvSfCJy/AiOtht1PDrkhEZJOo6RnwA9u0OcrCf6+D+f/106gqwEWkiKklHtA+8TKyz8XQex/os0/YlYiINImanoFITPvES9rqpfDQ2f53ZUsFuIiUBKVWwJ8ARS3xkrTqa7hzOMx6AL54J+xqRESajbrTA5o7vUSt+BImjPDHgp80CbbZL+yKRESajUI8ENHc6aVn+SK482hY/hmcPFkBLiIlRyEeiMbjVGufeIlxUNUKTn0Atv5O2MWIiDQ7hXhALfESsuILaNMN2neHM5/VucBFpGTp0y2gudNLxJIP4eZh8MRl/rL+pyJSwtQSD0R1nHjxW/w+TBgOsVrY7bSwqxERyTmFeEBzpxe5L+f4UegAYx+FzfuHW4+ISB4oxAHnXDBjm0K8KEVrYeKJYC1g7CPQbbuwKxIRyQuFOH6iF4AqnQClOFVWwzE3QrstoMu2YVcjIpI3anri94cD6k4vNgtegzfu8H/3/q4CXETKjlILiMTjABrYVkzmvwR3HQP//as/N7iISBlSiJPQEld3enH4+Hm4+1hotyWMe8xP6CIiUoYU4vh50wGqKrU5Ct6HT8M9J0DHrWH8dGi/ZdgViYiERgPbgNq6ENfEIIVv8Vzo0hfGTIU2XcOuRkQkVApxEge2qTu9YK1dBjUdYM9zYPfxUFUTdkUiIqFT0xM/0QtodHrBmv0QXLcLLHrbX1aAi4gACnHAn/wEdJx4QZo5GaacDt12gE59wq5GRKSgKMRZ352uGdsKzP/ugQfPhK2/C6dMgZr2YVckIlJQlFqsH9imfeIF5MOn4eFzYZv94eTJ0LJt2BWJiBQcDWwj4RAztcQLR+994KArYOg52gcuIpKGUov1c6drspcC8OZdsPIrqKiCvX+oABcRyUAhDkRiGp1eEJ7/E0w7H166PuxKRESKgrrTWT+wrVohHg7n4Nnfw4zfwk6j4MBfhF2RiEhRUIiT2BJXd3reOQf/uRJe+DPsegoM/xu0qAi7KhGRoqCmJxCpO5+4Qjz/alfCe4/6WdiG/10BLiLSCGqJs350eqXmTs8f5yAeg5bt4HtPQU1HMH2JEhFpDKUWmjs97+JxePQieOB7PshbdVKAi4hsAoU4EAnmTtfAtjyIx/wI9DfugC7bgmmbi4hsKnWnA5GoDjHLi1gUpp4N79wP+18O+12qFriISBMoxEmY7EXd6bn16A98gA/7Fezzo7CrEREpegpxEs9ippZ4Tu02BjbfCfY8O+xKRERKglKLhNHpaok3v8hamDPN/91rqAJcRKQZKcRZf5y45k5vZrWrYeJomDwGvno37GpEREqOutPxM7ZVVRimQVbNZ91KH+CfvAAjrofNdgy7IhGRkqMQx3ena6KXZrR2OdxzAix8FY69GXY+IeyKRERKkkIcP7BN+8Ob0YdPw2dvwPG3wYCRYVcjIlKyctr8NLPDzGyumc0zs8tS3H6Kmc0Mfl40s11yWU860XicKh0j3nTOjy1gwDFwwesKcBGRHMtZcplZBXA9cDjQHzjJzPonLfYxsJ9zbmfg18BNuaonk2jM6eQnTbVyMdx6CMx/0V/u1DvUckREykEuu9OHAPOccx8BmNkkYAQwp24B59yLCcu/DPTMYT1p1WqfeNOs+BImDIdv5kN0bdjViIiUjVwmVw9gQcLlhcF16XwPeDyH9aSllngTLP8c7jgCvl0Ap9wP2x4YdkUiImUjly3xVKnoUi5odgA+xPdOc/uZwJkAvXr1aq766kXjcc2bvilWfgW3HwGrvoZTH4Ct9wq7IhGRspLL5FoIbJVwuSfwefJCZrYzcAswwjm3JNUDOeducs4Nds4N7tatW7MXGok5TfSyKVp3gW32h9MeUoCLiIQgly3x14B+ZtYH+AwYDZycuICZ9QIeBE5zzr2fw1oyisY0Or1RlnwIlTXQoQcc/ZewqxERKVs5C3HnXNTMzgeeBCqA25xzs83s7OD2G4FfAl2AG4LZ0qLOucG5qimdiPaJZ2/xXLhzuB99fvoTOpWoiEiIcjrZi3NuOjA96bobE/4+AzgjlzVkIxLTPvGsfDnHj0LHfAtcAS4iEiolF/584mqJN2DRTLjjSGhRCeOnay50EZECoBBHc6c3yDl48nKoag3jHoOu/cKuSERE0NzpgPaJN8gMTrgDaldBp63DrkZERAJqflJ3KlJtio3MfxEeOAOitdCmqwJcRKTAKLnw+8Q1sC3JRzPg7uNg0duwdlnY1YiISApKLoKWuCZ7WW/ev+HeE/1hZOMeg7bNP8GOiIg0nUIcP3e6ziceeP8pmHiSH7w29lFou1nYFYmISBoKcTR3+gbadIWtvwNjpkGbLmFXIyIiGSi5gNponOpyD/HFc/3vHoNgzMPQunO49YiISIPKPLm8aLzMT4Dy9n1ww54wc3LYlYiISCMoxKnbJ16mm+LNu+Chs6D33rDDkWFXIyIijVCmybWhSDxenpO9vHYrTDsftj0QTp4M1W3CrkhERBqh7EM8Fnc4R/lNu7p4Ljx2MWx3GIy+F6pahV2RiIg0UtlPuxqJxQGoqiyzlni37eHUKdB7X6isDrsaERHZBGXW/NxYfYiXS0v8hWvhw2f8330PUoCLiBSxMkmu9KIxB1D6k704B89cDf++AmY/FHY1IiLSDNSdHvct8ZIene6cD+///gV2OxWOujbsikREpBmUfYjXtcRLdu505+DJn8HL18Pg0+GIP0G57DoQESlxZf9pXh/ipdoSdw7WLYOhZ8ORf1aAi4iUkLJvidfG6rrTS6wlHo/D6iX+DGRH/w3M/I+IiJSMsm+WRYN94iXVEo/H4OHz4JZh/lzgLVoowEVESlAJJdemqR+dXir7xGNRePBMePteP4itpkPYFYmISI6UfXd6/XHipdASj9bCA9+Dd6fBQVfA3j8MuyIREcmhsg/xaLyEBrbNuNoH+KFXw17nhV2NiIjkWNmHeCRaQgPbvvsD2Hwg7HR82JWIiEgelEDzs2ki9S3xIg3x2tXw9FUQWQutOinARUTKSNmHeLTuELNiPH563Uq45wR4/k/w6YthVyMiInmm7vRinTt97TIf4Atfh2Nv9ucEFxGRslL2IV53nHh1MQ1sW/MN3HUsfDETTrgd+o8IuyIREQlB2Yd4JFaEJ0BZ8SUs/xxG3QU7HBF2NSIiEhKFeDFN9rJuJVS3gc12gAv/B9Wtw65IRERCVETNz9womhOgrPgCbj4Qnv+jv6wAFxEpe2XfEo/Gi+A48WWfwZ1H+yDvtVfY1YiISIEo+xCPFHpL/NtPfYCvWgKnPQi99gy7IhERKRAK8fq50wuwJR5Z6wN8zTcw5mHouXvYFYmISAEp+xAv6MleqmrggJ9D137QfdewqxERkQJT9iG+vju9gFriX70HyxZCv4Ng5xPCrkZERApU2Yd4NB6nooVhViAh/sUsmDDCjz4//3WobBl2RSIiUqAKsA85v6IxVzit8M/fgjuPgopqOPUhBbiIiGRU9iFeG4tTVQj7wxe+AROGQ3VbGP8YdO0bdkUiIlLg1J0ec4VxjPich/ypRMc+Ah17hV2NiIgUAYV4PB7uvOmxKFRUwkFXwnd/CG26hFeLiIgUlQLoRw5XJOaoCmve9I9mwA17wjefQIsWCnAREWmUsg/xaCyklvgH/4Z7T/SD2Kra5H/9IiJS9Mo+xCNhjE6f+zhMOslP4jL2EWjbLb/rFxGRkqAQj8XzO2/6RzPgvlNh84E+wNWFLiIim6jsQzwaz/Po9O6DYPdxMGaqH40uIiKyico+xCOxeH7mTf/gX1C7Gmraw5F/gpoOuV+niIiUtLIP8bzM2PbmXXDPCfD8H3O7HhERKStlH+I53yf+2i0w7XzoOwz2vSR36xERkbKjEI+73B1i9vI/4LGLYbvDYfS9UNUqN+sREZGyVPYhHo3FczPZy5pv4Pk/w47DYdQEncxERESanaZdzcXc6c75kedn/Ava94CKquZ9fBERERTiRJpz7nTn4JnfQKwWDvo/6NS7eR5XREQkhbLvTo/E4lQ3R4g7B//6JTx3Daxe6i+LiIjkUNm3xKMxR2VT94k7B0/8FF75Bwz+HhzxR39CExERkRwq+xCPxJphdPrjP4FX/wl7nguHXg1WAOcnFxGRklf2IR6Nx5s+2cvWe0F1Gxj2SwW4iIjkTdn3+fru9E3YDLEoLHzd/z1gJBz0KwW4iIjkVdmHeG0sTlVlI8M3FoGHzoTbDoUlH+amMBERkQaoOz0Wp6oxLfFoLTxwOrz7CBx8JXTZNnfFiYiIZFDWIR6PO+KO7Cd7ia6DyWPh/cfhsN/BnufktkAREZEMyjrEI/E4QPYnQHl7kg/wI/8Ee5yRw8pEREQaVtYhHo35CVmyPk580BjotgP0GprDqkRERLJT1gPbIrEsWuLrVvgu9K/n+dHnCnARESkQZR7iviWe9jjxtcvgrmP9ILav5uSxMhERkYaVd3d6sE885Yxta77xAf7FO3DCHdB/eH6LExERaUB5h3i6feKrl8KE4bB4Lpx4N2x/WAjViYiIZFbm3elp9olXVEPrrnDSRAW4iIgUrLJuia/fJx6E+Iov/BzoLdvBaQ9pGlURESloOW2Jm9lhZjbXzOaZ2WUpbjcz+2tw+0wzG5TLepLVtcQrKwyWLYTbD4cpp9cVl89SREREGi1nLXEzqwCuBw4GFgKvmdk051ziMO/DgX7Bz1DgH8HvvIjGfUu83ZrP4PbxfjDbyH/ma/UiIgUrEomwcOFC1q5dG3YpZaWmpoaePXtSVVWV1fK57E4fAsxzzn0EYGaTgBFAYoiPACY45xzwspl1NLMtnXOLclhXvWgsTi/7kkFP/xjiq2DMVOixez5WLSJS0BYuXEi7du3o3bs3pp7JvHDOsWTJEhYuXEifPn2yuk8uu9N7AAsSLi8MrmvsMjkTica5rup6KmJrYOwjCnARkcDatWvp0qWLAjyPzIwuXbo0qvcjlyGe6j/vNmEZzOxMM3vdzF5fvHhxsxQH0LplJTd3uZT5R98HW+7SbI8rIlIKFOD519htnssQXwhslXC5J/D5JiyDc+4m59xg59zgbt26NVuBu2zVkRt+cCJ9B2oqVRGRQvTQQw9hZrz33nv1182YMYOjjjpqg+XGjRvHlClTAL8//7LLLqNfv34MHDiQIUOG8Pjjjze5lt/+9rf07duX7bffnieffDLlMm+//TZ77bUXO+20E0cffTTLly+vv23mzJnstddeDBgwgJ122qlZxhvkMsRfA/qZWR8zqwZGA9OSlpkGjAlGqe8JLMvX/nARESl8EydOZO+992bSpElZ3+cXv/gFixYtYtasWcyaNYtHHnmEFStWNKmOOXPmMGnSJGbPns0TTzzBueeeSywW22i5M844g9/97ne88847jBw5kmuuuQaAaDTKqaeeyo033sjs2bOZMWNG1oPXMslZiDvnosD5wJPAu8Bk59xsMzvbzM4OFpsOfATMA24Gzs1VPSIiUlxWrlzJf//7X2699dasQ3z16tXcfPPN/O1vf6Nly5YAbL755owaNapJtTz88MOMHj2ali1b0qdPH/r27curr7660XJz585l3333BeDggw/mgQceAOCpp55i5513Zpdd/K7bLl26UFFR0aSaIMeTvTjnpuODOvG6GxP+dsB5uaxBRESa5v8emc2cz5c3vGAj9O/enl8dPSDjMlOnTuWwww5ju+22o3Pnzrz55psMGpR5OpF58+bRq1cv2rdv32ANP/zhD3nmmWc2un706NFcdtmGU5t89tln7LnnnvWXe/bsyWeffbbRfQcOHMi0adMYMWIE999/PwsW+LHb77//PmbGoYceyuLFixk9ejSXXnppgzU2pKxnbBMRkcI1ceJELrroIsAH68SJExk0aFDawV+NHRR27bXXZr2sb3M2vL7bbruNCy+8kCuvvJLhw4dTXV0N+O70F154gddee43WrVszbNgwdt99d4YNG9aompMpxEVEJKOGWsy5sGTJEp5++mlmzZqFmRGLxTAz/vCHP9ClSxe++eabDZZfunQpXbt2pW/fvnz66aesWLGCdu3aZVxHY1riPXv2rG9Vgz+Ovnv37hvdd4cdduCpp54CfOv7scceq7//fvvtR9euXQE44ogjePPNN5sc4mV9AhQRESlMU6ZMYcyYMcyfP59PPvmEBQsW0KdPH1544QX69evH559/zrvvvgvA/Pnzefvtt9l1111p3bo13/ve97jwwgupra0FYNGiRdx9990brePaa6/lrbfe2ugnOcABhg8fzqRJk1i3bh0ff/wxH3zwAUOGDNloua+++gqAeDzOVVddxdln+yFghx56KDNnzmT16tVEo1GeffZZ+vfv3+TtpBAXEZGCM3HiREaOHLnBdccddxz33nsvLVu25O6772b8+PHsuuuuHH/88dxyyy106NABgKuuuopu3brRv39/Bg4cyDHHHENTD08eMGAAo0aNon///hx22GFcf/319QPTzjjjDF5//fX6urfbbjt22GEHunfvzvjx4wHo1KkTP/rRj9hjjz3YddddGTRoEEceeWSTagKwVP38hWzw4MGubmOJiEhuvPvuu+y4445hl1GWUm17M3vDOTc4eVm1xEVERIqUQlxERKRIKcRFRESKlEJcRERSKrYxU6WgsdtcIS4iIhupqalhyZIlCvI8qjufeE1NTdb30WQvIiKykZ49e7Jw4UKa8/TP0rCamhp69uyZ9fIKcRER2UhVVRV9+vQJuwxpgLrTRUREipRCXEREpEgpxEVERIpU0U27amaLgfnN+JBdga+b8fHKlbZj02kbNp22YdNpGzZdLrbh1s65jSaAL7oQb25m9nqq+WilcbQdm07bsOm0DZtO27Dp8rkN1Z0uIiJSpBTiIiIiRUohDjeFXUCJ0HZsOm3DptM2bDptw6bL2zYs+33iIiIixUotcRERkSJVNiFuZoeZ2Vwzm2dml6W43czsr8HtM81sUBh1FrIstuEpwbabaWYvmtkuYdRZyBrahgnL7WFmMTM7Pp/1FYtstqOZ7W9mb5nZbDN7Nt81Fros3s8dzOwRM3s72Ibjw6izUJnZbWb2lZnNSnN7fjLFOVfyP0AF8CGwDVANvA30T1rmCOBxwIA9gVfCrruQfrLcht8BOgV/H65t2PhtmLDc08B04Piw6y60nyxfix2BOUCv4PJmYdddSD9ZbsPLgd8Hf3cDlgLVYddeKD/AvsAgYFaa2/OSKeXSEh8CzHPOfeScqwUmASOSlhkBTHDey0BHM9sy34UWsAa3oXPuRefcN8HFl4HsT8VTHrJ5HQJcADwAfJXP4opINtvxZOBB59ynAM45bcsNZbMNHdDOzAxoiw/xaH7LLFzOuefw2ySdvGRKuYR4D2BBwuWFwXWNXaacNXb7fA//LVTWa3AbmlkPYCRwYx7rKjbZvBa3AzqZ2Qwze8PMxuStuuKQzTb8O7Aj8DnwDvAD51w8P+WVhLxkSrmcitRSXJc8LD+bZcpZ1tvHzA7Ah/jeOa2o+GSzDf8C/MQ5F/MNIEkhm+1YCewODANaAS+Z2cvOufdzXVyRyGYbHgq8BRwIbAv8y8yed84tz3FtpSIvmVIuIb4Q2Crhck/8t8vGLlPOsto+ZrYzcAtwuHNuSZ5qKxbZbMPBwKQgwLsCR5hZ1Dk3NS8VFods389fO+dWAavM7DlgF0Ah7mWzDccDv3N+B+88M/sY2AF4NT8lFr28ZEq5dKe/BvQzsz5mVg2MBqYlLTMNGBOMKNwTWOacW5TvQgtYg9vQzHoBDwKnqcWTUoPb0DnXxznX2znXG5gCnKsA30g27+eHgX3MrNLMWgNDgXfzXGchy2YbforvycDMNge2Bz7Ka5XFLS+ZUhYtcedc1MzOB57Ej8q8zTk328zODm6/ET8S+AhgHrAa/y1UAlluw18CXYAbgpZk1OlECvWy3IbSgGy2o3PuXTN7ApgJxIFbnHMpDwUqR1m+Fn8N3GFm7+C7hn/inNPZzQJmNhHYH+hqZguBXwFVkN9M0YxtIiIiRapcutNFRERKjkJcRESkSCnERUREipRCXEREpEgpxEVERIqUQlwkBMEZyt5K+OmdYdmVzbC+O8zs42Bdb5rZXpvwGLeYWf/g78uTbnuxqTUGj1O3XWYFZ9Dq2MDyu5rZEc2xbpFipEPMREJgZiudc22be9kMj3EH8KhzboqZHQL80Tm3cxMer8k1NfS4ZnYn8L5z7jcZlh8HDHbOnd/ctYgUA7XERQqAmbU1s/8EreR3zGyjs5uZ2ZZm9lxCS3Wf4PpDzOyl4L73m1lD4foc0De474+Cx5plZhcF17Uxs8eC80jPMrMTg+tnmNlgM/sd0Cqo457gtpXB7/sSW8ZBD8BxZlZhZteY2Wvmz618Vhab5SWCE0aY2RDz56j/X/B7+2CmsSuBE4NaTgxqvy1Yz/9SbUeRUlIWM7aJFKBWZvZW8PfHwAnASOfccjPrCrxsZtPchl1lJwNPOud+Y2YVQOtg2Z8DBznnVpnZT4Af4cMtnaOBd8xsd/wsUkPxM3K9YmbP4s8x/blz7kgAM+uQeGfn3GVmdr5zbtcUjz0JOBGYHoTsMOAc/Alxljnn9jCzlsB/zewp59zHqQoMnt8w4NbgqveAfYOZxg4CrnbOHWdmvyShJW5mVwNPO+dOD7riXzWzfwdzqIuUHIW4SDjWJIagmVUBV5vZvvhpQnsAmwNfJNznNeC2YNmpzrm3zGw/oD8+FAGq8S3YVK4xs58Di/GhOgx4qC7gzOxBYB/gCeCPZvZ7fBf88414Xo8Dfw2C+jDgOefcmqALf2czOz5YrgPQD/8FJlHdl5vewBvAvxKWv9PM+uHPBFWVZv2HAMPN7MfB5RqgF5o3XUqUQlykMJwCdAN2d85FzOwTfADVc849F4T8kcBdZnYN8A3wL+fcSVms4xLn3JS6C0GLdiPOufeDVvoRwG+DFnOmln3ifdea2Qz8aSxPBCbWrQ64wDn3ZAMPscY5t2vQ+n8UOA/4K34e72eccyODQYAz0tzfgOOcc3OzqVek2GmfuEhh6AB8FQT4AcDWyQuY2dbBMjfju5kHAS8D3zWzun3crc1suyzX+RxwTHCfNsBI4Hkz6w6sds7dDfwxWE+ySNAjkMokfDf9PvgTbBD8PqfuPma2XbDOlJxzy4ALgR8H9+kAfBbcPC5h0RVAu4TLTwIXWNAtYWa7pVuHSClQiIsUhnuAwWb2Or5V/l6KZfYH3jKz/wHHAdc55xbjQ22imc3Eh/oO2azQOfcmcAf+/NCv4M/09T9gJ/y+5LeAnwFXpbj7TcDMuoFtSZ4C9gX+7ZyrDa67BZgDvGlms4B/0kBPYFDL2/jTZP4B3yvwX/xZt+o8A/SvG9iGb7FXBbXNCi6LlCwdYiYiIlKk1BIXEREpUgpxERGRIqUQFxERKVIKcRERkSKlEBcRESlSCnEREZEipRAXEREpUgpxERGRIvX/4qptSe8dK5EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_test_pred)\n",
    "auc_sc = auc(fpr, tpr)\n",
    "# Draw ROC curve:\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, label=\"AUC = %0.2f\"%auc_sc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Receiver Operating Characteristic(ROC) for Support Vector Machine\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221105527638191\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  0.9067545349181962\n",
      "Test ROC_AUC:  0.9477513227513227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#KNN is more sensititve to noise\n",
    "transformer = RobustScaler().fit(X)\n",
    "X_scaled=transformer.transform(X)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=random)\n",
    "#scaling didn't help*****************************\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_train_pred=knn.predict(X_train_scaled)\n",
    "y_test_pred=knn.predict(X_test_scaled)\n",
    "print(knn.score(X_train_scaled, y_train))\n",
    "print(knn.score(X_test_scaled, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=21, p=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9708566137566137"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'n_neighbors': np.arange(1,40),\n",
    "            'p':[1,2]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(knn, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.008267</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 21, 'p': 1}</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.970857</td>\n",
       "      <td>0.030315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.006967</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 20, 'p': 1}</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.970729</td>\n",
       "      <td>0.030571</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 19, 'p': 1}</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.970589</td>\n",
       "      <td>0.030254</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 22, 'p': 1}</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.970053</td>\n",
       "      <td>0.030255</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.007468</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 24, 'p': 1}</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.969385</td>\n",
       "      <td>0.031476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 23, 'p': 1}</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.969299</td>\n",
       "      <td>0.030338</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 25, 'p': 1}</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.968854</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 26, 'p': 1}</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.861429</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.968135</td>\n",
       "      <td>0.032153</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 29, 'p': 1}</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.967857</td>\n",
       "      <td>0.032761</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 17, 'p': 1}</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.967585</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "40       0.007228      0.004328         0.008267        0.003864   \n",
       "38       0.006967      0.001196         0.009110        0.001402   \n",
       "36       0.009134      0.001118         0.010868        0.000957   \n",
       "42       0.006667      0.001135         0.008301        0.001574   \n",
       "46       0.007468      0.002077         0.009535        0.001978   \n",
       "44       0.004934      0.001031         0.006472        0.001334   \n",
       "48       0.007168      0.002117         0.008168        0.001753   \n",
       "50       0.004867      0.000922         0.006133        0.001056   \n",
       "56       0.005702      0.001451         0.007341        0.001870   \n",
       "32       0.007374      0.001232         0.009284        0.001270   \n",
       "\n",
       "   param_n_neighbors param_p                       params  split0_test_score  \\\n",
       "40                21       1  {'n_neighbors': 21, 'p': 1}           0.978667   \n",
       "38                20       1  {'n_neighbors': 20, 'p': 1}           0.978667   \n",
       "36                19       1  {'n_neighbors': 19, 'p': 1}           0.978667   \n",
       "42                22       1  {'n_neighbors': 22, 'p': 1}           0.978667   \n",
       "46                24       1  {'n_neighbors': 24, 'p': 1}           0.974667   \n",
       "44                23       1  {'n_neighbors': 23, 'p': 1}           0.974667   \n",
       "48                25       1  {'n_neighbors': 25, 'p': 1}           0.969333   \n",
       "50                26       1  {'n_neighbors': 26, 'p': 1}           0.968000   \n",
       "56                29       1  {'n_neighbors': 29, 'p': 1}           0.970667   \n",
       "32                17       1  {'n_neighbors': 17, 'p': 1}           0.981333   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  split23_test_score  \\\n",
       "40           0.996000           0.992000  ...            0.965333   \n",
       "38           0.993333           0.989333  ...            0.941333   \n",
       "36           0.994667           0.993333  ...            0.941333   \n",
       "42           0.996000           0.992000  ...            0.961333   \n",
       "46           0.997333           0.993333  ...            0.958667   \n",
       "44           0.994667           0.990667  ...            0.960000   \n",
       "48           0.997333           0.992000  ...            0.958667   \n",
       "50           0.998667           0.993333  ...            0.958667   \n",
       "56           1.000000           0.990667  ...            0.952000   \n",
       "32           0.994667           0.993333  ...            0.941333   \n",
       "\n",
       "    split24_test_score  split25_test_score  split26_test_score  \\\n",
       "40            0.977333            0.980000            0.993333   \n",
       "38            0.976000            0.985333            0.997333   \n",
       "36            0.977333            0.986667            0.992000   \n",
       "42            0.974667            0.977333            0.993333   \n",
       "46            0.973333            0.976000            0.993333   \n",
       "44            0.973333            0.977333            0.990667   \n",
       "48            0.973333            0.973333            0.994667   \n",
       "50            0.969333            0.972000            0.994667   \n",
       "56            0.969333            0.970667            0.993333   \n",
       "32            0.981333            0.985333            0.989333   \n",
       "\n",
       "    split27_test_score  split28_test_score  split29_test_score  \\\n",
       "40            0.996000            0.868571            0.972222   \n",
       "38            0.997333            0.868571            0.972222   \n",
       "36            0.997333            0.874286            0.972222   \n",
       "42            0.994667            0.868571            0.972222   \n",
       "46            0.994667            0.862857            0.986111   \n",
       "44            0.994667            0.868571            0.972222   \n",
       "48            0.994667            0.862857            0.986111   \n",
       "50            0.994667            0.861429            0.986111   \n",
       "56            0.994667            0.858571            0.986111   \n",
       "32            0.997333            0.880000            0.972222   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "40         0.970857        0.030315                1  \n",
       "38         0.970729        0.030571                2  \n",
       "36         0.970589        0.030254                3  \n",
       "42         0.970053        0.030255                4  \n",
       "46         0.969385        0.031476                5  \n",
       "44         0.969299        0.030338                6  \n",
       "48         0.968854        0.031651                7  \n",
       "50         0.968135        0.032153                8  \n",
       "56         0.967857        0.032761                9  \n",
       "32         0.967585        0.032415               10  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914572864321608\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  0.895339748254764\n",
      "Test ROC_AUC:  0.9477513227513227\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=21, p=1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_train_pred=knn.predict(X_train_scaled)\n",
    "y_test_pred=knn.predict(X_test_scaled)\n",
    "print(knn.score(X_train_scaled, y_train))\n",
    "print(knn.score(X_test_scaled, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914572864321608\n",
      "0.9649122807017544\n",
      "Training ROC_AUC:  0.895339748254764\n",
      "Test ROC_AUC:  0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=17, p=1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_train_pred=knn.predict(X_train_scaled)\n",
    "y_test_pred=knn.predict(X_test_scaled)\n",
    "print(knn.score(X_train_scaled, y_train))\n",
    "print(knn.score(X_test_scaled, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'False Positive Rate')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHwCAYAAAC2blbYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABUmElEQVR4nO3dd5hU1f3H8feXLSy9WwARFCyADRE0sWMvIBbERjHGrjExGmOaP2NMMYkxicbYxQIiKqJiSaJYYtcoAopiQVBUBKXDTjm/P87dZRhmZmfZnblTPq/n2Wd3Zu7M/c7dmfnMOffcc805h4iIiBSfFmEXICIiIptGIS4iIlKkFOIiIiJFSiEuIiJSpBTiIiIiRUohLiIiUqQU4iExs9lmtn/YdRQKM7vczG4Jad13mNlVYay7uZnZKWb21CbeN+vXpJlNNLNjNmU9m8rMhpvZpAaW2d7M/mdmK8zswnzVJsXFzD4xs4PS3LaPmc3Nd02bSiFO/T90jZmtNLMvgg/1trlcp3NugHNuRi7XUcfMWprZb83s0+B5fmBml5iZ5WP9KerZ38wWJl7nnLvaOXdGjtZnZnahmc0ys1VmttDM7jeznXKxvk1lZleY2d1NeQzn3D3OuUOyWNdGX1yyfU2a2c7ALsDDweVxZhYL3j/LzextMzsq6T5ZvQbN7FAzey4I4cVm9qyZDQ/qmwYMDNafzqXADOdcO+fcXxt6Llk8145mdlvwubDCzN43s5809XFzoYFg6mFmUTPbNsVtD5nZH5uwXmdmfTf1/iker3fwmG8mXd/VzGrN7JPmWlcqzrnnnXPb53IdzUkhvt7Rzrm2wK7AbsBPwy2n8cysMs1N9wPDgCOAdsBpwJnAdTmowcys0F5X1wE/AC4EOgPbAVOBI5t7RRn+BzmXx3WfBdzjNpwp6qXg/dMRuAGYZGYdE25v8DVoZscHy00AegKbA78Ejk54nInB/dLZGpi9KU8qzfa7FmgL7Ah0AIYDH27K4+dKNv9359xnwH/w2z3xvp3x/5M7c1NdZg3U3sbMBiZcPhn4OMclFR/nXNn/AJ8AByVc/gPwWMLlPYEXgW+Bt4H9E27rDNwOfA58A0xNuO0o4K3gfi8COyevE+gOrAE6J9y2G/A1UBVcPh14N3j8J4GtE5Z1wHnAB8DHKZ7bMGAtsFXS9UOBGNA3uDwD+C3wKrAM38rqnOU2mAH8Bvhv8Fz6AuODmlcAHwFnBcu2CZaJAyuDn+7AFcDdwTK9g+c1Fvg02BY/S1hfK/yHzjfBOi4FFqb53/YLnueQDP//O4DrgceCel8Btk24/TpgAbAceAPYJ+G2K4ApwN3B7WcAQ4CXgm21CPg7UJ1wnwHAv4ClwJfA5cBhQC0QCbbJ28GyHYBbg8f5DLgKqAhuGxds82uDx7oquO6F4HYLbvsq+J/OBAbiQzASrG8l8Ejy+wCoCOr6MNgmbxC8hoL/594Jz6d+ncHl1sH/b49sX4NBrZ8ClzTwXv0uKV7nwW1PB4+3Nnhe2wXbbwKwGJgP/BxokW77pXjMWcAxadbXO3ielUnvhTOSHv9vwfZ/DxiWtGym99xw/BeSb4Nld0z6/PhJ8D9dh/9yE8e/t1YCl6ao92Tgw6TrzgXeDP7uDjwQbKuPgQsTlkv5egCeC7bBqmC9JwbLfx+YF2zXaUD3Rnxm1W3XnwPXJFz/OvAz4JOE6y5LqGkOMDLpsb7P+s+hOcCghO3342D7LQPuA2qC2/Yn4fMk07INfc7n4yeU0Cy0Hzb88OoJvANcF1zuASzBf1ttARwcXO4W3P5Y8E/tBFQB+wXXD8J/eA4N3gBjg/W0TLHOp4HvJ9RzDXBj8PcxwZthR6AyeGG/mPSG+Bf+y0SrFM/td8CzaZ73fNaH6wx8SAzEB+0DrA/VhrbBDPwH8ICgxip8K3db/IfzfsDqhDfQBm+S4Lor2DjEb8YH9i74D6odE59TsM17Bm+udCF+NjC/gf//HfgPmyFB/fcAkxJuPxXoEtx2MfAF69/wV+AD8Zhg27QCdsd/6akMnsu7wEXB8u3wgXwxUBNcHpq8DRLWPRX4Z/A/2Qz/gV/3PxsHRIELgnW1YsMQPxT/Ydsx+D/sCGyZ8JyvSlrXJ6x/TV6Cfx9sH9x3l2AbtAn+N90S7pe4zgr8B3QtsFm2r0Fgh+Bx+zTwv+ocLNc+ze0zCEI0uDwBH47tgv/F+8D30m2/FI93Cz5IxwP9km7rTcMhHgV+iH9PnIgPgc5ZvOe2wwfjwcF9L8V/DlQn/K/ewgdpq+T/X5pt0ypYf+IXsJeAi/Cv3TfwPR/VwDb4L2uHZno9JHwG9U14zAPxX7wHAS3xX2Kea8RnVt127Y3/8lyBf+3OxTd8PklY9gT8l48WwfZdxfrX+AnB9t0jqLkvQQMo2FavBvftjH+Pnp3q86mBZTN+zufjJ/QALYSfYKOvxH9bc/hup47BbT8B7kpa/sngn7Ul/ttvpxSP+Q/g10nXzWV9yNe/4fCtt6eDvy144e4bXH6c4EMnuNwCH4h1L0YHHJjhud1CQiAl3fYyQQsX/4Hyu4Tb+uM/iCsybYOE+17ZwDaeCvwg+HuDN0lw3RVsHOI9E25/FRgd/F3/4ZKw/dKF+M+Alxuo7Q7gloTLRwDvZVj+G2CXhLqfa+DxLwIeCv4+CfhfmuXqt0FweXP8l5dWCdedBDwT/D0O+DTpMcaxPlAPxIfWngStz6TnnCnE5wIjUtTYI/jf1CStM4pviUTwrcFRjXkN4lvYGzxumuWrguV6pbl9ButDtCLYfv0Tbj8Lv8885fZL8Xit8C3QN4LnNg84POl1minEPwcs6XV8WhbvuV8AkxNua4EPpP0T/lenp/v/ZXg+twA3BX/3C9a3GT6Ekl9LPwVuz/R6CG5LDvFbgT8kXG4bbLveCctn+syq367Av/FfRn8XvE42CPEU932rrk78Z9QP0iz3CXBqwuU/sL7htD8bh3i6ZTN+zufjp9D2XYbpGOdcO/w/cAega3D91sAJZvZt3Q+wNz7AtwKWOue+SfF4WwMXJ91vK/y3uWRTgL3MrDuwL/4F/HzC41yX8BhL8UHfI+H+CzI8r6+DWlPZMrg91ePMx39gdiXzNkhZg5kdbmYvm9nSYPkjWL9Ns/VFwt+r8R8G4Ldh4voyPf8lpH/+2awLM7vYzN41s2XBc+nAhs8l+blvZ2aPBoOhlgNXJyy/FdnvU90a/z9YlLDd/4n/0E257kTOuafxXfnXA1+a2U1m1j7Ldaer89vgd7uk6192znXE945MA/ZJuC2b1+CShMuZ1K3320wLBbriW5XzE66bT/bvHZxza5wfdLk7vidiMnB/sC85G5+54JM9Yf2JnwHp3nPdE+t2zsWDZbOuPY07gVFmVoPfP/6Ec+4r/Gute9J7/HL8F0lo3Os2ufaV+P/vptQ+Af9l6CT8LqsNmNkYM3sroeaBZP9eS/ueb8SyjfmczwmFeBLn3LP4VkrdaM0F+FZox4SfNs653wW3dU4awEPC/X6TdL/WzrmJKdb5LfAUMAq/32piwht/Ab77NPFxWjnnXkx8iAxP6d/AUDPbKvFKMxuCf7E9nXB14jK98N+ev25gG2xUg5m1xHcN/hHYPPhwn47/8tFQvdlYhO9GT1V3sv8APc1s8KasyMz2wfdEjML3uHTEd0kmjqpOfj7/wO//7Oeca4//MKxbfgF+N0MqyY+zAN+S7Jqw3ds75wZkuM+GD+jcX4MAGoDvor0km/ulq9M5twr/wbhdmvWtxO9nPc3MdguuzuY1ODdY53EN1LUjviW2vIHlwL92I/gP2jq98C3a+pKzeBy/oF/n1fiu7z74rlvwYwDqbJF0tx5JI/B74VvnddK95z5PrDt4jK0aqL3B5+Kcex4fqCPwu4kmBDctwO+fTnyPt3POHZFwe7rXbbLk2tvgvwBtynZ/AL9r7iPnXOKXMcxsa/wut/PxXfsd8WMYsnmvNZesP+dzRSGe2l+Ag81sV/y3v6ODQ18qzKzG/CFSPZ1zi/Dd3TeYWSczqzKzfYPHuBk428yGBiO225jZkWaW3IKpcy8wBv8hdm/C9TcCPzWzAQBm1sHMTsj2iTjn/o0PsgfMbEDwHPbE7/f9h3Pug4TFTzWz/mbWGrgSmOKci2XaBmlWW43fF7YYiJrZ4UDiYU9fAl3MrEO2zyPJZPw26WRmPfBv4pSC53cDMDGouTqof7SZXZbFutrhu4oXA5Vm9kugodZsO/wgt5VmtgNwTsJtjwJbmNlF5g+7amdmQ4PbvgR6143uD15fTwF/MrP2ZtbCzLY1s/2yqBsz2yN4/VXhA2ctfuBX3bq2yXD3W4Bfm1m/4PW7s5l1CW6bjh/nkJJzbklw/18Glxt8DQZfWn8E/MLMxic8373N7KaEh98P/55rUPDanQz8JtjOWwfryPowPjP7RbAdq4PW6w/wvQBznXOL8cF0avCcTmfj0NgMuDD4bDgB/yVkesLt6d5zk4EjzWxY8P+7GP+F7kXSa+h/WmcC8Hv8WIlHguteBZab2U/MrFXwfAaa2R7B7ZleD8nrvRcYb2a7Bl/orwZecc59kkVtGwi+NB6I32WWrG58xmIAMxuPb4nXuQX4sZntHtTcN3gNNKfGfs43O4V4CsGbcwLwC+fcAvy31svxL5YF+NZM3bY7Df/t+T38AIeLgsd4HT8y8u/4fajz8N1C6UzD76P60jn3dkItD+HfcJPMd83OAg5v5FM6DngGeAK/7/9u/H6rC5KWuwvfC/EFftDVhUENDW2DDTjnVgT3nYx/7icHz6/u9vfwo2k/Mt8F1diupyuBhfgRtP/G745Yl2H5C1nfrfwtviU5kvUfYJk8iQ+N9/FdhGtpuCvwx/jnvAL/Jr+v7oZg2xyMP2zqC/wI3QOCm+8Pfi+x9cfIjsF/KZqD35ZTyG73APgvGzcH95uPb4HV9TDdCvQPtv/UFPf9M/7/9xT+C8mt+P3DADcBpyS1MJP9BTjC1h/T3eBr0Dk3BT846XR8a+5L/Ij7hxMe9yT8LoVsXYD/AvMR8AI+YG5rxP0d/uiTutbxwcCRQY8D+Pf4JfhtO4CNQ/YV/Pv6a/wRHMcHX3LqpHvPzcW3lP8W3Pdo/GGwtRlq/S3w8+B/+uMMy03At/rvc86tC9YXC9axK/599TU+BOu+aGd6PVwB3Bmsd5Rz7j/4ffoP4HvNtgVGZ6gnI+fc6865jbrFnXNzgD/hB+d9CeyEPxqg7vb78dv8Xvx7cSp+YFqz2YTP+WZnG+6ukXJlZjPwg6pCmTWtKczsHPygt6xaqNJ0ZnYvfuDV1Dyu82j8oLBR+VpnU5jZOPwgt73T3D6DIn3PSeEIbWIKkU1lZlviu+9ewrdyLsZ/E5Y8cc6dHMI6HyG73hORsqEQl2JUje9S7YPvHp+E3+8tIlJW1J0uIiJSpDSwTUREpEgpxEVERIpU0e0T79q1q+vdu3fYZYiIiOTNG2+88bVzrlvy9UUX4r179+b1118PuwwREZG8MbP5qa5Xd7qIiEiRUoiLiIgUKYW4iIhIkVKIi4iIFCmFuIiISJFSiIuIiBQphbiIiEiRUoiLiIgUKYW4iIhIkVKIi4iIFCmFuIiISJFSiIuIiBQphbiIiEiRUoiLiIgUqZyFuJndZmZfmdmsNLebmf3VzOaZ2UwzG5SrWkREREpRLlvidwCHZbj9cKBf8HMm8I8c1iIiIlJychbizrnngKUZFhkBTHDey0BHM9syV/WIiIjkWiQWZ+mqWpxzeVlfZV7WkloPYEHC5YXBdYvCKUdERMpdLO5YsTbC8jVRlq+NsGxNhOVrIixPuM5fjm5024q16zg/fi+PxvZk8hVn06Zl7iM2zBC3FNel/OpiZmfiu9zp1atXLmsSEZEiFo87VqyLbhCuy+r/9uG7QSgn3bZyXTTj47cwaN+qivY1VbRvVUn7miq26dqW9q0qOeTb+zho4SPstV0PWliqiGt+YYb4QmCrhMs9gc9TLeicuwm4CWDw4MH56aMQEZG8c86xcl10fdimafWuD94IyxLCeOW6KJl6ss2gXcvKDYK4V+fWG1zuUP93Fe1rgmWDv9u2rMTSBfSaXvBOH3bd4wy/ojwIM8SnAeeb2SRgKLDMOaeudBGRIuacY3VtLHXYrk7REl4bSei2jrJibYR4A021ti0rNwjXHh1bseOW7TYI3g71wbu+xdy+VRVtW1ZS0aIZAzYWhZevhyFnQatOMOT7zffYWchZiJvZRGB/oKuZLQR+BVQBOOduBKYDRwDzgNXA+FzVIiIi2XHOsTYS3yB8N94/nCKI1wS3r40SayCFW1dXbNDq3bxdDf02a7c+mFO2iP11bVtWUllRIFOcxCLwwBkwZyp02AoGHpv3EnIW4s65kxq43QHn5Wr9IiLlam0kVUs4mtD9vPFtKxJCuTYWz/j4NVUtNmj1dmlTTZ+ubTZq9bavqQpaxOuva1dTSVWhhHBTRNfB/eNh7mNwyG9CCXAItztdRERSqI3G0w/ESmr1Jg/MWr4mwrpo5hCurmgRdEVX1gdtr86tN2oJ1wVvh4R9w+1qKmlZWZGnLVGgImth8mnwwVNw+DUw9MzQSlGIi4g0s2gszoq1iaOio43qnl4TiWV8/MoWlrDP14dr9w6tNgjmDQZlJbWIa6rKPISbatlC+OxNOOovMDjcPcEKcRGRJLG4Y+Xaho8TXt8i3vC2VbWZQ7iihW3U6t2sXVsftq2rGmgRV1FT1SL9CGnJneg6qKiGrn3hgjegVcewK1KIi0jpiccdK2vrDlHKfJxw4m0rgttWNHCssBkbBmxNFb27tk7Z/VzfKk7oum5dXaEQLjZrl8M9J8C2B8D+lxVEgINCXEQKkHOOVbWxjcM27XHCG163ooFjhQHa1WzY7bxV59YbBHNyd3X9ba2qaFtdSYvmPExJCtuab+Hu42DRW7Dn2WFXswGFuIg0O+ccayKx9GGb4TjhuuUbOla4TXXFBscCd+9Yww417VJM0JEUzDVVtK1p5mOFpXStXgp3HQNfzoFRE2CHI8OuaAMKcRHZiHOOddH4hjNi1YVxliOmow2kcKuqig2OBd6sXQ19u228LzjVpB3tagroWGEpXbGoD/Cv3oPR98J2h4Rd0UYU4iIlal00uSWc+Tjh5PmkGzpWuGVliw1mx+rUppqtu7TZ6DjhVNNYtquporpSISwFrqIS9jof2nSFbQ8Mu5qUFOIiBSoSi2fR6k0/YrqhY4WrKqw+XNsFg7F6dmqVclR08jSW7WoqdZiSlK7ln8NX70LfYbDzqLCryUghLpIjdccKb8pxwsvXRljdwGFKlS1so4FXW3ZolfY44eQWcctKHaYkspFvF8CdR8O65fCDmdCybdgVZaQQF0kj8ZSGmVq96Y4h3tRTGiZPU5luGstWVTpMSaRZLf0Y7hwOa5fBaQ8WfICDQlxKWDzuWFXrT2noz56UvtWbqkXc1FMabhTGCSOmO7Sqoo2OFRYpHEs+9C3wyGoY+zB03y3sirKiEJeClXxKww2PE84wacfa7E9pWBfC7YKATT6l4caTdiScyKGljhUWKRlvT4ToWhj7CGyxU9jVZE0hLjmT6pSGDY2KTp5ZK5tTGnZICNgt2tew3ebrT2nYIeUgrQI8paGIhMM53622/+Ww+3jo0CPsihpFIS4ZpTql4cZnT0q/nzgSyxzCdac0rBv53LVtNdt02/CUhqmOEy6pUxqKSDgWvQ0Pn+cncem8TdEFOCjES166UxpmbhGvn9yjthGnNOzQqoqOaU5pmHycsE5pKCKh+uwNuGskVLejwTl6C5hCvMBF6g5TauRxwnVBvTaSOYRTntKwY6sGjxPWKQ1FpGgteNXPhd6qk98H3mnrsCvaZArxHIvFHSs28TjhTT2l4ebt22Z1nLBOaSgiZeezN30LvO3mMHYadOgZdkVNohBvQOKxwo05n3BTT2mYqvs58bjhutt1SkMRkUbo2g92PBqG/Qrabxl2NU2mEM/gykfmcPuLH2/yKQ3THiec0Cpuo1Maiojk3qevwBYDoWU7GHlj2NU0G4V4Bu989i09O7Vi7F69dUpDEZFiNfcJmHwaDBoLR/4x7GqalUI8g0jM0btLG87YZ5uwSxERkU3x7iNw/3jfCj/g8rCraXY6yDaDaDxOtY5DFhEpTrMehMljofuuMOZhaN057IqanRIqg2jMUVmhrnIRkaJTuxqevBy2GgqnPQQ1HcKuKCfUnZ5BJBbXtJwiIsWoujWMfdSPQK9uE3Y1OaOEyiASc1Rp0JqISPF47VZ46hd+FraufUs6wEEhnlFULXERkeLx8o3w2I/g6/chnnmOjlKhhMogEnc6wYaISDH471/hiZ/ADkfBqLugoirsivJCCZVBNBanSgPbREQK2/N/hn/9AgYcCyfcAZXVYVeUNwrxDKIxR2ULbSIRkYLWuQ/segoce3PZtMDraHR6BrVqiYuIFCbn4MvZfhKXASP9TxlSMzODaFzHiYuIFBzn/DHgN+0Hi94Ou5pQqSWehnOOWFzd6SIiBSUeh8cvgddugaFnwxY7h11RqBTiaURi/tRl1ZUKcRGRghCPw6M/gDcnwHcuhIOv9OdzLmMK8TSi8TgAlZrsRUSkMMyZ6gN830vggJ+VfYCDQjytSNS3xDXZi4hIgRgwEmraQ9+Dwq6kYCih0ogELXGNThcRCVEsAo/+EL7+wLe8FeAbUEs8jWiwT1wD20REQhJdB/ePg7nT/QC2rv3CrqjgKMTTiMTUEhcRCU1kDdx3Gsz7FxzxRxg8PuyKCpJCPI1o3LfENXe6iEie1a6GSSfBR8/C0X+F3ceGXVHBUoinUdcS12QvIiL55iAeg2P+AbueFHYxBU0hnkZ9iGufuIhIfqxd7gevtWwHY6aBPn8bpC2URt3ANu0TFxHJgzXfwF3HwKST/bSqCvCsaCulEa0/xEybSEQkp1YvhTuHwxfvwNBzNIlLI6g7PY26aVe1T1xEJIdWLoYJI2DJPBg9EfrpOPDGUIinsf4QM7XERURy5qEzYelHcPJ9sO0BYVdTdBTiaayf7EUtcRGRnDnij7DiC+j93bArKUpqZqahlriISI58+yk8+wc/gK3LtgrwJlBLPA1N9iIikgNLP4Y7j/aHk+18InTaOuyKippCPA1N9iIi0sy+nucDPLoGxk5TgDcDhXgadaPTq3SsoohI0331HkwY7mdiG/sobDEw7IpKgkI8jaha4iIizefbT6FFlZ+JbbMdwq6mZCjE04jEdZy4iEiTrV0ONe1hu0PggjegqibsikqK+orTqGuJV2tgm4jIpln4Bly3C7z7iL+sAG92Sqg06o8TV4iLiDTep6/4mdhatoMtdwm7mpKlhEqjtv4sZupOFxFplE/+C3eNhLabwfjHoWOvsCsqWQrxNNafxUybSEQka0s/hruPgw49Yfx06NAj7IpKmga2pRGNxzGDCrXERUSy16k3HPQrGHg8tO0WdjUlT83MNCIxp1a4iEi25j4BX872pxHd8xwFeJ4opdKIxuJUqRUuItKwOQ/DfafAf64Mu5KyoxBPIxKLa2S6iEhD3pkC94+HHrvDsTeFXU3ZUUqlEYk7qjTRi4hIem9NhAe/D732hFMfgJoOYVdUdjSwLY1oLE6l5k0XEUnNOXjnfui9D5w0EarbhF1RWVKIpxGNOaoq1RIXEdlILAIVVXDi3X4gW1WrsCsqW2pqphGJO53BTEQk2cv/gNsO83OiV7dWgIdMKZVGJBrXyU9ERBK98Bd44jJo3x0qNQ96IVB3ehrRuPaJi4jUe/YP8MxvYOBxMPImqFB8FAKlVBp+she1xEVEeOl6H+A7j4Zjb1aAFxD9J9KIxuOasU1EBGCHI2HVYjjwF9CiIuxqJIFSKo1IzGmfuIiUL+dg1gMQjwfzoV+hAC9AOQ1xMzvMzOaa2TwzuyzF7R3M7BEze9vMZpvZ+FzW0xiRmFriIlKm4nF47GKYcjq890jY1UgGOUspM6sArgcOB/oDJ5lZ/6TFzgPmOOd2AfYH/mRm1bmqqTGiMadziYtI+YnH4JEL4fVb4bsXwY7Dw65IMshlU3MIMM8595FzrhaYBIxIWsYB7czMgLbAUiCaw5qyprnTRaTsxKIw9Vz4312w76W+C93UmClkuRzY1gNYkHB5ITA0aZm/A9OAz4F2wInOuXgOa8paNO6oVoiLSDn5ajbMfggO+Dnsd0nY1UgWchniqb6+uaTLhwJvAQcC2wL/MrPnnXPLN3ggszOBMwF69erV/JWmEI1pshcRKRPO+Rb3lrvAea9A5z5hVyRZymVTcyGwVcLlnvgWd6LxwIPOmwd8DOyQ/EDOuZucc4Odc4O7dcvPieYjMafJXkSk9EXXwaRT4K17/WUFeFHJZUq9BvQzsz7BYLXR+K7zRJ8CwwDMbHNge+CjHNaUNT86XS1xESlhkTUw8SSY+xhEVoddjWyCnHWnO+eiZnY+8CRQAdzmnJttZmcHt98I/Bq4w8zewXe//8Q593WuamqMaFzHiYtICatdBRNHw8fPw/C/waAxYVckmyCnM7Y556YD05OuuzHh78+BQ3JZw6aK6HziIlKqorVw9/Gw4GUYeSPsMjrsimQTadrVNKIxR3WlQlxESlBlNWx7IAw5w5/QRIqWQjwNfxYzdaeLSAlZ8w0s+wy2GKhDyEqEmpopOOeCudO1eUSkRKxaAnceDXcf5we0SUlQSzyFaNwfzl6llriIlIKVX8GEEbD0IzjxHqhqFXZF0kwU4ilEYz7E1RIXkaK3fBFMGA7fLoCT74Nt9g+7ImlGCvEUInE/86uOExeRovf8n/x+8FMfgN7fDbsaaWYK8RTqWuI6FamIFL1DroLdx8IWO4VdieSAUiqFSMy3xDXZi4gUpaUfwb2jYfVSqKpRgJcwtcRTqAvxKk32IiLF5usP/Cj06DpYsQhadw67IskhhXgK6we2qSUuIkXkq/d8gONg3KOw+YCwK5IcU1MzhWj9wDZtHhEpEl/OhjuOBGsB4x5TgJcJpVQKkfqBbWqJi0iRqOkA3baH8dP9bykL6k5PoX5gm/aJi0ih+/oD6LwNdOjpW+Cmxkc5UUqlENE+cREpBvNfgpsOgGd+4y8rwMuOQjyFaEz7xEWkwH38vJ8Hvd3msMcZYVcjIVFKpVA/d7pCXEQK0YfPwD0nQMetYNx0aN897IokJNonnoImexGRgrVuBUwZ7/eDj3kY2nYLuyIJkUI8hfrR6RrYJiKFpmU7OGkSdN1OE7mIutNTiaolLiKFZs7D8Prt/u9eeyrABVCIpxSJ6zhxESkg70yB+8fDzMkQj4VdjRQQhXgKGp0uIgXjrXvhwe9Dr73glPuhRUXYFUkBUUqlsH7udG0eEQnRG3fC1HOhz74+wFu2DbsiKTBKqRRq689ipu50EQnR2m+h70Fw0n1Q3TrsaqQAKcRTWD+wTZtHREKw4kv/+7s/gJPv8+cEF0lBKZVC3WQvGp0uInn3/J/h74Nh8fv+svaBSwYK8RTqjhOvVktcRPLFOZjxe/jP/0G/Q/xkLiIN0GQvKdR3p2ufuIjkg3Pw9K/h+T/BLifDiL+rBS5ZUVMzhbppVysU4iKSDzMn+wAfNBZGXK8Al6ypJZ5CJO6oqjBMp/UTkXwYeCxE18BuY0DTPUsj6NWSQjQWp1JvJBHJpXgcnr0GVi6GiirYfZwCXBpNr5gUIjGnKVdFJHfiMZh2ATxzFcx6IOxqpIipOz2FaDyuKVdFJDdiUZh6DrwzGfa7DIaeFXZFUsQU4ilEok7HiItI84tF4IEzYM5UOPAXsO+Pw65IipxCPIVIXPvERSQH1i6HL2fDIVfBdy4IuxopAQrxFKLaJy4izSmyFlpUQpsucNZzmgddmo2amylon7iINJva1TDpJJh6tp/URQEuzUhJlUIk5nTyExFputpVcO8o+PAZ2GZ/0NwT0szUnZ5CJBZXd7qINM3a5T7AF7wCI/8Ju5wYdkVSghTiKURjTvOmi8imcw4mj4EFr8Jxt/oZ2URyQCGeQiQWV3e6iGw6M9jvUtjjDNjxqLCrkRKmEE8hGne0qtIJCESkkVZ9DfP+47vOt/5O2NVIGVCIpxCNxams0aYRkUZY+RXcORy++QT67APtu4ddkZQBJVUKtTGnyV5EJHvLF8GE4bBsIZx8nwJc8kYhnkJUo9NFJFvLFsKdR/uW+KkPqBtd8kohnkI0ruPERSRLHz0Lq5bAaQ/BVkPCrkbKjEI8hUgsTpUOMRORTGJRqKiE3U6BfodA225hVyRlSM3NFPzc6do0IpLG4vfhhqHw6cv+sgJcQqKWeAr+OHG1xEUkhS/nwIQRgIOW7cOuRsqcmpsp+GlXtWlEJMkX78CdR4G1gHHTYfP+YVckZU5JlUI0rmlXRSTJkg/hjqOgsgbGT4du24VdkYi601OJ6ixmIpKs49aw68kw9Czo1DvsakQAhfhGnHNE4nGqtU9cRAAWvAYdekL7LeGw34ZdjcgG1NxMEos7nEMtcRGBj5/3g9geuzjsSkRSUlIlicYdgEani5S7D5+Ge06AjlvBUdeGXY1ISgrxJJFYHIAqzZ0uUr7efwruHQ1d+sK4x6Dd5mFXJJKS9oknicbUEhcpa/E4PHMVbLajn0q1deewKxJJSyGeJBIPWuLaJy5SfpyDFi3glClQUQ2tOoZdkUhGSqokkaAlrrOYiZSZmZPh/rEQi0DbzRTgUhQU4kmiwT5xnU9cpIz872548ExYvRRitWFXI5I1JVWSiPaJi5SX12+Dh8+DbfaHkydDdZuwKxLJmkI8SVT7xEXKx+u3waM/hH6HwkmToLp12BWJNIqSKkm0fp+4No1IydtiF9h5NJx4N1TVhF2NSKMpqZLUHSeu7nSRErbgVf+75+5w7D+hsjrcekQ2kUI8Sf3odA1sEyk9zsEzv4VbD/YTuogUOR0nniSqlrhIaXIO/vN/8MK1sOsp0HdY2BWJNJlCPEkkruPERUqOc/Dkz+Dl62H38XDkn/2kLiJFTq/iJHUtcQ1sEykhC171AT7kLH8yEwW4lAi1xJPUHyeuN7lI6eg1FE5/CrYaAqZeNikdSqok9WcxU3e6SHGLx/wx4B8/5y/3GqoAl5KjEE9SN9lLpbrTRYpXLAoPneUnc1n4WtjViORM1kllZo2ei9DMDjOzuWY2z8wuS7PM/mb2lpnNNrNnG7uO5ra+O13f2EWKUiwCD3wP3rkfhv0S9rk47IpEcqbBEDez75jZHODd4PIuZnZDFverAK4HDgf6AyeZWf+kZToCNwDDnXMDgBMa/QyaWd2MbdWVaomLFJ1oLdw/DuZMhUN+owCXkpdNUl0LHAosAXDOvQ3sm8X9hgDznHMfOedqgUnAiKRlTgYedM59Gjz2V9kWniv13elqiYsUnxaV0LI9HH4NfOf8sKsRybmsRqc75xbYhgNCYlncrQewIOHyQmBo0jLbAVVmNgNoB1znnJuQTU25UhvVPnGRolO7GtZ+C+27wzE3aACblI1sQnyBmX0HcGZWDVxI0LXegFTvIpdi/bsDw4BWwEtm9rJz7v0NHsjsTOBMgF69emWx6k0X1WQvIsVl3UqYOBqWfw7nvgSVLcOuSCRvsmlung2ch29ZLwR2Bc7N4n4Lga0SLvcEPk+xzBPOuVXOua+B54Bdkh/IOXeTc26wc25wt27dslj1pqufdlXHiYsUvrXL4e7jYP5/Yf+fKsCl7GSTVNs7505xzm3unNvMOXcqsGMW93sN6GdmfYIW/GhgWtIyDwP7mFmlmbXGd7dn08rPmfoToKglLlLY1nwLd42Ez16H42+DnUMfFyuSd9mE+N+yvG4DzrkocD7wJD6YJzvnZpvZ2WZ2drDMu8ATwEzgVeAW59ysbIvPhWg8TmULw7RPTaSwPfkzWPQ2jJoAA0aGXY1IKNLuEzezvYDvAN3M7EcJN7UHKrJ5cOfcdGB60nU3Jl2+Brgm24JzLRJzOoOZSDE45New8yjYZr+wKxEJTaaWeDXQFh/07RJ+lgPH5760cERicZ1LXKRQrfgSpl8K0XXQurMCXMpe2pa4c+5Z4Fkzu8M5Nz+PNYUqqpa4SGFa/jnceTQsXwS7nQJbbjQGVqTsZHOI2WozuwYYANTUXemcOzBnVYUoGo/rNKQihebbBT7AV30Npz2oABcJZJNW9wDvAX2A/wM+wY88L0mRmFOIixSSbz6BO46A1UthzFTotWfYFYkUjGzSqotz7lYg4px71jl3OlCy76JILK7udJFCsnY5WAWMfRh6Dg67GpGCkk13eiT4vcjMjsRP2NIzdyWFKxpzmjddpBCsWgJtusCWO8P5r0NFVrNEi5SVbFriV5lZB+Bi4MfALcBFuSwqTJGY9omLhO7LOXDDUHjpen9ZAS6SUoPvDOfco8Gfy4ADAMzsu7ksKkzRuPaJi4Rq0UyYMMJPodrvkLCrESlomSZ7qQBG4edMf8I5N8vMjgIux5+sZLf8lJhf2icuEqLP3vRTqVa3hbHToMu2YVckUtAytcRvxZ/A5FXgr2Y2H9gLuMw5NzUPtYVCk72IhGTNNz7AazrA2Eeg09ZhVyRS8DKF+GBgZ+dc3MxqgK+Bvs65L/JTWjiiMUd1pUJcJO9adYKjroWthkCHkh07K9KsMoV4rXMuDuCcW2tm75d6gANE4o7W2icukj8fPQuxCPQ7CAYeG3Y1IkUlU4jvYGYzg78N2Da4bIBzzu2c8+pCEI3FqdIhZiL5Me/fMOkU2Kw/bHsgaFeWSKNkCvFszhlecqKasU0kP+Y+AZNPg27bwylTFOAimyDTCVDK5qQniTQ6XSQP3n0E7h8PWwyEUx/0ZyQTkUbTDApJIjoBikjuffQsdN8NTp3iR6OLyCZRiCfRtKsiORRZA1Wt4PA/QHQNVLcJuyKRopZVk9PMWpnZ9rkuphBEYo5KtcRFmt+bd8H1Q2DZZ37/twJcpMkaTCszOxp4C3giuLyrmU3LcV2hicbjVGufuEjzeu1WmHY+dOmn/d8izSibJucVwBDgWwDn3FtA71wVFLZINK6WuEhzevlGeOxHsN1hMPpe350uIs0im7SKOueW5bySAhGJO41OF2kuMyfDEz+BHY6CUXdBVU3YFYmUlGwGts0ys5OBCjPrB1wIvJjbssIT1dzpIs1nu0Nh30thv0uhoirsakRKTjZpdQEwAFgH3Is/JelFOawpNPG4I+5QS1ykKZyD/93jR6LXdIADf6YAF8mRbFri2zvnfgb8LNfFhC0SjwPoOHGRTeUc/Of/4IVrYd1y2POcsCsSKWnZpNWfzew9M/u1mQ3IeUUhisQcAFVqiYs0nnPw5M98gA8+HYacFXZFIiWvwRB3zh0A7A8sBm4ys3fM7Oe5LiwM0ZhviVdqn7hI48TjMP0SePl6GHo2HPlnzYUukgdZvcucc1845/4KnI0/ZvyXuSwqLGqJi2yiFYtg9oPwnQvgsN+B6T0kkg8N7hM3sx2BE4HjgSXAJODiHNcVimiwT1zHiYtkKR73gd2hB5zzIrTdXAEukkfZDGy7HZgIHOKc+zzH9YQqWt8SV4iLNCgWhYfOgk5bw7BfQrstwq5IpOxks098T+fcdaUe4AC1sbrR6WpJiGQUrYUp42HWFGjZLuxqRMpW2pa4mU12zo0ys3cAl3gT4JxzO+e8ujyra4lrYJtIBtF1cP84mDsdDr0a9jov7IpEylam7vQfBL+PykchhSBSNzpdLXGR1JyDyWPh/cfhiD/CkO+HXZFIWUvb5HTOLQr+PNc5Nz/xBzg3P+XlVzSu0ekiGZnBTsfD0dcpwEUKQDb9xgenuO7w5i6kEERjmrFNJKV1K+Hj5/3fOx0Pu48LtRwR8dKmlZmdE+wP397MZib8fAzMzF+J+VOryV5ENrZ2Gdx9LNxzAqz8KuxqRCRBpn3i9wKPA78FLku4foVzbmlOqwpJVJO9iGxozTdw17HwxUw4/jZou1nYFYlIgkwh7pxzn5jZRkNPzaxzKQa5JnsRSbB6KUwYAYvf8+cC3+GIsCsSkSQNtcSPAt7AH2KW2Dx1wDY5rCsUkfpDzNQSF+F/d8HiuTB6IvQ7KOxqRCSFtCHunDsq+N0nf+WEq647vbpSLXERvnMh9DsUNtsh7EpEJI0G08rMvmtmbYK/TzWzP5tZr9yXln/1x4mrJS7lavnncMdRsORDfziZAlykoGXT5PwHsNrMdgEuBeYDd+W0qpBEdIiZlLNvP4XbD4fP34LVS8KuRkSykE1aRZ1zDhgBXOecuw4oycmS6yZ70YxtUnaWfgy3HwGrv4ExD8NWQ8KuSESykM1ZzFaY2U+B04B9zKwCqMptWeGI6jhxKUd1AR5dA2OnQfddw65IRLKUTVqdCKwDTnfOfQH0AK7JaVUhqRudXq3udCknbbpBj0Ew9lEFuEiRyeZUpF8A9wAdzOwoYK1zbkLOKwuBToAiZWXx+3461ZZtYfQ9sMXAsCsSkUbKZnT6KOBV4ARgFPCKmR2f68LCoH3iUjYWvQ23HQqPXhR2JSLSBNnsE/8ZsIdz7isAM+sG/BuYksvCwlA/Ol37xKWULXwD7h4JLdvDAZeHXY2INEE2adWiLsADS7K8X9GJxhwtDFroOHEpVZ++4qdSrekI46dD55KbeFGkrGTTEn/CzJ4EJgaXTwSm566k8ETicR0jLqUrFoWHz/UnMRn7CHToEXZFItJEDYa4c+4SMzsW2Bs/f/pNzrmHcl5ZCKIxpxCX0lVR6edBr2kP7bYIuxoRaQZpQ9zM+gF/BLYF3gF+7Jz7LF+FhSESi2tQm5SeD/4NnzwPB10B3bYLuxoRaUaZmp23AY8Cx+HPZPa3vFQUokjMaaIXKS1zH4dJJ8GH/4HaVWFXIyLNLFN3ejvn3M3B33PN7M18FBSmaCxOlVriUirmPAxTToctdobTHvTHg4tISckU4jVmthvrzyPeKvGyc67kQj0a1z5xKRHvTIEHz4Seg+GU+6GmQ9gViUgOZArxRcCfEy5/kXDZAQfmqqiwaJ+4lIzKltB7bz8TW8uSPF+RiJAhxJ1zB+SzkEIQicU10YsUt2/mQ6etYcejYYej/DnBRaRkKbESRGNOLXEpXq/eDH/bHT55wV9WgIuUPIV4gkjcUal94lKMXroBpv8Y+h4EPfcIuxoRyRMlVoJoLE6VplyVYvPCX+DJn8KOw2HUBL8/XETKQjZnMTMzO9XMfhlc7mVmQ3JfWv5pxjYpOh89C//+FQw8Do6/HSqrw65IRPIom8S6AdgLOCm4vAK4PmcVhahWo9Ol2PTZF467FY692U+rKiJlJZsQH+qcOw9YC+Cc+wYoya/7UZ0ARYqBc/DsH+Cr9/zgtZ2OhxYVYVclIiHIJrEiZlaBPza87nzi8ZxWFZJozFGpfeJSyJyDJ34Kz/wG3rk/7GpEJGTZhPhfgYeAzczsN8ALwNU5rSokkZha4lLA4nF47GJ45R+w57lw4M/DrkhEQpbNqUjvMbM3gGH4KVePcc69m/PKQuCnXVVLXApQPAaP/AD+dxd89yJ/RjIdBy5S9hoMcTPrBawGHkm8zjn3aS4LC0MkGtdx4lKYYrXwzSew309g/58qwEUEyCLEgcfw+8MNqAH6AHOBATmsKxQRtcSl0MQiEF3r5z8/9UEdQiYiG8imO32nxMtmNgg4K2cVhSgai+t84lI4orUwZTysWgzjHlOAi8hGGp1YwSlIS3JeR82dLgUjug4mnwbvPQoDRkJFVdgViUgBymaf+I8SLrYABgGLc1ZRiCLxONXaJy5hi6yBSafAh/+BI/8Ee5wRdkUiUqCySax2CT8t8fvIR2Tz4GZ2mJnNNbN5ZnZZhuX2MLOYmR2fzePmSkQtcSkEj/4QPnwahv9NAS4iGWVsiQeTvLR1zl3S2AcO7ns9cDCwEHjNzKY55+akWO73wJONXUdzcs4RizvtE5fw7XuJPxvZTqF+pxWRIpA2scys0jkXw3efb4ohwDzn3EfOuVpgEqlb8BcADwBfbeJ6mkUk5gA0Ol3CsXYZvPh3PyNbl20V4CKSlUwt8VfxAf6WmU0D7gdW1d3onHuwgcfuASxIuLwQGJq4gJn1AEYCBxLyYLlo3M8kq+PEJe/WfAN3HQtfzPQnNNly57ArEpEikc1x4p2BJfigrTte3AENhXiqJq1LuvwX4CfOuZhlmLzCzM4EzgTo1atXFiU33vqWuEJc8mjVErjrGFj8Hpx4twJcRBolU4hvFoxMn8X68K6THMapLAS2SrjcE/g8aZnBwKQgwLsCR5hZ1Dk3NXEh59xNwE0AgwcPzmbdjRaJ+Za4utMlb1YuhgkjYOmHMHoi9Dso7IpEpMhkCvEKoC3ZtahTeQ3oZ2Z9gM+A0cDJGzyIc33q/jazO4BHkwM8X6JBS1wD2yRvvpoNyxfCyffBNvuHXY2IFKFMIb7IOXflpj6wcy5qZufjR51XALc552ab2dnB7Tdu6mPnQl1LXIeYSc5F10FlSx/cF70DNR3CrkhEilSmEG9ymjnnpgPTk65LGd7OuXFNXV9TROManS558M18vw/8gJ/5EegKcBFpgkwhPixvVRSAaP0+cXWnS44s/QjuHA7rlkPnPg0vLyLSgLQh7pxbms9CwlZb152ufeKSC19/AHce7bvSxz4CW+4SdkUiUgKyOcSsLEQ12Yvkyqqv4fYjAAfjHoXNS+4sviISEoV4QJO9SM606Qp7nQfbHw7dtg+7GhEpIQrxQP1kLy3UEpdm8vlb0KICttgJ9r4o7GpEpASp2Rmo706v1CaRZrDwdT+IbdoFfj50EZEcUGIF6o8TV0tcmmr+SzDhGGjdCUZNgAxTCouINIVCPBDRIWbSHD5+Hu4+DtptDuMfh465metfRAS0T7xe3WQvmrFNmuTVf0LHrWDMNB/kIiI5pBAPRHScuDRFPA4tWsCxN0PtamjTJeyKRKQMKLECdQPbqtWdLo313mNw+2Gw5luoaqUAF5G8UWIFdAIU2SSzp8LkMRCPhl2JiJQhhXggon3i0lgz74cpp0OPwXDaVGjVMeyKRKTMKMQD9SdA0T5xycbsh+ChM2Hr78CpD0BN+7ArEpEypMQK1O0TV0tcstJ9EOxyEpw8GVq2DbsaESlTCvFAJK7jxCULHz7jR6J32hqOuQGqW4ddkYiUMSVWIBKtO4uZNomk8dL1cNcx8MbtYVciIgIoxOtF43HMoELTrkoqz/8Znrwc+o+AQWPCrkZEBNBkL/UiMadBbZLajN/DjKthpxPgmBuhQm8bESkMSq1ANBbXoDbZ2NKP4YU/wy4nw8h/KsBFpKDoEykQjTvtD5eNde4DZ/wHNuvvp1UVESkg+lQK1MbiVKklLuDP//34ZfDmXf7yFgMV4CJSkPTJFIjG4jr5ifjDxx79IbzyD1j8XtjViIhkpO70QDTmtE+83MVjMO1CeOtu2PuHMOxXYVckIpKRQjwQ0T7x8uYcTD0HZt4H+10G+18Gpi91IlLYFOKBqPaJlzcz6NoPDvw57HtJ2NWIiGRFIR6IaJ94eYrWwjcfQ7ftFd4iUnSUWoFIzKklXm4ia2HyaXDrIbB6adjViIg0mlrigWg8TqX2iZePyBqYdDJ8+DQcdS207hx2RSIijaYQD0RijkrNm14ealfBvSfCJy/AiOtht1PDrkhEZJOo6RnwA9u0OcrCf6+D+f/106gqwEWkiKklHtA+8TKyz8XQex/os0/YlYiINImanoFITPvES9rqpfDQ2f53ZUsFuIiUBKVWwJ8ARS3xkrTqa7hzOMx6AL54J+xqRESajbrTA5o7vUSt+BImjPDHgp80CbbZL+yKRESajUI8ENHc6aVn+SK482hY/hmcPFkBLiIlRyEeiMbjVGufeIlxUNUKTn0Atv5O2MWIiDQ7hXhALfESsuILaNMN2neHM5/VucBFpGTp0y2gudNLxJIP4eZh8MRl/rL+pyJSwtQSD0R1nHjxW/w+TBgOsVrY7bSwqxERyTmFeEBzpxe5L+f4UegAYx+FzfuHW4+ISB4oxAHnXDBjm0K8KEVrYeKJYC1g7CPQbbuwKxIRyQuFOH6iF4AqnQClOFVWwzE3QrstoMu2YVcjIpI3anri94cD6k4vNgtegzfu8H/3/q4CXETKjlILiMTjABrYVkzmvwR3HQP//as/N7iISBlSiJPQEld3enH4+Hm4+1hotyWMe8xP6CIiUoYU4vh50wGqKrU5Ct6HT8M9J0DHrWH8dGi/ZdgViYiERgPbgNq6ENfEIIVv8Vzo0hfGTIU2XcOuRkQkVApxEge2qTu9YK1dBjUdYM9zYPfxUFUTdkUiIqFT0xM/0QtodHrBmv0QXLcLLHrbX1aAi4gACnHAn/wEdJx4QZo5GaacDt12gE59wq5GRKSgKMRZ352uGdsKzP/ugQfPhK2/C6dMgZr2YVckIlJQlFqsH9imfeIF5MOn4eFzYZv94eTJ0LJt2BWJiBQcDWwj4RAztcQLR+994KArYOg52gcuIpKGUov1c6drspcC8OZdsPIrqKiCvX+oABcRyUAhDkRiGp1eEJ7/E0w7H166PuxKRESKgrrTWT+wrVohHg7n4Nnfw4zfwk6j4MBfhF2RiEhRUIiT2BJXd3reOQf/uRJe+DPsegoM/xu0qAi7KhGRoqCmJxCpO5+4Qjz/alfCe4/6WdiG/10BLiLSCGqJs350eqXmTs8f5yAeg5bt4HtPQU1HMH2JEhFpDKUWmjs97+JxePQieOB7PshbdVKAi4hsAoU4EAnmTtfAtjyIx/wI9DfugC7bgmmbi4hsKnWnA5GoDjHLi1gUpp4N79wP+18O+12qFriISBMoxEmY7EXd6bn16A98gA/7Fezzo7CrEREpegpxEs9ippZ4Tu02BjbfCfY8O+xKRERKglKLhNHpaok3v8hamDPN/91rqAJcRKQZKcRZf5y45k5vZrWrYeJomDwGvno37GpEREqOutPxM7ZVVRimQVbNZ91KH+CfvAAjrofNdgy7IhGRkqMQx3ena6KXZrR2OdxzAix8FY69GXY+IeyKRERKkkIcP7BN+8Ob0YdPw2dvwPG3wYCRYVcjIlKyctr8NLPDzGyumc0zs8tS3H6Kmc0Mfl40s11yWU860XicKh0j3nTOjy1gwDFwwesKcBGRHMtZcplZBXA9cDjQHzjJzPonLfYxsJ9zbmfg18BNuaonk2jM6eQnTbVyMdx6CMx/0V/u1DvUckREykEuu9OHAPOccx8BmNkkYAQwp24B59yLCcu/DPTMYT1p1WqfeNOs+BImDIdv5kN0bdjViIiUjVwmVw9gQcLlhcF16XwPeDyH9aSllngTLP8c7jgCvl0Ap9wP2x4YdkUiImUjly3xVKnoUi5odgA+xPdOc/uZwJkAvXr1aq766kXjcc2bvilWfgW3HwGrvoZTH4Ct9wq7IhGRspLL5FoIbJVwuSfwefJCZrYzcAswwjm3JNUDOeducs4Nds4N7tatW7MXGok5TfSyKVp3gW32h9MeUoCLiIQgly3x14B+ZtYH+AwYDZycuICZ9QIeBE5zzr2fw1oyisY0Or1RlnwIlTXQoQcc/ZewqxERKVs5C3HnXNTMzgeeBCqA25xzs83s7OD2G4FfAl2AG4LZ0qLOucG5qimdiPaJZ2/xXLhzuB99fvoTOpWoiEiIcjrZi3NuOjA96bobE/4+AzgjlzVkIxLTPvGsfDnHj0LHfAtcAS4iEiolF/584mqJN2DRTLjjSGhRCeOnay50EZECoBBHc6c3yDl48nKoag3jHoOu/cKuSERE0NzpgPaJN8gMTrgDaldBp63DrkZERAJqflJ3KlJtio3MfxEeOAOitdCmqwJcRKTAKLnw+8Q1sC3JRzPg7uNg0duwdlnY1YiISApKLoKWuCZ7WW/ev+HeE/1hZOMeg7bNP8GOiIg0nUIcP3e6ziceeP8pmHiSH7w29lFou1nYFYmISBoKcTR3+gbadIWtvwNjpkGbLmFXIyIiGSi5gNponOpyD/HFc/3vHoNgzMPQunO49YiISIPKPLm8aLzMT4Dy9n1ww54wc3LYlYiISCMoxKnbJ16mm+LNu+Chs6D33rDDkWFXIyIijVCmybWhSDxenpO9vHYrTDsftj0QTp4M1W3CrkhERBqh7EM8Fnc4R/lNu7p4Ljx2MWx3GIy+F6pahV2RiIg0UtlPuxqJxQGoqiyzlni37eHUKdB7X6isDrsaERHZBGXW/NxYfYiXS0v8hWvhw2f8330PUoCLiBSxMkmu9KIxB1D6k704B89cDf++AmY/FHY1IiLSDNSdHvct8ZIene6cD+///gV2OxWOujbsikREpBmUfYjXtcRLdu505+DJn8HL18Pg0+GIP0G57DoQESlxZf9pXh/ipdoSdw7WLYOhZ8ORf1aAi4iUkLJvidfG6rrTS6wlHo/D6iX+DGRH/w3M/I+IiJSMsm+WRYN94iXVEo/H4OHz4JZh/lzgLVoowEVESlAJJdemqR+dXir7xGNRePBMePteP4itpkPYFYmISI6UfXd6/XHipdASj9bCA9+Dd6fBQVfA3j8MuyIREcmhsg/xaLyEBrbNuNoH+KFXw17nhV2NiIjkWNmHeCRaQgPbvvsD2Hwg7HR82JWIiEgelEDzs2ki9S3xIg3x2tXw9FUQWQutOinARUTKSNmHeLTuELNiPH563Uq45wR4/k/w6YthVyMiInmm7vRinTt97TIf4Atfh2Nv9ucEFxGRslL2IV53nHh1MQ1sW/MN3HUsfDETTrgd+o8IuyIREQlB2Yd4JFaEJ0BZ8SUs/xxG3QU7HBF2NSIiEhKFeDFN9rJuJVS3gc12gAv/B9Wtw65IRERCVETNz9womhOgrPgCbj4Qnv+jv6wAFxEpe2XfEo/Gi+A48WWfwZ1H+yDvtVfY1YiISIEo+xCPFHpL/NtPfYCvWgKnPQi99gy7IhERKRAK8fq50wuwJR5Z6wN8zTcw5mHouXvYFYmISAEp+xAv6MleqmrggJ9D137QfdewqxERkQJT9iG+vju9gFriX70HyxZCv4Ng5xPCrkZERApU2Yd4NB6nooVhViAh/sUsmDDCjz4//3WobBl2RSIiUqAKsA85v6IxVzit8M/fgjuPgopqOPUhBbiIiGRU9iFeG4tTVQj7wxe+AROGQ3VbGP8YdO0bdkUiIlLg1J0ec4VxjPich/ypRMc+Ah17hV2NiIgUAYV4PB7uvOmxKFRUwkFXwnd/CG26hFeLiIgUlQLoRw5XJOaoCmve9I9mwA17wjefQIsWCnAREWmUsg/xaCyklvgH/4Z7T/SD2Kra5H/9IiJS9Mo+xCNhjE6f+zhMOslP4jL2EWjbLb/rFxGRkqAQj8XzO2/6RzPgvlNh84E+wNWFLiIim6jsQzwaz/Po9O6DYPdxMGaqH40uIiKyico+xCOxeH7mTf/gX1C7Gmraw5F/gpoOuV+niIiUtLIP8bzM2PbmXXDPCfD8H3O7HhERKStlH+I53yf+2i0w7XzoOwz2vSR36xERkbKjEI+73B1i9vI/4LGLYbvDYfS9UNUqN+sREZGyVPYhHo3FczPZy5pv4Pk/w47DYdQEncxERESanaZdzcXc6c75kedn/Ava94CKquZ9fBERERTiRJpz7nTn4JnfQKwWDvo/6NS7eR5XREQkhbLvTo/E4lQ3R4g7B//6JTx3Daxe6i+LiIjkUNm3xKMxR2VT94k7B0/8FF75Bwz+HhzxR39CExERkRwq+xCPxJphdPrjP4FX/wl7nguHXg1WAOcnFxGRklf2IR6Nx5s+2cvWe0F1Gxj2SwW4iIjkTdn3+fru9E3YDLEoLHzd/z1gJBz0KwW4iIjkVdmHeG0sTlVlI8M3FoGHzoTbDoUlH+amMBERkQaoOz0Wp6oxLfFoLTxwOrz7CBx8JXTZNnfFiYiIZFDWIR6PO+KO7Cd7ia6DyWPh/cfhsN/BnufktkAREZEMyjrEI/E4QPYnQHl7kg/wI/8Ee5yRw8pEREQaVtYhHo35CVmyPk580BjotgP0GprDqkRERLJT1gPbIrEsWuLrVvgu9K/n+dHnCnARESkQZR7iviWe9jjxtcvgrmP9ILav5uSxMhERkYaVd3d6sE885Yxta77xAf7FO3DCHdB/eH6LExERaUB5h3i6feKrl8KE4bB4Lpx4N2x/WAjViYiIZFbm3elp9olXVEPrrnDSRAW4iIgUrLJuia/fJx6E+Iov/BzoLdvBaQ9pGlURESloOW2Jm9lhZjbXzOaZ2WUpbjcz+2tw+0wzG5TLepLVtcQrKwyWLYTbD4cpp9cVl89SREREGi1nLXEzqwCuBw4GFgKvmdk051ziMO/DgX7Bz1DgH8HvvIjGfUu83ZrP4PbxfjDbyH/ma/UiIgUrEomwcOFC1q5dG3YpZaWmpoaePXtSVVWV1fK57E4fAsxzzn0EYGaTgBFAYoiPACY45xzwspl1NLMtnXOLclhXvWgsTi/7kkFP/xjiq2DMVOixez5WLSJS0BYuXEi7du3o3bs3pp7JvHDOsWTJEhYuXEifPn2yuk8uu9N7AAsSLi8MrmvsMjkTica5rup6KmJrYOwjCnARkcDatWvp0qWLAjyPzIwuXbo0qvcjlyGe6j/vNmEZzOxMM3vdzF5fvHhxsxQH0LplJTd3uZT5R98HW+7SbI8rIlIKFOD519htnssQXwhslXC5J/D5JiyDc+4m59xg59zgbt26NVuBu2zVkRt+cCJ9B2oqVRGRQvTQQw9hZrz33nv1182YMYOjjjpqg+XGjRvHlClTAL8//7LLLqNfv34MHDiQIUOG8Pjjjze5lt/+9rf07duX7bffnieffDLlMm+//TZ77bUXO+20E0cffTTLly+vv23mzJnstddeDBgwgJ122qlZxhvkMsRfA/qZWR8zqwZGA9OSlpkGjAlGqe8JLMvX/nARESl8EydOZO+992bSpElZ3+cXv/gFixYtYtasWcyaNYtHHnmEFStWNKmOOXPmMGnSJGbPns0TTzzBueeeSywW22i5M844g9/97ne88847jBw5kmuuuQaAaDTKqaeeyo033sjs2bOZMWNG1oPXMslZiDvnosD5wJPAu8Bk59xsMzvbzM4OFpsOfATMA24Gzs1VPSIiUlxWrlzJf//7X2699dasQ3z16tXcfPPN/O1vf6Nly5YAbL755owaNapJtTz88MOMHj2ali1b0qdPH/r27curr7660XJz585l3333BeDggw/mgQceAOCpp55i5513Zpdd/K7bLl26UFFR0aSaIMeTvTjnpuODOvG6GxP+dsB5uaxBRESa5v8emc2cz5c3vGAj9O/enl8dPSDjMlOnTuWwww5ju+22o3Pnzrz55psMGpR5OpF58+bRq1cv2rdv32ANP/zhD3nmmWc2un706NFcdtmGU5t89tln7LnnnvWXe/bsyWeffbbRfQcOHMi0adMYMWIE999/PwsW+LHb77//PmbGoYceyuLFixk9ejSXXnppgzU2pKxnbBMRkcI1ceJELrroIsAH68SJExk0aFDawV+NHRR27bXXZr2sb3M2vL7bbruNCy+8kCuvvJLhw4dTXV0N+O70F154gddee43WrVszbNgwdt99d4YNG9aompMpxEVEJKOGWsy5sGTJEp5++mlmzZqFmRGLxTAz/vCHP9ClSxe++eabDZZfunQpXbt2pW/fvnz66aesWLGCdu3aZVxHY1riPXv2rG9Vgz+Ovnv37hvdd4cdduCpp54CfOv7scceq7//fvvtR9euXQE44ogjePPNN5sc4mV9AhQRESlMU6ZMYcyYMcyfP59PPvmEBQsW0KdPH1544QX69evH559/zrvvvgvA/Pnzefvtt9l1111p3bo13/ve97jwwgupra0FYNGiRdx9990brePaa6/lrbfe2ugnOcABhg8fzqRJk1i3bh0ff/wxH3zwAUOGDNloua+++gqAeDzOVVddxdln+yFghx56KDNnzmT16tVEo1GeffZZ+vfv3+TtpBAXEZGCM3HiREaOHLnBdccddxz33nsvLVu25O6772b8+PHsuuuuHH/88dxyyy106NABgKuuuopu3brRv39/Bg4cyDHHHENTD08eMGAAo0aNon///hx22GFcf/319QPTzjjjDF5//fX6urfbbjt22GEHunfvzvjx4wHo1KkTP/rRj9hjjz3YddddGTRoEEceeWSTagKwVP38hWzw4MGubmOJiEhuvPvuu+y4445hl1GWUm17M3vDOTc4eVm1xEVERIqUQlxERKRIKcRFRESKlEJcRERSKrYxU6WgsdtcIS4iIhupqalhyZIlCvI8qjufeE1NTdb30WQvIiKykZ49e7Jw4UKa8/TP0rCamhp69uyZ9fIKcRER2UhVVRV9+vQJuwxpgLrTRUREipRCXEREpEgpxEVERIpU0U27amaLgfnN+JBdga+b8fHKlbZj02kbNp22YdNpGzZdLrbh1s65jSaAL7oQb25m9nqq+WilcbQdm07bsOm0DZtO27Dp8rkN1Z0uIiJSpBTiIiIiRUohDjeFXUCJ0HZsOm3DptM2bDptw6bL2zYs+33iIiIixUotcRERkSJVNiFuZoeZ2Vwzm2dml6W43czsr8HtM81sUBh1FrIstuEpwbabaWYvmtkuYdRZyBrahgnL7WFmMTM7Pp/1FYtstqOZ7W9mb5nZbDN7Nt81Fros3s8dzOwRM3s72Ibjw6izUJnZbWb2lZnNSnN7fjLFOVfyP0AF8CGwDVANvA30T1rmCOBxwIA9gVfCrruQfrLcht8BOgV/H65t2PhtmLDc08B04Piw6y60nyxfix2BOUCv4PJmYdddSD9ZbsPLgd8Hf3cDlgLVYddeKD/AvsAgYFaa2/OSKeXSEh8CzHPOfeScqwUmASOSlhkBTHDey0BHM9sy34UWsAa3oXPuRefcN8HFl4HsT8VTHrJ5HQJcADwAfJXP4opINtvxZOBB59ynAM45bcsNZbMNHdDOzAxoiw/xaH7LLFzOuefw2ySdvGRKuYR4D2BBwuWFwXWNXaacNXb7fA//LVTWa3AbmlkPYCRwYx7rKjbZvBa3AzqZ2Qwze8PMxuStuuKQzTb8O7Aj8DnwDvAD51w8P+WVhLxkSrmcitRSXJc8LD+bZcpZ1tvHzA7Ah/jeOa2o+GSzDf8C/MQ5F/MNIEkhm+1YCewODANaAS+Z2cvOufdzXVyRyGYbHgq8BRwIbAv8y8yed84tz3FtpSIvmVIuIb4Q2Crhck/8t8vGLlPOsto+ZrYzcAtwuHNuSZ5qKxbZbMPBwKQgwLsCR5hZ1Dk3NS8VFods389fO+dWAavM7DlgF0Ah7mWzDccDv3N+B+88M/sY2AF4NT8lFr28ZEq5dKe/BvQzsz5mVg2MBqYlLTMNGBOMKNwTWOacW5TvQgtYg9vQzHoBDwKnqcWTUoPb0DnXxznX2znXG5gCnKsA30g27+eHgX3MrNLMWgNDgXfzXGchy2YbforvycDMNge2Bz7Ka5XFLS+ZUhYtcedc1MzOB57Ej8q8zTk328zODm6/ET8S+AhgHrAa/y1UAlluw18CXYAbgpZk1OlECvWy3IbSgGy2o3PuXTN7ApgJxIFbnHMpDwUqR1m+Fn8N3GFm7+C7hn/inNPZzQJmNhHYH+hqZguBXwFVkN9M0YxtIiIiRapcutNFRERKjkJcRESkSCnERUREipRCXEREpEgpxEVERIqUQlwkBMEZyt5K+OmdYdmVzbC+O8zs42Bdb5rZXpvwGLeYWf/g78uTbnuxqTUGj1O3XWYFZ9Dq2MDyu5rZEc2xbpFipEPMREJgZiudc22be9kMj3EH8KhzboqZHQL80Tm3cxMer8k1NfS4ZnYn8L5z7jcZlh8HDHbOnd/ctYgUA7XERQqAmbU1s/8EreR3zGyjs5uZ2ZZm9lxCS3Wf4PpDzOyl4L73m1lD4foc0De474+Cx5plZhcF17Uxs8eC80jPMrMTg+tnmNlgM/sd0Cqo457gtpXB7/sSW8ZBD8BxZlZhZteY2Wvmz618Vhab5SWCE0aY2RDz56j/X/B7+2CmsSuBE4NaTgxqvy1Yz/9SbUeRUlIWM7aJFKBWZvZW8PfHwAnASOfccjPrCrxsZtPchl1lJwNPOud+Y2YVQOtg2Z8DBznnVpnZT4Af4cMtnaOBd8xsd/wsUkPxM3K9YmbP4s8x/blz7kgAM+uQeGfn3GVmdr5zbtcUjz0JOBGYHoTsMOAc/Alxljnn9jCzlsB/zewp59zHqQoMnt8w4NbgqveAfYOZxg4CrnbOHWdmvyShJW5mVwNPO+dOD7riXzWzfwdzqIuUHIW4SDjWJIagmVUBV5vZvvhpQnsAmwNfJNznNeC2YNmpzrm3zGw/oD8+FAGq8S3YVK4xs58Di/GhOgx4qC7gzOxBYB/gCeCPZvZ7fBf88414Xo8Dfw2C+jDgOefcmqALf2czOz5YrgPQD/8FJlHdl5vewBvAvxKWv9PM+uHPBFWVZv2HAMPN7MfB5RqgF5o3XUqUQlykMJwCdAN2d85FzOwTfADVc849F4T8kcBdZnYN8A3wL+fcSVms4xLn3JS6C0GLdiPOufeDVvoRwG+DFnOmln3ifdea2Qz8aSxPBCbWrQ64wDn3ZAMPscY5t2vQ+n8UOA/4K34e72eccyODQYAz0tzfgOOcc3OzqVek2GmfuEhh6AB8FQT4AcDWyQuY2dbBMjfju5kHAS8D3zWzun3crc1suyzX+RxwTHCfNsBI4Hkz6w6sds7dDfwxWE+ySNAjkMokfDf9PvgTbBD8PqfuPma2XbDOlJxzy4ALgR8H9+kAfBbcPC5h0RVAu4TLTwIXWNAtYWa7pVuHSClQiIsUhnuAwWb2Or5V/l6KZfYH3jKz/wHHAdc55xbjQ22imc3Eh/oO2azQOfcmcAf+/NCv4M/09T9gJ/y+5LeAnwFXpbj7TcDMuoFtSZ4C9gX+7ZyrDa67BZgDvGlms4B/0kBPYFDL2/jTZP4B3yvwX/xZt+o8A/SvG9iGb7FXBbXNCi6LlCwdYiYiIlKk1BIXEREpUgpxERGRIqUQFxERKVIKcRERkSKlEBcRESlSCnEREZEipRAXEREpUgpxERGRIvX/4qptSe8dK5EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_test_pred)\n",
    "auc_sc = auc(fpr, tpr)\n",
    "# Draw ROC curve:\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, label=\"AUC = %0.2f\"%auc_sc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Receiver Operating Characteristic(ROC) for Support Vector Machine\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8994974874371859\n",
      "0.9473684210526315\n",
      "Training ROC_AUC:  0.8752055200668446\n",
      "Test ROC_AUC:  0.9318783068783069\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9704275132275133"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'kernel' : ['poly', 'rbf', 'sigmoid'],\n",
    "             'C' : [50, 10, 1.0, 0.1, 0.01],\n",
    "             'gamma' : ['scale']}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021379</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>50</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.970428</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007367</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>50</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 50, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.966641</td>\n",
       "      <td>0.028397</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.938667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.854286</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.961508</td>\n",
       "      <td>0.031755</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010018</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.961146</td>\n",
       "      <td>0.031886</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012334</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.959720</td>\n",
       "      <td>0.032469</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.959631</td>\n",
       "      <td>0.032406</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014370</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.959631</td>\n",
       "      <td>0.032406</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.014737</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.959631</td>\n",
       "      <td>0.032406</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.020901</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.016301</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.959542</td>\n",
       "      <td>0.032453</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.019510</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.959542</td>\n",
       "      <td>0.032453</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "1        0.021379      0.009298         0.014392        0.008814      50   \n",
       "0        0.007367      0.002961         0.005037        0.000657      50   \n",
       "4        0.011009      0.001961         0.007973        0.000870      10   \n",
       "3        0.010018      0.000870         0.008094        0.000608      10   \n",
       "7        0.012334      0.001468         0.010010        0.002973       1   \n",
       "6        0.010500      0.000922         0.008668        0.000830       1   \n",
       "9        0.014370      0.006635         0.011566        0.003424     0.1   \n",
       "12       0.014737      0.003731         0.011134        0.004145    0.01   \n",
       "10       0.020901      0.006881         0.016301        0.010270     0.1   \n",
       "13       0.019510      0.005921         0.010136        0.002319    0.01   \n",
       "\n",
       "   param_gamma param_kernel                                           params  \\\n",
       "1        scale          rbf     {'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "0        scale         poly    {'C': 50, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "4        scale          rbf     {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "3        scale         poly    {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "7        scale          rbf    {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "6        scale         poly   {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "9        scale         poly   {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "12       scale         poly  {'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "10       scale          rbf    {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "13       scale          rbf   {'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  ...  split23_test_score  \\\n",
       "1            0.949333           1.000000  ...            0.965333   \n",
       "0            0.952000           1.000000  ...            0.965333   \n",
       "4            0.938667           1.000000  ...            0.960000   \n",
       "3            0.944000           0.997333  ...            0.962667   \n",
       "7            0.944000           0.997333  ...            0.960000   \n",
       "6            0.944000           0.997333  ...            0.957333   \n",
       "9            0.944000           0.997333  ...            0.957333   \n",
       "12           0.944000           0.997333  ...            0.957333   \n",
       "10           0.941333           0.997333  ...            0.957333   \n",
       "13           0.941333           0.997333  ...            0.957333   \n",
       "\n",
       "    split24_test_score  split25_test_score  split26_test_score  \\\n",
       "1             0.965333            0.965333            0.989333   \n",
       "0             0.952000            0.962667            0.989333   \n",
       "4             0.946667            0.962667            0.986667   \n",
       "3             0.944000            0.962667            0.986667   \n",
       "7             0.944000            0.960000            0.986667   \n",
       "6             0.944000            0.960000            0.986667   \n",
       "9             0.944000            0.960000            0.986667   \n",
       "12            0.944000            0.960000            0.986667   \n",
       "10            0.944000            0.960000            0.986667   \n",
       "13            0.944000            0.960000            0.986667   \n",
       "\n",
       "    split27_test_score  split28_test_score  split29_test_score  \\\n",
       "1             0.992000            0.885714            0.983333   \n",
       "0             0.992000            0.871429            0.983333   \n",
       "4             0.994667            0.854286            0.983333   \n",
       "3             0.994667            0.851429            0.983333   \n",
       "7             0.994667            0.851429            0.983333   \n",
       "6             0.994667            0.851429            0.983333   \n",
       "9             0.994667            0.851429            0.983333   \n",
       "12            0.994667            0.851429            0.983333   \n",
       "10            0.994667            0.851429            0.983333   \n",
       "13            0.994667            0.851429            0.983333   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "1          0.970428        0.025301                1  \n",
       "0          0.966641        0.028397                2  \n",
       "4          0.961508        0.031755                3  \n",
       "3          0.961146        0.031886                4  \n",
       "7          0.959720        0.032469                5  \n",
       "6          0.959631        0.032406                6  \n",
       "9          0.959631        0.032406                6  \n",
       "12         0.959631        0.032406                6  \n",
       "10         0.959542        0.032453                9  \n",
       "13         0.959542        0.032453                9  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9120603015075377\n",
      "0.9532163742690059\n",
      "Training ROC_AUC:  0.8919840435567774\n",
      "Test ROC_AUC:  0.9365079365079365\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=50, kernel='rbf')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9095477386934674\n",
      "0.9473684210526315\n",
      "Training ROC_AUC:  0.8886283388587908\n",
      "Test ROC_AUC:  0.9318783068783069\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=10, kernel='poly')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9473684210526315\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.9484126984126984\n"
     ]
    }
   ],
   "source": [
    "# Decision trees\n",
    "from sklearn import tree\n",
    "clf=tree.DecisionTreeClassifier(random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'max_features': 0.6, 'max_leaf_nodes': 30, 'min_samples_leaf': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9716034391534392"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxDepth=clf.tree_.max_depth\n",
    "param_grid = {'max_depth':range(1, maxDepth+1),\n",
    "              'max_features':[0.2,0.4,0.6,0.8], \n",
    "              'max_leaf_nodes':[20,30,40,50],\n",
    "             'min_samples_leaf': [1,2,5,10]}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.971603</td>\n",
       "      <td>0.024036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.006737</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.932857</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.971308</td>\n",
       "      <td>0.024779</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.4, 'max_lea...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.937333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.952857</td>\n",
       "      <td>0.952778</td>\n",
       "      <td>0.970328</td>\n",
       "      <td>0.025256</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.4, 'max_lea...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.982667</td>\n",
       "      <td>0.937333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937333</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.969576</td>\n",
       "      <td>0.028998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.010733</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.934286</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.969522</td>\n",
       "      <td>0.024917</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.4, 'max_lea...</td>\n",
       "      <td>0.925333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921333</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.888571</td>\n",
       "      <td>0.947222</td>\n",
       "      <td>0.969200</td>\n",
       "      <td>0.029976</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.934286</td>\n",
       "      <td>0.943056</td>\n",
       "      <td>0.968727</td>\n",
       "      <td>0.028036</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934286</td>\n",
       "      <td>0.961111</td>\n",
       "      <td>0.968700</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.930667</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.968603</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.007094</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.911429</td>\n",
       "      <td>0.973611</td>\n",
       "      <td>0.968463</td>\n",
       "      <td>0.029267</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "423       0.005879      0.000767         0.004824        0.000771   \n",
       "311       0.006737      0.001310         0.005265        0.001264   \n",
       "275       0.005805      0.003026         0.005830        0.002935   \n",
       "351       0.005865      0.002321         0.004968        0.000705   \n",
       "379       0.010733      0.001124         0.007968        0.001197   \n",
       "279       0.005078      0.000451         0.004567        0.000804   \n",
       "355       0.005800      0.000542         0.004737        0.000575   \n",
       "419       0.005600      0.000490         0.004971        0.001830   \n",
       "483       0.006424      0.001407         0.004870        0.000803   \n",
       "319       0.007094      0.001443         0.005437        0.001735   \n",
       "\n",
       "    param_max_depth param_max_features param_max_leaf_nodes  \\\n",
       "423               7                0.6                   30   \n",
       "311               5                0.8                   30   \n",
       "275               5                0.4                   20   \n",
       "351               6                0.4                   50   \n",
       "379               6                0.8                   40   \n",
       "279               5                0.4                   30   \n",
       "355               6                0.6                   20   \n",
       "419               7                0.6                   20   \n",
       "483               8                0.6                   20   \n",
       "319               5                0.8                   50   \n",
       "\n",
       "    param_min_samples_leaf                                             params  \\\n",
       "423                     10  {'max_depth': 7, 'max_features': 0.6, 'max_lea...   \n",
       "311                     10  {'max_depth': 5, 'max_features': 0.8, 'max_lea...   \n",
       "275                     10  {'max_depth': 5, 'max_features': 0.4, 'max_lea...   \n",
       "351                     10  {'max_depth': 6, 'max_features': 0.4, 'max_lea...   \n",
       "379                     10  {'max_depth': 6, 'max_features': 0.8, 'max_lea...   \n",
       "279                     10  {'max_depth': 5, 'max_features': 0.4, 'max_lea...   \n",
       "355                     10  {'max_depth': 6, 'max_features': 0.6, 'max_lea...   \n",
       "419                     10  {'max_depth': 7, 'max_features': 0.6, 'max_lea...   \n",
       "483                     10  {'max_depth': 8, 'max_features': 0.6, 'max_lea...   \n",
       "319                     10  {'max_depth': 5, 'max_features': 0.8, 'max_lea...   \n",
       "\n",
       "     split0_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "423           0.997333  ...            0.958667            1.000000   \n",
       "311           0.996000  ...            0.961333            0.997333   \n",
       "275           0.992000  ...            0.958667            0.986667   \n",
       "351           0.960000  ...            0.952000            0.982667   \n",
       "379           0.996000  ...            0.961333            0.966667   \n",
       "279           0.925333  ...            0.954667            1.000000   \n",
       "355           0.998667  ...            0.945333            0.958667   \n",
       "419           0.928000  ...            0.989333            0.996000   \n",
       "483           0.993333  ...            0.922667            0.997333   \n",
       "319           0.996000  ...            0.945333            0.992000   \n",
       "\n",
       "     split25_test_score  split26_test_score  split27_test_score  \\\n",
       "423            0.922667            0.972000            0.996000   \n",
       "311            0.964000            0.952000            0.996000   \n",
       "275            0.937333            0.940000            0.994667   \n",
       "351            0.937333            1.000000            0.937333   \n",
       "379            0.941333            0.972000            0.973333   \n",
       "279            0.921333            0.953333            0.996000   \n",
       "355            0.953333            0.990667            0.996000   \n",
       "419            0.941333            0.972000            1.000000   \n",
       "483            0.930667            0.954667            0.990667   \n",
       "319            0.906667            0.972000            0.988000   \n",
       "\n",
       "     split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "423            0.965714            0.986111         0.971603        0.024036   \n",
       "311            0.932857            0.975000         0.971308        0.024779   \n",
       "275            0.952857            0.952778         0.970328        0.025256   \n",
       "351            0.984286            0.987500         0.969576        0.028998   \n",
       "379            0.934286            0.972222         0.969522        0.024917   \n",
       "279            0.888571            0.947222         0.969200        0.029976   \n",
       "355            0.934286            0.943056         0.968727        0.028036   \n",
       "419            0.934286            0.961111         0.968700        0.027120   \n",
       "483            0.940000            0.963889         0.968603        0.024215   \n",
       "319            0.911429            0.973611         0.968463        0.029267   \n",
       "\n",
       "     rank_test_score  \n",
       "423                1  \n",
       "311                2  \n",
       "275                3  \n",
       "351                4  \n",
       "379                5  \n",
       "279                6  \n",
       "355                7  \n",
       "419                8  \n",
       "483                9  \n",
       "319               10  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9522613065326633\n",
      "0.9415204678362573\n",
      "Training ROC_AUC:  0.9497183364329802\n",
      "Test ROC_AUC:  0.9404761904761905\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(max_depth= 7, max_features= 0.6, max_leaf_nodes= 30, min_samples_leaf= 10)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.9543650793650793\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_train_pred=clf_rf.predict(X_train)\n",
    "y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=7, max_features=0.2, n_estimators=50,\n",
      "                       random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9930978835978835"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_depth':np.arange(4, 10),\n",
    "              'max_features':[0.2,0.4,0.6,0.8],\n",
    "              'n_estimators': [10,50,100,200,300,500,1000]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf_rf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.139652</td>\n",
       "      <td>0.014124</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.993098</td>\n",
       "      <td>0.010205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1.580843</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.089364</td>\n",
       "      <td>0.013171</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.992711</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1.829905</td>\n",
       "      <td>0.281519</td>\n",
       "      <td>0.096048</td>\n",
       "      <td>0.014892</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.992711</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.002822</td>\n",
       "      <td>0.076456</td>\n",
       "      <td>0.056950</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.992711</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2.445210</td>\n",
       "      <td>0.330017</td>\n",
       "      <td>0.127408</td>\n",
       "      <td>0.030147</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.992622</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.801414</td>\n",
       "      <td>0.058154</td>\n",
       "      <td>0.045825</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.992444</td>\n",
       "      <td>0.011591</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2.038390</td>\n",
       "      <td>0.124647</td>\n",
       "      <td>0.106546</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.992438</td>\n",
       "      <td>0.011383</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.617862</td>\n",
       "      <td>0.052247</td>\n",
       "      <td>0.036225</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.011209</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.879133</td>\n",
       "      <td>0.047228</td>\n",
       "      <td>0.046941</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.992352</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.417642</td>\n",
       "      <td>0.039063</td>\n",
       "      <td>0.025626</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.992349</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "85        0.139652      0.014124         0.011601        0.001796   \n",
       "146       1.580843      0.071354         0.089364        0.013171   \n",
       "118       1.829905      0.281519         0.096048        0.014892   \n",
       "61        1.002822      0.076456         0.056950        0.008179   \n",
       "90        2.445210      0.330017         0.127408        0.030147   \n",
       "145       0.801414      0.058154         0.045825        0.004575   \n",
       "62        2.038390      0.124647         0.106546        0.015259   \n",
       "60        0.617862      0.052247         0.036225        0.006260   \n",
       "117       0.879133      0.047228         0.046941        0.002203   \n",
       "59        0.417642      0.039063         0.025626        0.003698   \n",
       "\n",
       "    param_max_depth param_max_features param_n_estimators  \\\n",
       "85                7                0.2                 50   \n",
       "146               9                0.2               1000   \n",
       "118               8                0.2               1000   \n",
       "61                6                0.2                500   \n",
       "90                7                0.2               1000   \n",
       "145               9                0.2                500   \n",
       "62                6                0.2               1000   \n",
       "60                6                0.2                300   \n",
       "117               8                0.2                500   \n",
       "59                6                0.2                200   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "85   {'max_depth': 7, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "146  {'max_depth': 9, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "118  {'max_depth': 8, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "61   {'max_depth': 6, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "90   {'max_depth': 7, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "145  {'max_depth': 9, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "62   {'max_depth': 6, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "60   {'max_depth': 6, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "117  {'max_depth': 8, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "59   {'max_depth': 6, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "\n",
       "     split1_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "85                 1.0  ...            0.988000                 1.0   \n",
       "146                1.0  ...            0.986667                 1.0   \n",
       "118                1.0  ...            0.986667                 1.0   \n",
       "61                 1.0  ...            0.989333                 1.0   \n",
       "90                 1.0  ...            0.986667                 1.0   \n",
       "145                1.0  ...            0.986667                 1.0   \n",
       "62                 1.0  ...            0.986667                 1.0   \n",
       "60                 1.0  ...            0.978667                 1.0   \n",
       "117                1.0  ...            0.986667                 1.0   \n",
       "59                 1.0  ...            0.978667                 1.0   \n",
       "\n",
       "     split25_test_score  split26_test_score  split27_test_score  \\\n",
       "85             0.978667            0.996000                 1.0   \n",
       "146            0.978667            0.997333                 1.0   \n",
       "118            0.978667            0.997333                 1.0   \n",
       "61             0.978667            0.997333                 1.0   \n",
       "90             0.978667            0.997333                 1.0   \n",
       "145            0.978667            0.997333                 1.0   \n",
       "62             0.978667            0.997333                 1.0   \n",
       "60             0.978667            0.997333                 1.0   \n",
       "117            0.978667            0.997333                 1.0   \n",
       "59             0.978667            0.997333                 1.0   \n",
       "\n",
       "     split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "85             0.985714            0.997222         0.993098        0.010205   \n",
       "146            0.980000            0.997222         0.992711        0.011000   \n",
       "118            0.980000            0.997222         0.992711        0.011000   \n",
       "61             0.980000            0.997222         0.992711        0.011277   \n",
       "90             0.980000            0.997222         0.992622        0.011314   \n",
       "145            0.980000            0.997222         0.992444        0.011591   \n",
       "62             0.977143            0.997222         0.992438        0.011383   \n",
       "60             0.980000            0.997222         0.992356        0.011209   \n",
       "117            0.980000            0.997222         0.992352        0.011784   \n",
       "59             0.977143            0.997222         0.992349        0.011561   \n",
       "\n",
       "     rank_test_score  \n",
       "85                 1  \n",
       "146                2  \n",
       "118                3  \n",
       "61                 3  \n",
       "90                 5  \n",
       "145                6  \n",
       "62                 7  \n",
       "60                 8  \n",
       "117                9  \n",
       "59                10  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9707602339181286\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.9636243386243386\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "clf_rf = RandomForestClassifier(max_depth=7, max_features=0.2, n_estimators=50,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_train_pred=clf_rf.predict(X_train)\n",
    "y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9707602339181286\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.9636243386243386\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "clf_rf = RandomForestClassifier(max_depth=9, max_features=0.2, n_estimators=1000,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_train_pred=clf_rf.predict(X_train)\n",
    "y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7060301507537688\n",
      "0.8070175438596491\n",
      "Training ROC_AUC:  0.7381067895744051\n",
      "Test ROC_AUC:  0.8339947089947088\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(max_iter=5000, random_state=random)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(max_iter=5000, random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8779767195767195"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'loss' : ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "              'penalty' : ['l2', 'l1', 'elasticnet'],\n",
    "              'random_state':[random]\n",
    "              }\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'hinge', 'penalty': 'l2', 'random_sta...</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834667</td>\n",
       "      <td>0.794667</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.762857</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>0.877977</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>l2</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'perceptron', 'penalty': 'l2', 'rando...</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834667</td>\n",
       "      <td>0.794667</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.762857</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>0.872554</td>\n",
       "      <td>0.073968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'squared_hinge', 'penalty': 'l2', 'ra...</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.861333</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.791429</td>\n",
       "      <td>0.947222</td>\n",
       "      <td>0.871776</td>\n",
       "      <td>0.072664</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>log</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'log', 'penalty': 'l1', 'random_state...</td>\n",
       "      <td>0.754667</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.913889</td>\n",
       "      <td>0.871454</td>\n",
       "      <td>0.055813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008132</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'modified_huber', 'penalty': 'elastic...</td>\n",
       "      <td>0.789333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.738667</td>\n",
       "      <td>0.890667</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.867780</td>\n",
       "      <td>0.074089</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>hinge</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'hinge', 'penalty': 'elasticnet', 'ra...</td>\n",
       "      <td>0.741333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.774286</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.867117</td>\n",
       "      <td>0.091810</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.008118</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'perceptron', 'penalty': 'elasticnet'...</td>\n",
       "      <td>0.741333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.774286</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.867117</td>\n",
       "      <td>0.091810</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>log</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'log', 'penalty': 'elasticnet', 'rand...</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.890667</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.864372</td>\n",
       "      <td>0.068407</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.006737</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'squared_hinge', 'penalty': 'l1', 'ra...</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890667</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.864095</td>\n",
       "      <td>0.063625</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'modified_huber', 'penalty': 'l1', 'r...</td>\n",
       "      <td>0.754667</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.810667</td>\n",
       "      <td>0.762667</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.068540</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.006667      0.001274         0.004168        0.000637   \n",
       "12       0.009331      0.002194         0.006503        0.002141   \n",
       "9        0.006578      0.001093         0.004035        0.000658   \n",
       "4        0.009306      0.001845         0.004193        0.000660   \n",
       "8        0.008132      0.001324         0.004144        0.000753   \n",
       "2        0.008099      0.001446         0.004368        0.000658   \n",
       "14       0.008118      0.001970         0.004096        0.000831   \n",
       "5        0.011807      0.002448         0.004667        0.000907   \n",
       "10       0.006737      0.001008         0.004231        0.000805   \n",
       "7        0.007365      0.001405         0.004567        0.001086   \n",
       "\n",
       "        param_loss param_penalty param_random_state  \\\n",
       "0            hinge            l2                 42   \n",
       "12      perceptron            l2                 42   \n",
       "9    squared_hinge            l2                 42   \n",
       "4              log            l1                 42   \n",
       "8   modified_huber    elasticnet                 42   \n",
       "2            hinge    elasticnet                 42   \n",
       "14      perceptron    elasticnet                 42   \n",
       "5              log    elasticnet                 42   \n",
       "10   squared_hinge            l1                 42   \n",
       "7   modified_huber            l1                 42   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'loss': 'hinge', 'penalty': 'l2', 'random_sta...           0.736000   \n",
       "12  {'loss': 'perceptron', 'penalty': 'l2', 'rando...           0.736000   \n",
       "9   {'loss': 'squared_hinge', 'penalty': 'l2', 'ra...           0.773333   \n",
       "4   {'loss': 'log', 'penalty': 'l1', 'random_state...           0.754667   \n",
       "8   {'loss': 'modified_huber', 'penalty': 'elastic...           0.789333   \n",
       "2   {'loss': 'hinge', 'penalty': 'elasticnet', 'ra...           0.741333   \n",
       "14  {'loss': 'perceptron', 'penalty': 'elasticnet'...           0.741333   \n",
       "5   {'loss': 'log', 'penalty': 'elasticnet', 'rand...           0.706667   \n",
       "10  {'loss': 'squared_hinge', 'penalty': 'l1', 'ra...           0.784000   \n",
       "7   {'loss': 'modified_huber', 'penalty': 'l1', 'r...           0.754667   \n",
       "\n",
       "    split1_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "0            0.992000  ...            0.834667            0.794667   \n",
       "12           0.992000  ...            0.834667            0.794667   \n",
       "9            0.986667  ...            0.776000            0.861333   \n",
       "4            0.973333  ...            0.882667            0.856000   \n",
       "8            0.992000  ...            0.866667            0.893333   \n",
       "2            0.992000  ...            0.912000            0.914667   \n",
       "14           0.992000  ...            0.912000            0.914667   \n",
       "5            0.954667  ...            0.933333            0.858667   \n",
       "10           0.960000  ...            0.890667            0.856000   \n",
       "7            0.978667  ...            0.680000            0.810667   \n",
       "\n",
       "    split25_test_score  split26_test_score  split27_test_score  \\\n",
       "0             0.914667            0.880000            0.973333   \n",
       "12            0.914667            0.880000            0.973333   \n",
       "9             0.784000            0.888000            0.973333   \n",
       "4             0.778667            0.882667            0.944000   \n",
       "8             0.738667            0.890667            0.957333   \n",
       "2             0.848000            0.880000            0.973333   \n",
       "14            0.848000            0.880000            0.973333   \n",
       "5             0.826667            0.890667            0.957333   \n",
       "10            0.778667            0.882667            0.957333   \n",
       "7             0.762667            0.882667            0.957333   \n",
       "\n",
       "    split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.762857            0.927778         0.877977        0.067909   \n",
       "12            0.762857            0.927778         0.872554        0.073968   \n",
       "9             0.791429            0.947222         0.871776        0.072664   \n",
       "4             0.785714            0.913889         0.871454        0.055813   \n",
       "8             0.822857            0.866667         0.867780        0.074089   \n",
       "2             0.774286            0.905556         0.867117        0.091810   \n",
       "14            0.774286            0.905556         0.867117        0.091810   \n",
       "5             0.822857            0.922222         0.864372        0.068407   \n",
       "10            0.800000            0.911111         0.864095        0.063625   \n",
       "7             0.785714            0.905556         0.859903        0.068540   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "12                2  \n",
       "9                 3  \n",
       "4                 4  \n",
       "8                 5  \n",
       "2                 6  \n",
       "14                6  \n",
       "5                 8  \n",
       "10                9  \n",
       "7                10  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7060301507537688\n",
      "0.8070175438596491\n",
      "Training ROC_AUC:  0.7381067895744051\n",
      "Test ROC_AUC:  0.8339947089947088\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', max_iter=5000, penalty='l2', random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8417085427135679\n",
      "0.8362573099415205\n",
      "Training ROC_AUC:  0.7939812943047357\n",
      "Test ROC_AUC:  0.791005291005291\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log', max_iter=100, penalty='l1', random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9649122807017544\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.9623015873015873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(n_estimators=1000, subsample=0.5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9935714285714285"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators' : [10, 100, 1000],\n",
    "              'learning_rate' : [0.001, 0.01, 0.1],\n",
    "              'subsample' : [0.5, 0.7, 1.0],\n",
    "              'max_depth' : [3, 7, 9]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2.012305</td>\n",
       "      <td>0.211939</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993571</td>\n",
       "      <td>0.011975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.522016</td>\n",
       "      <td>1.560077</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 9, 'n_est...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.991995</td>\n",
       "      <td>0.011942</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2.673594</td>\n",
       "      <td>0.573345</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.991936</td>\n",
       "      <td>0.014052</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.749249</td>\n",
       "      <td>2.485144</td>\n",
       "      <td>0.014646</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.991419</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>7.359962</td>\n",
       "      <td>1.438678</td>\n",
       "      <td>0.009364</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 9, 'n_esti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.991267</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.170234</td>\n",
       "      <td>0.539412</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.991217</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8.450187</td>\n",
       "      <td>2.265075</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 9, 'n_est...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.991157</td>\n",
       "      <td>0.013281</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7.468017</td>\n",
       "      <td>2.222581</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.991091</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.333309</td>\n",
       "      <td>0.070490</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.990960</td>\n",
       "      <td>0.014672</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.843419</td>\n",
       "      <td>1.155414</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "60       2.012305      0.211939         0.005731        0.001132   \n",
       "51       6.522016      1.560077         0.010372        0.002621   \n",
       "61       2.673594      0.573345         0.006513        0.001869   \n",
       "42       7.749249      2.485144         0.014646        0.009373   \n",
       "79       7.359962      1.438678         0.009364        0.001720   \n",
       "33       3.170234      0.539412         0.009055        0.004072   \n",
       "52       8.450187      2.265075         0.010005        0.002635   \n",
       "43       7.468017      2.222581         0.010684        0.003510   \n",
       "58       0.333309      0.070490         0.005915        0.001540   \n",
       "70       5.843419      1.155414         0.008245        0.001929   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_subsample  \\\n",
       "60                 0.1               3               1000             0.5   \n",
       "51                0.01               9               1000             0.5   \n",
       "61                 0.1               3               1000             0.7   \n",
       "42                0.01               7               1000             0.5   \n",
       "79                 0.1               9               1000             0.7   \n",
       "33                0.01               3               1000             0.5   \n",
       "52                0.01               9               1000             0.7   \n",
       "43                0.01               7               1000             0.7   \n",
       "58                 0.1               3                100             0.7   \n",
       "70                 0.1               7               1000             0.7   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "60  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...                1.0  ...   \n",
       "51  {'learning_rate': 0.01, 'max_depth': 9, 'n_est...                1.0  ...   \n",
       "61  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...                1.0  ...   \n",
       "42  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...                1.0  ...   \n",
       "79  {'learning_rate': 0.1, 'max_depth': 9, 'n_esti...                1.0  ...   \n",
       "33  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...                1.0  ...   \n",
       "52  {'learning_rate': 0.01, 'max_depth': 9, 'n_est...                1.0  ...   \n",
       "43  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...                1.0  ...   \n",
       "58  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...                1.0  ...   \n",
       "70  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...                1.0  ...   \n",
       "\n",
       "    split23_test_score  split24_test_score  split25_test_score  \\\n",
       "60            0.984000               1.000            0.997333   \n",
       "51            0.976000               1.000            0.978667   \n",
       "61            0.976000               1.000            0.994667   \n",
       "42            0.981333               1.000            0.981333   \n",
       "79            0.976000               0.992            0.981333   \n",
       "33            0.978667               1.000            0.986667   \n",
       "52            0.978667               1.000            0.981333   \n",
       "43            0.978667               1.000            0.976000   \n",
       "58            0.986667               1.000            0.978667   \n",
       "70            0.973333               0.992            0.984000   \n",
       "\n",
       "    split26_test_score  split27_test_score  split28_test_score  \\\n",
       "60                 1.0                 1.0            0.957143   \n",
       "51                 1.0                 1.0            0.974286   \n",
       "61                 1.0                 1.0            0.942857   \n",
       "42                 1.0                 1.0            0.960000   \n",
       "79                 1.0                 1.0            0.968571   \n",
       "33                 1.0                 1.0            0.942857   \n",
       "52                 1.0                 1.0            0.965714   \n",
       "43                 1.0                 1.0            0.974286   \n",
       "58                 1.0                 1.0            0.948571   \n",
       "70                 1.0                 1.0            0.957143   \n",
       "\n",
       "    split29_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "60            1.000000         0.993571        0.011975                1  \n",
       "51            0.997222         0.991995        0.011942                2  \n",
       "61            0.997222         0.991936        0.014052                3  \n",
       "42            0.997222         0.991419        0.013169                4  \n",
       "79            0.997222         0.991267        0.011943                5  \n",
       "33            0.997222         0.991217        0.015166                6  \n",
       "52            0.997222         0.991157        0.013281                7  \n",
       "43            0.997222         0.991091        0.014082                8  \n",
       "58            0.997222         0.990960        0.014672                9  \n",
       "70            0.997222         0.990879        0.013205               10  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9649122807017544\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.958994708994709\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.1, subsample=0.5, max_depth=3)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9649122807017544\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.958994708994709\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.01, subsample=0.5, max_depth=9)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
