{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Diagnostic\n",
    "## The goal of this project is to build a model able to predict the diagnosis of breast cancer tissues as malignant or benign. \n",
    "\n",
    "- Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. \n",
    "\n",
    "- Class distribution: 357 benign, 212 malignant. More info about this dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (roc_auc_score, confusion_matrix, recall_score, precision_score, RocCurveDisplay, \n",
    "                             accuracy_score, plot_confusion_matrix, auc)\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "X= pd.read_csv(\"X.csv\")\n",
    "y=pd.read_csv(\"y.csv\")\n",
    "y=y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping based on dec tree feature importance and multicollinearity\n",
    "xMean=X.iloc[:,0:10].copy().drop([\"perimeter_mean\", \"area_mean\", \"concave points_mean\", \"compactness_mean\"], axis=1)\n",
    "xSE=X.iloc[:,10:20].copy().drop([\"perimeter_se\", \"radius_se\", \"concavity_se\", \"compactness_se\"], axis=1)\n",
    "xWorst=X.iloc[:,20:30].copy().drop([\"perimeter_worst\", \"area_worst\", \"concavity_worst\", \"concave points_worst\", 'fractal_dimension_worst'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,10))\n",
    "# sns.heatmap(xWorst.corr(),linewidths=.1,cmap=\"YlGnBu\", annot=True, fmt= '.1f')\n",
    "# plt.yticks(rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xWorst, y, test_size=0.30, random_state=random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.949748743718593\n",
      "Test Accuracy:  0.9649122807017544\n",
      "Training ROC_AUC:  0.9423196140265762\n",
      "Test ROC_AUC:  0.958994708994709\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(random_state=random)\n",
    "lr= lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "print(\"Training Accuracy: \", lr.score(X_train, y_train))\n",
    "print(\"Test Accuracy: \", lr.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000, max_iter=5000, random_state=42, solver='newton-cg')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9884126984126984"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models and parameters\n",
    "# define grid search\n",
    "param_grid={'solver': ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "            'penalty':['l2'],\n",
    "            'C':[100, 10, 1.0, 0.1, 0.01, 1000],\n",
    "           'max_iter': [5000]}\n",
    "\n",
    "#why? keep the balance in the splits\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(lr, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=3000, max_iter=5000, random_state=42, solver='newton-cg')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9886857142857143"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models and parameters\n",
    "# define grid search\n",
    "param_grid={'solver': ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "            'penalty':['l2'],\n",
    "            'C':[900, 1000,2000,3000,3100, 3500],\n",
    "           'max_iter': [5000]}\n",
    "\n",
    "#why? keep the balance in the splits\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(lr, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.028677</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>3000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 3000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988686</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.026045</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>3000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 3000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988686</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.029338</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>3100</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 3100, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988686</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.022875</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>3100</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 3100, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988686</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>2000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988597</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>2000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988597</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.024180</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>2000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988597</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.029113</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>3500</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 3500, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988502</td>\n",
       "      <td>0.017979</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>900</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 900, 'max_iter': 5000, 'penalty': 'l2', ...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988502</td>\n",
       "      <td>0.018201</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.023341</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>3500</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 3500, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988502</td>\n",
       "      <td>0.017979</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "9        0.028677      0.003708         0.002601        0.000489    3000   \n",
       "10       0.026045      0.005020         0.002999        0.000683    3000   \n",
       "12       0.029338      0.004123         0.002798        0.000542    3100   \n",
       "13       0.022875      0.003140         0.002535        0.000498    3100   \n",
       "8        0.003268      0.000511         0.002338        0.000468    2000   \n",
       "6        0.029470      0.004110         0.002843        0.000749    2000   \n",
       "7        0.024180      0.005602         0.002901        0.000651    2000   \n",
       "15       0.029113      0.003838         0.002567        0.000667    3500   \n",
       "2        0.003266      0.000510         0.002368        0.000607     900   \n",
       "16       0.023341      0.004220         0.002767        0.000558    3500   \n",
       "\n",
       "   param_max_iter param_penalty param_solver  \\\n",
       "9            5000            l2    newton-cg   \n",
       "10           5000            l2        lbfgs   \n",
       "12           5000            l2    newton-cg   \n",
       "13           5000            l2        lbfgs   \n",
       "8            5000            l2    liblinear   \n",
       "6            5000            l2    newton-cg   \n",
       "7            5000            l2        lbfgs   \n",
       "15           5000            l2    newton-cg   \n",
       "2            5000            l2    liblinear   \n",
       "16           5000            l2        lbfgs   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "9   {'C': 3000, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "10  {'C': 3000, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "12  {'C': 3100, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "13  {'C': 3100, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "8   {'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "6   {'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "7   {'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "15  {'C': 3500, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "2   {'C': 900, 'max_iter': 5000, 'penalty': 'l2', ...           0.994667  ...   \n",
       "16  {'C': 3500, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "\n",
       "    split23_test_score  split24_test_score  split25_test_score  \\\n",
       "9             0.978667                 1.0                 1.0   \n",
       "10            0.978667                 1.0                 1.0   \n",
       "12            0.978667                 1.0                 1.0   \n",
       "13            0.978667                 1.0                 1.0   \n",
       "8             0.976000                 1.0                 1.0   \n",
       "6             0.976000                 1.0                 1.0   \n",
       "7             0.976000                 1.0                 1.0   \n",
       "15            0.978667                 1.0                 1.0   \n",
       "2             0.973333                 1.0                 1.0   \n",
       "16            0.978667                 1.0                 1.0   \n",
       "\n",
       "    split26_test_score  split27_test_score  split28_test_score  \\\n",
       "9                  1.0                 1.0            0.948571   \n",
       "10                 1.0                 1.0            0.948571   \n",
       "12                 1.0                 1.0            0.948571   \n",
       "13                 1.0                 1.0            0.948571   \n",
       "8                  1.0                 1.0            0.948571   \n",
       "6                  1.0                 1.0            0.948571   \n",
       "7                  1.0                 1.0            0.948571   \n",
       "15                 1.0                 1.0            0.945714   \n",
       "2                  1.0                 1.0            0.945714   \n",
       "16                 1.0                 1.0            0.945714   \n",
       "\n",
       "    split29_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "9                  1.0         0.988686        0.017795                1  \n",
       "10                 1.0         0.988686        0.017795                1  \n",
       "12                 1.0         0.988686        0.017795                1  \n",
       "13                 1.0         0.988686        0.017795                1  \n",
       "8                  1.0         0.988597        0.017851                5  \n",
       "6                  1.0         0.988597        0.017851                5  \n",
       "7                  1.0         0.988597        0.017851                5  \n",
       "15                 1.0         0.988502        0.017979                8  \n",
       "2                  1.0         0.988502        0.018201                8  \n",
       "16                 1.0         0.988502        0.017979                8  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9723618090452262\n",
      "0.9707602339181286\n",
      "Training ROC_AUC:  0.9684779386000378\n",
      "Test ROC_AUC:  0.9702380952380952\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(C=3000, solver='newton-cg', random_state=random, max_iter=5000)\n",
    "lr= lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "print(lr.score(X_train, y_train))\n",
    "print(lr.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 97.08\n",
      "precision : 95.31\n",
      "recall : 96.83\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Accuracy :', round(accuracy_score(y_test,y_test_pred)*100,2))\n",
    "print('precision :', round(precision_score(y_test,y_test_pred)*100,2))\n",
    "print('recall :', round(recall_score(y_test,y_test_pred)*100,2))\n",
    "\n",
    "cm = confusion_matrix(y_test,y_test_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(lr, X_test, y_test, cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'False Positive Rate')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_test_pred)\n",
    "auc_sc = auc(fpr, tpr)\n",
    "# Draw ROC curve:\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, label=\"AUC = %0.2f\"%auc_sc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Receiver Operating Characteristic(ROC) for Support Vector Machine\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.9698492462311558\n",
      "Test Score:  0.9707602339181286\n",
      "Training ROC_AUC:  0.9651222339020512\n",
      "Test ROC_AUC:  0.9702380952380952\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(C=3100, solver='liblinear', random_state=random)\n",
    "lr= lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "print(\"Training Score: \",lr.score(X_train, y_train))\n",
    "print(\"Test Score: \", lr.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100, max_iter=5000, penalty='l1', random_state=42,\n",
      "                   solver='liblinear')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9880507936507936"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models and parameters\n",
    "# define grid search\n",
    "param_grid={'solver': ['liblinear'], \n",
    "            'penalty':['l1'],\n",
    "            'C':[100, 10, 1.0, 0.1, 0.01, 1000],\n",
    "           'max_iter': [5000]}\n",
    "\n",
    "#why? keep the balance in the splits\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(lr, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.9698492462311558\n",
      "Test Score:  0.9707602339181286\n",
      "Training ROC_AUC:  0.9651222339020512\n",
      "Test ROC_AUC:  0.9702380952380952\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(penalty='l1', C=100, solver='liblinear', random_state=random)\n",
    "lr= lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "print(\"Training Score: \",lr.score(X_train, y_train))\n",
    "print(\"Test Score: \", lr.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949748743718593\n",
      "0.9473684210526315\n",
      "Training RMSE:  0.22416791983111017\n",
      "Test RMSE:  0.22941573387056177\n",
      "Training ROC_AUC:  0.9436672865960487\n",
      "Test ROC_AUC:  0.9417989417989417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#normal data helped this\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "y_train_pred=gnb.predict(X_train)\n",
    "y_test_pred=gnb.predict(X_test)\n",
    "print(gnb.score(X_train, y_train))\n",
    "print(gnb.score(X_test, y_test))\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6256281407035176\n",
      "0.631578947368421\n",
      "Training RMSE:  0.6118593460073013\n",
      "Test RMSE:  0.6069769786668839\n",
      "Training ROC_AUC:  0.5\n",
      "Test ROC_AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=6.579332246575683e-05)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9898603174603174"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'var_smoothing': np.logspace(0,-9, num=100)\n",
    "        }\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(gnb, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var_smoothing is a stability calculation to widen (or smooth) the curve and therefore account for more samples that are further away from the distribution mean. In this case, np.logspace returns numbers spaced evenly on a log scale, starts from 0, ends at -9, and generates 100 samples.\n",
    "from https://medium.com/analytics-vidhya/how-to-improve-naive-bayes-9fa698e14cba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>6.57933e-05</td>\n",
       "      <td>{'var_smoothing': 6.579332246575683e-05}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989860</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>5.3367e-05</td>\n",
       "      <td>{'var_smoothing': 5.3366992312063123e-05}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989860</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>8.11131e-05</td>\n",
       "      <td>{'var_smoothing': 8.111308307896872e-05}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989765</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>4.32876e-05</td>\n",
       "      <td>{'var_smoothing': 4.328761281083062e-05}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989594</td>\n",
       "      <td>0.016869</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'var_smoothing': 0.0001}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000151991</td>\n",
       "      <td>{'var_smoothing': 0.0001519911082952933}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.989501</td>\n",
       "      <td>0.015605</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000123285</td>\n",
       "      <td>{'var_smoothing': 0.0001232846739442066}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.989495</td>\n",
       "      <td>0.015861</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>3.51119e-05</td>\n",
       "      <td>{'var_smoothing': 3.511191734215127e-05}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989323</td>\n",
       "      <td>0.016763</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000187382</td>\n",
       "      <td>{'var_smoothing': 0.0001873817422860383}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.989317</td>\n",
       "      <td>0.015727</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>2.84804e-05</td>\n",
       "      <td>{'var_smoothing': 2.848035868435799e-05}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989146</td>\n",
       "      <td>0.016677</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "46       0.002467      0.000670         0.002833        0.000934   \n",
       "47       0.002467      0.000669         0.002901        0.000700   \n",
       "45       0.002466      0.000499         0.002500        0.000500   \n",
       "48       0.002167      0.000372         0.002700        0.000458   \n",
       "44       0.002367      0.000546         0.002700        0.000526   \n",
       "42       0.002467      0.000670         0.002567        0.000615   \n",
       "43       0.002433      0.000615         0.002767        0.000423   \n",
       "49       0.002233      0.000422         0.002701        0.000458   \n",
       "41       0.002300      0.000459         0.002634        0.000482   \n",
       "50       0.002400      0.000554         0.002367        0.000482   \n",
       "\n",
       "   param_var_smoothing                                     params  \\\n",
       "46         6.57933e-05   {'var_smoothing': 6.579332246575683e-05}   \n",
       "47          5.3367e-05  {'var_smoothing': 5.3366992312063123e-05}   \n",
       "45         8.11131e-05   {'var_smoothing': 8.111308307896872e-05}   \n",
       "48         4.32876e-05   {'var_smoothing': 4.328761281083062e-05}   \n",
       "44              0.0001                  {'var_smoothing': 0.0001}   \n",
       "42         0.000151991   {'var_smoothing': 0.0001519911082952933}   \n",
       "43         0.000123285   {'var_smoothing': 0.0001232846739442066}   \n",
       "49         3.51119e-05   {'var_smoothing': 3.511191734215127e-05}   \n",
       "41         0.000187382   {'var_smoothing': 0.0001873817422860383}   \n",
       "50         2.84804e-05   {'var_smoothing': 2.848035868435799e-05}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "46                1.0           1.000000                1.0   \n",
       "47                1.0           1.000000                1.0   \n",
       "45                1.0           1.000000                1.0   \n",
       "48                1.0           1.000000                1.0   \n",
       "44                1.0           0.997333                1.0   \n",
       "42                1.0           0.997333                1.0   \n",
       "43                1.0           0.997333                1.0   \n",
       "49                1.0           1.000000                1.0   \n",
       "41                1.0           0.997333                1.0   \n",
       "50                1.0           1.000000                1.0   \n",
       "\n",
       "    split3_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "46           0.960000  ...            0.981333            1.000000   \n",
       "47           0.960000  ...            0.981333            1.000000   \n",
       "45           0.962667  ...            0.981333            1.000000   \n",
       "48           0.957333  ...            0.978667            0.997333   \n",
       "44           0.962667  ...            0.978667            1.000000   \n",
       "42           0.970667  ...            0.973333            1.000000   \n",
       "43           0.968000  ...            0.976000            1.000000   \n",
       "49           0.957333  ...            0.978667            0.997333   \n",
       "41           0.970667  ...            0.973333            1.000000   \n",
       "50           0.957333  ...            0.976000            0.997333   \n",
       "\n",
       "    split25_test_score  split26_test_score  split27_test_score  \\\n",
       "46                 1.0                 1.0                 1.0   \n",
       "47                 1.0                 1.0                 1.0   \n",
       "45                 1.0                 1.0                 1.0   \n",
       "48                 1.0                 1.0                 1.0   \n",
       "44                 1.0                 1.0                 1.0   \n",
       "42                 1.0                 1.0                 1.0   \n",
       "43                 1.0                 1.0                 1.0   \n",
       "49                 1.0                 1.0                 1.0   \n",
       "41                 1.0                 1.0                 1.0   \n",
       "50                 1.0                 1.0                 1.0   \n",
       "\n",
       "    split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "46            0.957143            1.000000         0.989860        0.016686   \n",
       "47            0.957143            1.000000         0.989860        0.016686   \n",
       "45            0.954286            1.000000         0.989765        0.016667   \n",
       "48            0.957143            1.000000         0.989594        0.016869   \n",
       "44            0.954286            1.000000         0.989587        0.016297   \n",
       "42            0.957143            0.997222         0.989501        0.015605   \n",
       "43            0.954286            0.997222         0.989495        0.015861   \n",
       "49            0.957143            1.000000         0.989323        0.016763   \n",
       "41            0.954286            0.997222         0.989317        0.015727   \n",
       "50            0.957143            1.000000         0.989146        0.016677   \n",
       "\n",
       "    rank_test_score  \n",
       "46                1  \n",
       "47                1  \n",
       "45                3  \n",
       "48                4  \n",
       "44                5  \n",
       "42                6  \n",
       "43                7  \n",
       "49                8  \n",
       "41                9  \n",
       "50               10  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9698492462311558\n",
      "0.9766081871345029\n",
      "Training RMSE:  0.1736397240519698\n",
      "Test RMSE:  0.1529438225803745\n",
      "Training ROC_AUC:  0.9610792161936336\n",
      "Test ROC_AUC:  0.9682539682539683\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(var_smoothing=6.579332246575683e-05)\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "y_train_pred=gnb.predict(X_train)\n",
    "y_test_pred=gnb.predict(X_test)\n",
    "print(gnb.score(X_train, y_train))\n",
    "print(gnb.score(X_test, y_test))\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x23f176dec40>"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(gnb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9422110552763819\n",
      "0.9473684210526315\n",
      "Training ROC_AUC:  0.9610792161936336\n",
      "Test ROC_AUC:  0.9682539682539683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#KNN is more sensititve to noise\n",
    "transformer = RobustScaler().fit(xWorst)\n",
    "X_scaled=transformer.transform(xWorst)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(xWorst, y, test_size=0.30, random_state=random)\n",
    "#scaling didn't help*****************************\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_train_prediction=knn.predict(X_train_scaled)\n",
    "y_prediction=knn.predict(X_test_scaled)\n",
    "print(knn.score(X_train_scaled, y_train))\n",
    "print(knn.score(X_test_scaled, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x23f44d341f0>"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAo+UlEQVR4nO3deXwV5dn/8c+VBdkXCVgFWUUW2YSACopaqgWxpdbWrS7oz1p3+9Ta2sc+VdFqF+r2iAt14bFaXKrihiuViljKZkQMggFRgigERNYASa7fHzM5nJycJCeQc0Jyvu/X67xyZuaemWsSuK+5Z7lvc3dERCR9ZdR3ACIiUr+UCERE0pwSgYhImlMiEBFJc0oEIiJpLqu+A6itnJwc79atW32HISLSoCxcuLDI3TvEW9bgEkG3bt1YsGBBfYchItKgmNlnVS3TpSERkTSnRCAikuaUCERE0pwSgYhImlMiEBFJc0lLBGb2iJmtM7MlVSw3M7vHzArMbLGZDUlWLCIiUrVktgimAmOqWT4W6BV+LgHuT2IsIiJShaS9R+Du75hZt2qKjAce86Af7Llm1tbMDnb3tcmKSUQkEWVlTkmZU+ZOafn3qHnR06Xl80r3LCuN+sQrX1rmlHrUNsuXuVNaWkapQ2lZGaVlRLZd6k5u13aMOjzuO2H7pD5fKOsErI6aLgznVUoEZnYJQauBLl26pCQ4kcbGfU8FVFoW5xNvfkwFVxa7rKxiZRa9jdjKM3q7VVWspXHmRW87dl61lXVs3HHmVbXt/dWlx/dsdInA4syL+xdw9ynAFIDc3Nz9968k9SK2QknobKyK8nsqxOBsLP688Gecs7cKy2LnlZXFVLbl88rLRMcQZ14kjphl7pSWVl2R7zne+v5LxZdhkJlhwceMjAwjq3w6nJeZWXFZhhlZ4bzychlmHJCdQTOLWb+8fEYV287IIDODPcui5kWWVdhmvGUV52VmZITxUnGZRccVNS/mWOLNyzAwi1dt7rv6TASFwKFR052BL+oplrS1pXg381dtpGjrrirPpkoTaRbHOVOLrqBit12xgop/plbjtsMy+6sKFU90JRanMoudF11xZWdm0DS7cmVW47bLK5CYedGVYbz9VVhWm/3FqZhj58VWzJkZlrTKTRJXn4ngReBKM3sSOAr4RvcHkm9nSSkLP/ua9wo2MGdFEYsLv6lVZZphwRlO+ZlOhkFWZgYZFpzhVFqWkUFGhbOfPWWaZGcGy2zPmVR5+fLKJfosK9jmnoor+owqtjLLNMjMDJfFqcwywsopXmVWYVnMthOqWMN5Ig1F0hKBmU0DTgByzKwQuBHIBnD3B4AZwClAAbAduDBZsaSz0jLnoy++YU7BBt5bUcS8Tzeys6SMzAxjYOc2XHZ8T0Yc1p4uBzav0CytUKFnEDmr09mbSOOTzKeGzq5huQNXJGv/6crdWbF+G++tKGJOQRH/XrGBzcUlAPQ+qBXnHNWFkT1zOKrHgbRqml3P0YrI/qDBdUMtla39Zkdwxl9QxJwVRXy1eScAnds1Y2z/gxlxWHtG9MyhQ6sD6jlSEdkfKRE0QJu27+LfK4Jr/O8VbGBl0TYADmzRhBE92zPysBxG9syhS/vm9RypiDQESgQNwI5dpcxftZE54eWej77YjDu0aJLJ8O4Hcs5RXRjRM4c+32qlm5QiUmtKBPuh3aVlLC7cxJyCDcwpKOL9zzexq7SM7EzjyC7t+Pnowxl5WHsGHdqW7Ez1Gygi+0aJYD9QVuYs+2oLcwqKeG/FBv6zcgPbdpViBkcc0poLR3ZjxGE5DOvWjuZN9CcTkbqlWqWerN64nXcL9jzZs2HbLgC657TgB0d2YuRhORzToz3tWjSp50hFpLFTIkiRoq07eW/Fnid7Vm/cAUDHVgcw6vAOkZu8h7RtVs+Riki6USJIki3Fu5n36cbIi1wff7kFgFZNszimR3suPrYHIw9rT88OLfWSlojUKyWCOrKzpJRFn22KvMj1Qdh1wwFZGeR2a8evxvRmZM8c+ndqQ6ae7BGR/YgSwT7YWVLKzKXreG5RIe8WFFG8u4wMg4Gd23Lp8T0Y2TOHIV3b0TQ7s75DFRGpkhJBLbk7eas38eyiQl76YC3f7NjNQa0P4KxhXRh5WNB1Q2t13SAiDYgSQYLWfrOD5xat4dlFhaxcv40DsjIY0/9bnD6kMyMPy9HlHhFpsJQIqrF9Vwmvf/Qlzy5cw5wVRbjD8G4H8rNRPThlwMHqtE1EGgUlghhlZc68VRt5dmEhMz5cy7ZdpRx6YDOu/nYvfjikE13bt6jvEEVE6pQSQeizDdt4dtEanltUSOHXO2h5QBbjBh7M6UM6M6zbgerDR0QarbRPBAs/28gfXv2Y+au+xgyOPSyHX57cm+8e8S2aNdHTPiLS+KV9Irjh+SVs3LaLX43pzWlHduLgNnqzV0TSS1ongsKvt/Pxl1u44ZS+/HRUj/oOR0SkXqR1H8b//HgdAKP7dqznSERE6k9aJ4KZS9fRPacFPTq0rO9QRETqTdomgm07S/j3ig2M7qPWgIikt7RNBLM/KWJXaRmj+x5U36GIiNSrtE0E//z4K1o1zSK3W7v6DkVEpF6lZSIoK3P++fF6TujdUWP+ikjaS8tacPGabyjaulP3B0RESNNEMHv5eszghN4d6jsUEZF6l5aJoPDrHeS0PIC2zTUwvIhIWiaCr7YUc1DrA+o7DBGR/UJaJoJ1m3fSsVXT+g5DRGS/kJ6JQC0CEZGItEsEu0vL2LBtFx3UIhARAZKcCMxsjJktM7MCM7s+zvI2ZvaSmX1gZh+Z2YXJjAegaOtO3FGLQEQklLREYGaZwGRgLNAPONvM+sUUuwLId/dBwAnAX8wsqY/yrNu8E0D3CEREQslsEQwHCtx9pbvvAp4ExseUcaCVmRnQEtgIlCQxJr7aXAyoRSAiUi6ZiaATsDpqujCcF+1eoC/wBfAhcI27l8VuyMwuMbMFZrZg/fr1+xTUui1Bi+Cg1moRiIhAchNBvNHePWb6u0AecAgwGLjXzFpXWsl9irvnuntuhw779jbwus3FmEH7FnqZTEQEkpsICoFDo6Y7E5z5R7sQeM4DBcCnQJ8kxsS6LTvJaXkAWepsTkQESG4imA/0MrPu4Q3gs4AXY8p8DowGMLODgN7AyiTGxFebi+nYSvcHRETKJW3wencvMbMrgdeBTOARd//IzC4Nlz8A3AJMNbMPCS4l/drdi5IVEwQtAt0fEBHZI2mJAMDdZwAzYuY9EPX9C+DkZMYQ66vNOxnQqU0qdykisl9LqwvlJaVlbNi2k45qEYiIRKRVIijaugt3dI9ARCRKWiWCPS+TqUUgIlIurRLBnpfJ1CIQESmXVomgvEWgfoZERPZIq0SwbstOzCCnpd4qFhEpl16JYHMx7VvorWIRkWhpVSMGL5Pp/oCISLS0SgTqXkJEpLK0SgTqXkJEpLKEE4GZtUhmIMlWUlpG0dadahGIiMSoMRGY2QgzyweWhtODzOy+pEdWxzZsC98qVotARKSCRFoEdxIMILMBwN0/AEYlM6hk0FvFIiLxJXRpyN1Xx8wqTUIsSbVn0HpdGhIRiZZIN9SrzWwE4OEAM1cTXiZqSHaWBEMhN2uSWc+RiIjsXxJpEVwKXEEw8HwhwdjClycxJhERSaFEWgS93f0n0TPMbCQwJzkhiYhIKiXSIvjfBOeJiEgDVGWLwMyOAUYAHczsF1GLWhOMQSwiIo1AdZeGmgAtwzKtouZvBn6UzKBERCR1qkwE7v4v4F9mNtXdP0thTCIikkKJ3CzebmZ/Bo4AIm9jufu3kxaViIikTCI3i58APga6AzcDq4D5SYxJRERSKJFE0N7dHwZ2u/u/3P0i4OgkxyUiIimSyKWh3eHPtWY2DvgC6Jy8kEREJJUSSQS3mlkb4FqC9wdaAz9PZlAiIpI6NSYCd385/PoNcCJE3iwWEZFGoLoXyjKBMwj6GHrN3ZeY2anAfwPNgCNTE6KIiCRTdS2Ch4FDgXnAPWb2GXAMcL27T09BbCIikgLVJYJcYKC7l5lZU6AIOMzdv0xNaCIikgrVPT66y93LANy9GFhe2yRgZmPMbJmZFZjZ9VWUOcHM8szsIzP7V222LyIi+666FkEfM1scfjegZzhtgLv7wOo2HN5jmAycRDCOwXwze9Hd86PKtAXuA8a4++dm1nHvD0VERPZGdYmg7z5uezhQ4O4rAczsSWA8kB9V5hzgOXf/HMDd1+3jPkVEpJaq63RuXzua6wREj3VcCBwVU+ZwINvMZhH0cHq3uz8WuyEzuwS4BKBLly77GJaIiERLaPD6vWRx5nnMdBYwFBgHfBf4HzM7vNJK7lPcPdfdczt06FD3kYqIpLFE3izeW4UEj5+W60zQPUVsmSJ33wZsM7N3gEHA8iTGJSIiURJqEZhZMzPrXcttzwd6mVl3M2sCnAW8GFPmBeA4M8sys+YEl46W1nI/IiKyD2pMBGb2PSAPeC2cHmxmsRV6Je5eAlwJvE5QuT/t7h+Z2aVmdmlYZmm43cUEL6495O5L9vJYRERkLyRyaegmgieAZgG4e56ZdUtk4+4+A5gRM++BmOk/A39OZHsiIlL3Erk0VOLu3yQ9EhERqReJtAiWmNk5QKaZ9QKuBt5LblgiIpIqibQIriIYr3gn8HeC7qh/nsSYREQkhRJpEfR29xuAG5IdjIiIpF4iLYI7zOxjM7vFzI5IekQiIpJSNSYCdz8ROAFYD0wxsw/N7LfJDkxERFIjoRfK3P1Ld78HuJTgnYLfJTMoERFJnUReKOtrZjeZ2RLgXoInhjonPTIREUmJRG4WPwpMA05299i+gkREpIGrMRG4+9GpCEREROpHlYnAzJ529zPM7EMqdh+d0AhlIiLSMFTXIrgm/HlqKgIREZH6UeXNYndfG3693N0/i/4Al6cmPBERSbZEHh89Kc68sXUdiIiI1I/q7hFcRnDm38PMFkctagXMSXZgIiKSGtXdI/g78CpwO3B91Pwt7r4xqVGJiEjKVJcI3N1XmdkVsQvM7EAlAxGRxqGmFsGpwEKCx0ctapkDPZIYl4iIpEiVicDdTw1/dk9dOCIikmqJ9DU00sxahN/PNbM7zKxL8kMTEZFUSOTx0fuB7WY2CPgV8Bnwt6RGJSIiKZPo4PUOjAfudve7CR4hFRGRRiCR3ke3mNlvgPOA48wsE8hOblgiIpIqibQIziQYuP4id/8S6AT8OalRiYhIyiQyVOWXwBNAGzM7FSh298eSHpmIiKREIk8NnQHMA34MnAH8x8x+lOzAREQkNRK5R3ADMMzd1wGYWQfgLeAfyQxMRERSI5F7BBnlSSC0IcH1RESkAUikRfCamb1OMG4xBDePZyQvJBERSaVExiy+zsx+CBxL0N/QFHd/PumRiYhISlQ3HkEvYBLQE/gQ+KW7r0lVYCIikhrVXet/BHgZOJ2gB9L/re3GzWyMmS0zswIzu76acsPMrFRPI4mIpF51l4Zauftfw+/LzGxRbTYcvoE8mWCoy0Jgvpm96O75ccr9EXi9NtsXEZG6UV0iaGpmR7JnHIJm0dPuXlNiGA4UuPtKADN7kqC/ovyYclcBzwLDahm7iIjUgeoSwVrgjqjpL6OmHfh2DdvuBKyOmi4EjoouYGadgNPCbVWZCMzsEuASgC5d1AO2iEhdqm5gmhP3cdsWZ57HTN8F/NrdS83iFY/EMgWYApCbmxu7DRER2QeJvEewtwqBQ6OmOwNfxJTJBZ4Mk0AOcIqZlbj79CTGJSIiUZKZCOYDvcysO7AGOAs4J7pA9DCYZjYVeFlJQEQktZKWCNy9xMyuJHgaKBN4xN0/MrNLw+UPJGvfIiKSuBoTgQXXbX4C9HD3ieF4xd9y93k1revuM4jpjqKqBODuExKKWERE6lQincfdBxwDnB1ObyF4P0BERBqBRC4NHeXuQ8zsfQB3/9rMmiQ5LhERSZFEWgS7w7d/HSLjEZQlNSoREUmZRBLBPcDzQEcz+z3wLnBbUqMSEZGUSaQb6ifMbCEwmuAlsR+4+9KkRyYiIimRyFNDXYDtwEvR89z982QGJiIiqZHIzeJXCO4PGNAU6A4sA45IYlwiIpIiiVwaGhA9bWZDgJ8lLSIREUmpWg9CH3Y/rS6jRUQaiUTuEfwiajIDGAKsT1pEIiKSUoncI2gV9b2E4J7Bs8kJR0REUq3aRBC+SNbS3a9LUTwiIpJiVd4jMLMsdy8luBQkIiKNVHUtgnkESSDPzF4EngG2lS909+eSHJuIiKRAIvcIDgQ2EIwrXP4+gQNKBCIijUB1iaBj+MTQEvYkgHIaN1hEpJGoLhFkAi1JbBB6ERFpoKpLBGvdfWLKIhERkXpR3ZvF8VoCIiLSyFSXCEanLAoREak3VSYCd9+YykBERKR+1LrTORERaVyUCERE0pwSgYhImlMiEBFJc0oEIiJpTolARCTNKRGIiKQ5JQIRkTSnRCAikuaSmgjMbIyZLTOzAjO7Ps7yn5jZ4vDznpkNSmY8IiJSWdISQTje8WRgLNAPONvM+sUU+xQ43t0HArcAU5IVj4iIxJfMFsFwoMDdV7r7LuBJYHx0AXd/z92/DifnAp2TGI+IiMSRzETQCVgdNV0YzqvK/wNejbfAzC4xswVmtmD9+vV1GKKIiCQzESQ8spmZnUiQCH4db7m7T3H3XHfP7dChQx2GKCIiiQxev7cKgUOjpjsDX8QWMrOBwEPAWHffkMR4REQkjmS2COYDvcysu5k1Ac4CXowuYGZdgOeA89x9eRJjERGRKiStReDuJWZ2JfA6kAk84u4fmdml4fIHgN8B7YH7zAygxN1zkxWTiIhUlsxLQ7j7DGBGzLwHor5fDFyczBhERKR6erNYRCTNKRGIiKQ5JQIRkTSnRCAikuaUCERE0pwSgYhImlMiEBFJc0oEIiJpTolARCTNKRGIiKQ5JQIRkTSnRCAikuaUCERE0pwSgYhImlMiEBFJc0oEIiJpTolARCTNKRGIiKQ5JQIRkTSnRCAikuaUCERE0lxWfQcgEs/u3bspLCykuLi4vkMRaVCaNm1K586dyc7OTngdJQLZLxUWFtKqVSu6deuGmdV3OCINgruzYcMGCgsL6d69e8Lr6dKQ7JeKi4tp3769koBILZgZ7du3r3VLWolA9ltKAiK1tzf/b5QIRETSnBKBSBVatmwZ+T5jxgx69erF559/zk033UTz5s1Zt25d3LJVOeWUU9i0aVO1ZU444QQWLFhQaf7UqVO58sorEw++FiZNmkSfPn3o378/gwYN4rHHHqs2lr2xYMECrr76agB27tzJd77zHQYPHsxTTz3FxRdfTH5+/j5t/6677orEDVBSUkJOTg6/+c1vKpTr1q0bRUVFkelZs2Zx6qmnRqZfffVVcnNz6du3L3369OGXv/zlPsUFsHDhQgYMGMBhhx3G1VdfjbtXKrNr1y4uvPBCBgwYwKBBg5g1a1Zk2bRp0xgwYAADBw5kzJgxkfjvvfdeHn300X2OD5QIRGo0c+ZMrrrqKl577TW6dOkCQE5ODn/5y19qtZ0ZM2bQtm3bJERYPXenrKws7rIHHniAN998k3nz5rFkyRLeeeeduBXVvsrNzeWee+4B4P3332f37t3k5eVx5pln8tBDD9GvX7+Et1VaWlphuqSkhEceeYRzzjknMu+NN96gd+/ePP300wkfz5IlS7jyyit5/PHHWbp0KUuWLKFHjx4Jx1WVyy67jClTpvDJJ5/wySef8Nprr1Uq89e//hWADz/8kDfffJNrr72WsrIySkpKuOaaa3j77bdZvHgxAwcO5N577wXgoosuivxO95USgez3bn7pI8588N91+rn5pY8S2vfs2bP56U9/yiuvvELPnj0j8y+66CKeeuopNm7cWGmdxx9/nOHDhzN48GB+9rOfRSqu6LPRW265hT59+nDSSSdx9tlnM2nSpMj6zzzzDMOHD+fwww9n9uzZkfmrV69mzJgx9O7dm5tvvjky/4477qB///7079+fu+66C4BVq1bRt29fLr/8coYMGcLq1auZMGEC/fv3Z8CAAdx5550A3Hbbbdx33320bt0agDZt2nDBBRdUOqbLLruM3NxcjjjiCG688cbI/Ouvv55+/foxcODAyNnzM888E2ldjBo1Cthz5r1u3TrOPfdc8vLyGDx4MCtWrKjQ8njjjTc45phjGDJkCD/+8Y/ZunVr5Hc3ceJEjj32WJ555pkKsf3zn/9kyJAhZGXteQhy2rRpXHPNNXTp0oW5c+fG+ctW9qc//YkbbriBPn36AJCVlcXll1+e0LpVWbt2LZs3b+aYY47BzDj//POZPn16pXL5+fmMHj0agI4dO9K2bVsWLFiAu+PubNu2DXdn8+bNHHLIIQA0b96cbt26MW/evH2KEfT4qEiVdu7cyfjx45k1a1akcijXsmVLLrroIu6+++4KlfLSpUt56qmnmDNnDtnZ2Vx++eU88cQTnH/++ZEyCxYs4Nlnn+X999+npKSEIUOGMHTo0MjykpIS5s2bx4wZM7j55pt56623ACJn7c2bN2fYsGGMGzcOM+PRRx/lP//5D+7OUUcdxfHHH0+7du1YtmwZjz76KPfddx8LFy5kzZo1LFmyBIBNmzaxZcsWtmzZUiHBVeX3v/89Bx54IKWlpYwePZrFixfTuXNnnn/+eT7++GPMLHLZa+LEibz++ut06tSp0qWwjh078tBDDzFp0iRefvnlCsuKioq49dZbeeutt2jRogV//OMfueOOO/jd734HBM/Hv/vuu5VimzNnToXf344dO5g5cyYPPvggmzZtYtq0aRxzzDE1HuOSJUu49tprayz39ttv81//9V+V5jdv3pz33nuvwrw1a9bQuXPnyHTnzp1Zs2ZNpXUHDRrECy+8wFlnncXq1atZuHAhq1evZvjw4dx///0MGDCAFi1a0KtXLyZPnhxZLzc3l9mzZzN8+PAa466OEoHs92783hH1st/s7GxGjBjBww8/zN13311p+dVXX83gwYMrVB4zZ85k4cKFDBs2DAgqpY4dO1ZY791332X8+PE0a9YMgO9973sVlv/whz8EYOjQoaxatSoy/6STTqJ9+/aRMu+++y5mxmmnnUaLFi0i82fPns33v/99unbtytFHHw1Ajx49WLlyJVdddRXjxo3j5JNPZuvWrQk/YfL0008zZcoUSkpKWLt2Lfn5+fTr14+mTZty8cUXM27cuMi19pEjRzJhwgTOOOOMyLEkYu7cueTn5zNy5EgguG4eXYGfeeaZcddbu3Ytffv2jUy//PLLnHjiiTRv3pzTTz+dW265hTvvvJPMzMy4x1vbp2xOPPFE8vLyEiob77JUvP1ddNFFLF26lNzcXLp27cqIESPIyspi9+7d3H///bz//vv06NGDq666ittvv53f/va3QJBYP/7441rFH09SLw2Z2RgzW2ZmBWZ2fZzlZmb3hMsXm9mQZMYjUhsZGRk8/fTTzJ8/n9tuu63S8rZt23LOOedw3333Rea5OxdccAF5eXnk5eWxbNkybrrppgrr1XTN+oADDgAgMzOTkpKSyPzYCsTMqt1WeXIAaNeuHR988AEnnHACkydP5uKLL6Z169a0aNGClStXVhvPp59+yqRJk5g5cyaLFy9m3LhxFBcXk5WVxbx58zj99NOZPn06Y8aMAYL7DrfeeiurV69m8ODBbNiwodrtl3N3TjrppMjvLj8/n4cffjju8URr1qxZhefmp02bxltvvUW3bt0YOnQoGzZs4O233wagffv2fP3115GyGzduJCcnB4AjjjiChQsX1hjn22+/zeDBgyt9RowYUals586dKSwsjEwXFhZGLu1Ey8rK4s477yQvL48XXniBTZs20atXr0jC6dmzJ2bGGWecUaHVUVxcHDmh2BdJSwRmlglMBsYC/YCzzSz2jtBYoFf4uQS4P1nxiOyN5s2b8/LLL/PEE09UqJTK/eIXv+DBBx+MVNijR4/mH//4R+SJoo0bN/LZZ59VWOfYY4/lpZdeori4mK1bt/LKK68kFMubb77Jxo0b2bFjB9OnT2fkyJGMGjWK6dOns337drZt28bzzz/PcccdV2ndoqIiysrKImfIixYtAuA3v/kNV1xxBZs3bwZg8+bNTJkypcK6mzdvpkWLFrRp04avvvqKV199FYCtW7fyzTffcMopp3DXXXdFKq0VK1Zw1FFHMXHiRHJycli9enVCx3f00UczZ84cCgoKANi+fTvLly+vcb2+fftG1tm8eTPvvvsun3/+OatWrWLVqlVMnjyZadOmAcGTUH/729+A4Kbz448/zoknngjAddddx2233RbZZ1lZGXfccUel/ZW3CGI/sZeFAA4++GBatWrF3LlzcXcee+wxxo8fX6lc+d8Pgr9zVlYW/fr1o1OnTuTn57N+/frIsujWz/Lly+nfv3+Nv6OaJPPS0HCgwN1XApjZk8B4IPo5sfHAYx6c1sw1s7ZmdrC7r01iXCK1cuCBB/Laa68xatSoyNljuZycHE477bTIzdd+/fpx6623cvLJJ1NWVkZ2djaTJ0+ma9eukXWGDRvG97//fQYNGkTXrl3Jzc2lTZs2NcZx7LHHct5551FQUMA555xDbm4uABMmTIhcI7744os58sgjK1xSguBa9YUXXhh5euj2228HgpvAW7duZdiwYWRnZ5OdnV3pOvmgQYM48sgjOeKII+jRo0fk0s2WLVsYP348xcXFuHvkd3DdddfxySef4O6MHj2aQYMG8a9//avG4+vQoQNTp07l7LPPZufOnQDceuutHH744dWuN3bsWM477zwAnnvuOb797W9HWlUA48eP51e/+hU7d+7kf/7nf7jssssYNGgQ7s6YMWM499xzARg4cCB33XUXZ599Ntu3b8fMGDduXI1x1+T+++9nwoQJ7Nixg7FjxzJ27FgAXnzxRRYsWMDEiRNZt24d3/3ud8nIyKBTp06RZHXIIYdw4403MmrUKLKzs+natStTp06NbHvOnDkVbt7vtfK70nX9AX4EPBQ1fR5wb0yZl4Fjo6ZnArlxtnUJsABY0KVLF98bC1Zt9MseX+Brvt6+V+tLauXn59d3CEm1ZcsWd3fftm2bDx061BcuXFjPETVsP/jBD3z58uX1HUZKLVq0yM8999y4y+L9/wEWeBX1dTJbBPHuwMRe0EykDO4+BZgCkJubu1cPOQ/t2o6hXYfWXFAkBS655BLy8/MpLi7mggsuYMgQ3R7bF3/4wx9Yu3YtvXr1qu9QUqaoqIhbbrmlTraVzERQCBwaNd0Z+GIvyog0On//+9/rO4RGpXfv3vTu3bu+w0ipk046qc62lcynhuYDvcysu5k1Ac4CXowp8yJwfvj00NHAN677AxLyJLzhKtLY7c3/m6S1CNy9xMyuBF4HMoFH3P0jM7s0XP4AMAM4BSgAtgMXJiseaViaNm3Khg0b1BW1SC14OB5B06ZNa7WeNbSzrtzcXK+rjrBk/6URykT2TlUjlJnZQnfPjbeO3iyW/VJ2dnatRlgSkb2nTudERNKcEoGISJpTIhARSXMN7maxma0HPquxYHw5QFGNpRoXHXN60DGnh3055q7u3iHeggaXCPaFmS2o6q55Y6VjTg865vSQrGPWpSERkTSnRCAikubSLRFMqblIo6NjTg865vSQlGNOq3sEIiJSWbq1CEREJIYSgYhImmuUicDMxpjZMjMrMLPr4yw3M7snXL7YzBr8qCAJHPNPwmNdbGbvmdmg+oizLtV0zFHlhplZqZn9KJXxJUMix2xmJ5hZnpl9ZGY1jxG5n0vg33YbM3vJzD4Ij7lB92JsZo+Y2TozW1LF8rqvv6oauqyhfgi6vF4B9ACaAB8A/WLKnAK8SjBC2tHAf+o77hQc8wigXfh9bDocc1S5fxJ0ef6j+o47BX/ntgTjgncJpzvWd9wpOOb/Bv4Yfu8AbASa1Hfs+3DMo4AhwJIqltd5/dUYWwTDgQJ3X+nuu4AngfExZcYDj3lgLtDWzA5OdaB1qMZjdvf33P3rcHIuwWhwDVkif2eAq4BngXWpDC5JEjnmc4Dn3P1zAHdv6MedyDE70MqCgStaEiSCktSGWXfc/R2CY6hKnddfjTERdAJWR00XhvNqW6Yhqe3x/D+CM4qGrMZjNrNOwGnAAymMK5kS+TsfDrQzs1lmttDMzk9ZdMmRyDHfC/QlGOb2Q+Aady9LTXj1os7rr8Y4HkG84axin5FNpExDkvDxmNmJBIng2KRGlHyJHPNdwK/dvbSRjHKWyDFnAUOB0UAz4N9mNtfdlyc7uCRJ5Ji/C+QB3wZ6Am+a2Wx335zk2OpLnddfjTERFAKHRk13JjhTqG2ZhiSh4zGzgcBDwFh335Ci2JIlkWPOBZ4Mk0AOcIqZlbj79JREWPcS/bdd5O7bgG1m9g4wCGioiSCRY74Q+IMHF9ALzOxToA8wLzUhplyd11+N8dLQfKCXmXU3sybAWcCLMWVeBM4P774fDXzj7mtTHWgdqvGYzawL8BxwXgM+O4xW4zG7e3d37+bu3YB/AJc34CQAif3bfgE4zsyyzKw5cBSwNMVx1qVEjvlzghYQZnYQ0BtYmdIoU6vO669G1yJw9xIzuxJ4neCJg0fc/SMzuzRc/gDBEySnAAXAdoIzigYrwWP+HdAeuC88Qy7xBtxzY4LH3KgkcszuvtTMXgMWA2XAQ+4e9zHEhiDBv/MtwFQz+5Dgssmv3b3Bdk9tZtOAE4AcMysEbgSyIXn1l7qYEBFJc43x0pCIiNSCEoGISJpTIhARSXNKBCIiaU6JQEQkzSkRyH4p7C00L+rTrZqyW+tgf1PN7NNwX4vM7Ji92MZDZtYv/P7fMcve29cYw+2U/16WhD1utq2h/GAzO6Uu9i2Nlx4flf2SmW1195Z1XbaabUwFXnb3f5jZycAkdx+4D9vb55hq2q6Z/R+w3N1/X035CUCuu19Z17FI46EWgTQIZtbSzGaGZ+sfmlmlnkbN7GAzeyfqjPm4cP7JZvbvcN1nzKymCvod4LBw3V+E21piZj8P57Uws1fC/u+XmNmZ4fxZZpZrZn8AmoVxPBEu2xr+fCr6DD1siZxuZplm9mczm29BH/M/S+DX8m/CzsbMbLgF40y8H/7sHb6JOxE4M4zlzDD2R8L9vB/v9yhpqL773tZHn3gfoJSgI7E84HmCt+Bbh8tyCN6qLG/Rbg1/XgvcEH7PBFqFZd8BWoTzfw38Ls7+phKOVwD8GPgPQedtHwItCLo3/gg4Ejgd+GvUum3Cn7MIzr4jMUWVKY/xNOD/wu9NCHqRbAZcAvw2nH8AsADoHifOrVHH9wwwJpxuDWSF378DPBt+nwDcG7X+bcC54fe2BH0Qtajvv7c+9ftpdF1MSKOxw90Hl0+YWTZwm5mNIug6oRNwEPBl1DrzgUfCstPdPc/Mjgf6AXPCrjWaEJxJx/NnM/stsJ6gh9bRwPMedOCGmT0HHAe8Bkwysz8SXE6aXYvjehW4x8wOAMYA77j7jvBy1EDbM4paG6AX8GnM+s3MLA/oBiwE3owq/39m1ougJ8rsKvZ/MvB9M/tlON0U6ELD7o9I9pESgTQUPyEYfWqou+82s1UElViEu78TJopxwN/M7M/A18Cb7n52Avu4zt3/UT5hZt+JV8jdl5vZUIL+Xm43szfcfWIiB+HuxWY2i6Dr5DOBaeW7A65y99dr2MQOdx9sZm2Al4ErgHsI+tt5291PC2+sz6pifQNOd/dlicQr6UH3CKShaAOsC5PAiUDX2AJm1jUs81fgYYLh/uYCI82s/Jp/czM7PMF9vgP8IFynBcFlndlmdgiw3d0fByaF+4m1O2yZxPMkQUdhxxF0pkb487Lydczs8HCfcbn7N8DVwC/DddoAa8LFE6KKbiG4RFbudeAqC5tHZnZkVfuQ9KFEIA3FE0CumS0gaB18HKfMCUCemb1PcB3/bndfT1AxTjOzxQSJoU8iO3T3RQT3DuYR3DN4yN3fBwYA88JLNDcAt8ZZfQqwuPxmcYw3CMalfcuD4RchGCciH1hkwaDlD1JDiz2M5QOCrpn/RNA6mUNw/6Dc20C/8pvFBC2H7DC2JeG0pDk9PioikubUIhARSXNKBCIiaU6JQEQkzSkRiIikOSUCEZE0p0QgIpLmlAhERNLc/wcMNNlNUZAMwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(knn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=28, p=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9776624338624339"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'n_neighbors': np.arange(1,40),\n",
    "            'p':[1,2]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(knn, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 28, 'p': 1}</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.915714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977662</td>\n",
       "      <td>0.023088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 27, 'p': 1}</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888571</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>0.977385</td>\n",
       "      <td>0.025139</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 29, 'p': 1}</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976930</td>\n",
       "      <td>0.023602</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 31, 'p': 1}</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976921</td>\n",
       "      <td>0.023630</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 34, 'p': 1}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.905714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976806</td>\n",
       "      <td>0.024479</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 30, 'p': 1}</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976797</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 26, 'p': 1}</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.891429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976675</td>\n",
       "      <td>0.026449</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 33, 'p': 1}</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.908571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976629</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 35, 'p': 1}</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.904286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976626</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 32, 'p': 1}</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.982667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.901429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976517</td>\n",
       "      <td>0.024589</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "54       0.002700      0.000781         0.003801        0.000600   \n",
       "52       0.003133      0.000670         0.004634        0.000949   \n",
       "56       0.002601      0.000663         0.003767        0.000803   \n",
       "60       0.002666      0.000745         0.003867        0.000763   \n",
       "66       0.002433      0.000495         0.003700        0.000737   \n",
       "58       0.002566      0.000716         0.004101        0.001165   \n",
       "50       0.002666      0.000789         0.003934        0.000814   \n",
       "64       0.002733      0.000814         0.004068        0.001124   \n",
       "68       0.002567      0.000761         0.004000        0.001000   \n",
       "62       0.002800      0.000791         0.004100        0.001248   \n",
       "\n",
       "   param_n_neighbors param_p                       params  split0_test_score  \\\n",
       "54                28       1  {'n_neighbors': 28, 'p': 1}           0.980000   \n",
       "52                27       1  {'n_neighbors': 27, 'p': 1}           0.988000   \n",
       "56                29       1  {'n_neighbors': 29, 'p': 1}           0.981333   \n",
       "60                31       1  {'n_neighbors': 31, 'p': 1}           0.977333   \n",
       "66                34       1  {'n_neighbors': 34, 'p': 1}           0.966667   \n",
       "58                30       1  {'n_neighbors': 30, 'p': 1}           0.981333   \n",
       "50                26       1  {'n_neighbors': 26, 'p': 1}           0.989333   \n",
       "64                33       1  {'n_neighbors': 33, 'p': 1}           0.970667   \n",
       "68                35       1  {'n_neighbors': 35, 'p': 1}           0.969333   \n",
       "62                32       1  {'n_neighbors': 32, 'p': 1}           0.974667   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  split23_test_score  \\\n",
       "54           0.958667           0.996000  ...            0.944000   \n",
       "52           0.960000           0.996000  ...            0.944000   \n",
       "56           0.957333           0.996000  ...            0.946667   \n",
       "60           0.956000           0.996000  ...            0.944000   \n",
       "66           0.958667           0.996000  ...            0.941333   \n",
       "58           0.958667           0.996000  ...            0.945333   \n",
       "50           0.960000           0.997333  ...            0.945333   \n",
       "64           0.956000           0.996000  ...            0.941333   \n",
       "68           0.960000           0.997333  ...            0.940000   \n",
       "62           0.956000           0.998667  ...            0.941333   \n",
       "\n",
       "    split24_test_score  split25_test_score  split26_test_score  \\\n",
       "54            0.984000            0.998667            1.000000   \n",
       "52            0.981333            0.998667            1.000000   \n",
       "56            0.984000            0.997333            0.997333   \n",
       "60            0.980000            0.997333            0.993333   \n",
       "66            0.985333            0.997333            0.994667   \n",
       "58            0.981333            0.997333            0.994667   \n",
       "50            0.980000            1.000000            1.000000   \n",
       "64            0.985333            0.997333            0.992000   \n",
       "68            0.985333            0.996000            0.989333   \n",
       "62            0.982667            0.997333            0.992000   \n",
       "\n",
       "    split27_test_score  split28_test_score  split29_test_score  \\\n",
       "54            0.998667            0.915714            1.000000   \n",
       "52            1.000000            0.888571            0.998611   \n",
       "56            1.000000            0.910000            1.000000   \n",
       "60            1.000000            0.907143            1.000000   \n",
       "66            0.997333            0.905714            1.000000   \n",
       "58            1.000000            0.910000            1.000000   \n",
       "50            0.998667            0.891429            1.000000   \n",
       "64            0.997333            0.908571            1.000000   \n",
       "68            0.997333            0.904286            1.000000   \n",
       "62            0.998667            0.901429            1.000000   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "54         0.977662        0.023088                1  \n",
       "52         0.977385        0.025139                2  \n",
       "56         0.976930        0.023602                3  \n",
       "60         0.976921        0.023630                4  \n",
       "66         0.976806        0.024479                5  \n",
       "58         0.976797        0.023984                6  \n",
       "50         0.976675        0.026449                7  \n",
       "64         0.976629        0.024051                8  \n",
       "68         0.976626        0.025118                9  \n",
       "62         0.976517        0.024589               10  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221105527638191\n",
      "0.9415204678362573\n",
      "Training ROC_AUC:  0.9610792161936336\n",
      "Test ROC_AUC:  0.9682539682539683\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=28, p=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9246231155778895\n",
      "0.9473684210526315\n",
      "Training ROC_AUC:  0.9610792161936336\n",
      "Test ROC_AUC:  0.9682539682539683\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=34, p=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9195979899497487\n",
      "0.9415204678362573\n",
      "Training ROC_AUC:  0.8980081399423196\n",
      "Test ROC_AUC:  0.9272486772486772\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=50, kernel='poly')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9829529100529102"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'kernel' : ['poly', 'rbf', 'sigmoid'],\n",
    "             'C' : [50, 10, 1.0, 0.1, 0.01],\n",
    "             'gamma' : ['scale']}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>50</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 50, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982953</td>\n",
       "      <td>0.020047</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.981269</td>\n",
       "      <td>0.019002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>50</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.981084</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980828</td>\n",
       "      <td>0.020175</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980624</td>\n",
       "      <td>0.019626</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911429</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.980081</td>\n",
       "      <td>0.021249</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979143</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004332</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.938667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.022002</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.917333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970474</td>\n",
       "      <td>0.022087</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.930667</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.905714</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.957450</td>\n",
       "      <td>0.025718</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.004700      0.001069         0.003534        0.000956      50   \n",
       "4        0.003633      0.001168         0.002900        0.000790      10   \n",
       "1        0.003433      0.000715         0.002600        0.000664      50   \n",
       "6        0.003066      0.000442         0.002567        0.000496       1   \n",
       "3        0.003433      0.000668         0.002533        0.000562      10   \n",
       "7        0.003499      0.000671         0.002701        0.000458       1   \n",
       "9        0.002933      0.000443         0.002500        0.000500     0.1   \n",
       "10       0.004332      0.000537         0.002902        0.000539     0.1   \n",
       "13       0.005866      0.000990         0.003635        0.001016    0.01   \n",
       "12       0.004933      0.000998         0.003568        0.000919    0.01   \n",
       "\n",
       "   param_gamma param_kernel                                           params  \\\n",
       "0        scale         poly    {'C': 50, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "4        scale          rbf     {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "1        scale          rbf     {'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "6        scale         poly   {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "3        scale         poly    {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "7        scale          rbf    {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "9        scale         poly   {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "10       scale          rbf    {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "13       scale          rbf   {'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "12       scale         poly  {'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  ...  split23_test_score  \\\n",
       "0            1.000000           0.989333  ...            0.960000   \n",
       "4            0.989333           0.986667  ...            0.957333   \n",
       "1            0.994667           0.984000  ...            0.957333   \n",
       "6            0.992000           0.984000  ...            0.957333   \n",
       "3            0.992000           0.984000  ...            0.957333   \n",
       "7            0.986667           0.973333  ...            0.957333   \n",
       "9            0.989333           0.949333  ...            0.960000   \n",
       "10           0.970667           0.938667  ...            0.952000   \n",
       "13           0.962667           0.917333  ...            0.949333   \n",
       "12           0.946667           0.877333  ...            0.941333   \n",
       "\n",
       "    split24_test_score  split25_test_score  split26_test_score  \\\n",
       "0             0.992000            1.000000            1.000000   \n",
       "4             0.981333            0.997333            1.000000   \n",
       "1             0.989333            1.000000            1.000000   \n",
       "6             0.984000            0.997333            0.994667   \n",
       "3             0.984000            0.997333            1.000000   \n",
       "7             0.984000            0.997333            0.997333   \n",
       "9             0.981333            0.997333            0.976000   \n",
       "10            0.978667            0.989333            0.981333   \n",
       "13            0.976000            0.986667            0.960000   \n",
       "12            0.962667            0.981333            0.930667   \n",
       "\n",
       "    split27_test_score  split28_test_score  split29_test_score  \\\n",
       "0             1.000000            0.920000            1.000000   \n",
       "4             1.000000            0.925714            0.997222   \n",
       "1             0.997333            0.925714            0.997222   \n",
       "6             1.000000            0.922857            1.000000   \n",
       "3             1.000000            0.922857            1.000000   \n",
       "7             1.000000            0.911429            0.997222   \n",
       "9             1.000000            0.928571            1.000000   \n",
       "10            1.000000            0.917143            1.000000   \n",
       "13            0.997333            0.914286            1.000000   \n",
       "12            0.986667            0.905714            0.986111   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "0          0.982953        0.020047                1  \n",
       "4          0.981269        0.019002                2  \n",
       "1          0.981084        0.018827                3  \n",
       "6          0.980828        0.020175                4  \n",
       "3          0.980624        0.019626                5  \n",
       "7          0.980081        0.021249                6  \n",
       "9          0.979143        0.019523                7  \n",
       "10         0.974888        0.022002                8  \n",
       "13         0.970474        0.022087                9  \n",
       "12         0.957450        0.025718               10  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9472361809045227\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  0.9389639093285894\n",
      "Test ROC_AUC:  0.9543650793650793\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=50, kernel='poly')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321608040201005\n",
      "0.9532163742690059\n",
      "Training ROC_AUC:  0.9228726988490876\n",
      "Test ROC_AUC:  0.9497354497354498\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=10, kernel='poly')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7663739411866044\n",
      "0.7428791076062855\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore',sparse=False)\n",
    "trainy_p = enc.fit_transform(y_train.to_numpy().reshape(-1,1))\n",
    "testy_p = enc.transform(y_test.to_numpy().reshape(-1,1))\n",
    "\n",
    "pls=PLSRegression(n_components=8)\n",
    "pls.fit(X_train_full, trainy_p)\n",
    "y_train_pred=pls.predict(X_train_full)\n",
    "#print(y_train_pred)\n",
    "y_test_pred=pls.predict(X_test_full)\n",
    "print(pls.score(X_train_full, trainy_p))\n",
    "print(pls.score(X_test_full, testy_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33941848,  0.82247677,  0.72304763, -0.05403946, -0.13889642,\n",
       "        1.63842282,  1.25964924,  0.5593925 ,  0.58157642,  0.0649855 ,\n",
       "        0.19050589,  0.65443225,  0.10422365,  0.49122839,  0.08993242,\n",
       "        0.83643059,  0.11382774, -0.18876128, -0.44817639,  0.94804801,\n",
       "        0.34017233,  0.10343666,  1.35526776, -0.11992418,  0.03813068,\n",
       "        0.17937062,  0.08450634,  0.2262079 ,  0.0284011 ,  1.05511498,\n",
       "       -0.02382478, -0.00833233,  0.19627962,  0.05483098, -0.05068765,\n",
       "        0.18591114,  0.52176524,  0.30340465,  0.80883849,  0.19293505,\n",
       "       -0.16054904,  0.8827977 ,  0.07510889, -0.00405496,  0.5368415 ,\n",
       "        0.22861266,  0.01511657,  0.0938028 ,  0.14926136, -0.00177114,\n",
       "        0.7985145 ,  1.18027993,  0.39208475,  0.3699705 , -0.10522685,\n",
       "        0.15536076,  0.04114256,  1.4617453 ,  0.61825245, -0.01327722,\n",
       "        0.10313582,  1.16622132,  1.33430912,  0.15828871,  0.03929542,\n",
       "        0.4173121 ,  1.04950373,  1.13624015,  0.0178229 ,  0.22342205,\n",
       "        0.90554357,  0.84163946,  0.11474773,  0.82234328,  0.04651494,\n",
       "        0.21139626,  0.19862936,  0.39367713, -0.15047874,  0.27450037,\n",
       "        0.58288984, -0.13519912,  0.52215012,  1.11146004,  0.63813848,\n",
       "        0.95856318,  1.37981298,  0.89996001,  0.09000397,  0.0858522 ,\n",
       "        0.14959364,  0.26973952,  0.17562758, -0.05259799,  0.01465141,\n",
       "        0.00354325,  0.97754341,  1.03595383, -0.05714314,  0.78800123,\n",
       "        0.70091003, -0.29395598,  0.82711941,  0.8105231 ,  0.15358522,\n",
       "        0.24511529,  0.15758585,  1.17270823,  0.37038599,  0.20234136,\n",
       "        0.77533027,  0.09027947,  0.38241093,  1.0141972 ,  0.10307738,\n",
       "        1.3553283 , -0.12436318,  0.17319644, -0.06898011,  1.0790116 ,\n",
       "        0.0551047 ,  0.00771969,  0.14938068,  0.84467291,  0.38435705,\n",
       "        1.0860414 ,  0.84347866,  0.09317465,  0.02473545,  1.02966692,\n",
       "        1.17149845,  1.48239222,  0.16716464,  0.03542444,  0.24384278,\n",
       "        0.80384702,  0.33901062,  0.37238497,  0.38334416,  0.85468181,\n",
       "        0.05304433,  1.15469694, -0.18391229, -0.09987028,  0.82761852,\n",
       "       -0.02359956,  1.0956601 ,  1.01000435,  0.4412859 , -0.08000156,\n",
       "        0.50998038,  0.01640041, -0.26869779,  0.14174447, -0.02895911,\n",
       "        1.46112966,  0.83655606, -0.06904627,  0.14331906, -0.13383626,\n",
       "       -0.46936807, -0.01918295,  0.06703851,  0.1264759 ,  0.49119557,\n",
       "        0.03606174,  0.0852242 ,  0.38291617, -0.02869652,  0.71894442,\n",
       "        0.41770306])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9415204678362573\n",
      "Training RMSE:  0.0\n",
      "Test RMSE:  0.2418254167033372\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.9437830687830688\n"
     ]
    }
   ],
   "source": [
    "# Decision trees\n",
    "from sklearn import tree\n",
    "clf=tree.DecisionTreeClassifier(random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9415204678362573\n",
      "Training RMSE:  0.0\n",
      "Test RMSE:  0.2418254167033372\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.9437830687830688\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=random)\n",
    "# Decision trees\n",
    "from sklearn import tree\n",
    "clf_tree=tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_tree=clf_tree.fit(X_train_full, y_train)\n",
    "y_train_pred=clf_tree.predict(X_train_full)\n",
    "y_test_pred=clf_tree.predict(X_test_full)\n",
    "print(clf_tree.score(X_train_full, y_train))\n",
    "print(clf_tree.score(X_test_full, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'max_features': 0.6, 'max_leaf_nodes': 40, 'min_samples_leaf': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9751825396825399"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxDepth=clf.tree_.max_depth\n",
    "param_grid = {'max_depth':range(1, maxDepth+1),\n",
    "              'max_features':[0.2,0.4,0.6,0.8], \n",
    "              'max_leaf_nodes':[20,30,40,50],\n",
    "             'min_samples_leaf': [1,2,5,10]}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.975183</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.905714</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>0.023623</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.973611</td>\n",
       "      <td>0.974724</td>\n",
       "      <td>0.027291</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.937333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.944286</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.972661</td>\n",
       "      <td>0.024171</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.950667</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.905714</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.971325</td>\n",
       "      <td>0.030036</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.938571</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.970907</td>\n",
       "      <td>0.026905</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.970777</td>\n",
       "      <td>0.025163</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950667</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.970275</td>\n",
       "      <td>0.027695</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.918667</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.970223</td>\n",
       "      <td>0.024462</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.937333</td>\n",
       "      <td>0.897143</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.969390</td>\n",
       "      <td>0.028835</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "555       0.002570      0.000618         0.002531        0.000766   \n",
       "563       0.002600      0.000611         0.002489        0.000556   \n",
       "507       0.002833      0.000820         0.002534        0.000670   \n",
       "379       0.002700      0.000458         0.002434        0.000496   \n",
       "503       0.002695      0.000935         0.002467        0.000562   \n",
       "231       0.002466      0.000561         0.002569        0.000559   \n",
       "383       0.002700      0.000458         0.002367        0.000482   \n",
       "499       0.002500      0.000563         0.002500        0.000619   \n",
       "311       0.002533      0.000499         0.002467        0.000499   \n",
       "443       0.002667      0.000537         0.002466        0.000499   \n",
       "\n",
       "    param_max_depth param_max_features param_max_leaf_nodes  \\\n",
       "555               9                0.6                   40   \n",
       "563               9                0.8                   20   \n",
       "507               8                0.8                   40   \n",
       "379               6                0.8                   40   \n",
       "503               8                0.8                   30   \n",
       "231               4                0.6                   30   \n",
       "383               6                0.8                   50   \n",
       "499               8                0.8                   20   \n",
       "311               5                0.8                   30   \n",
       "443               7                0.8                   40   \n",
       "\n",
       "    param_min_samples_leaf                                             params  \\\n",
       "555                     10  {'max_depth': 9, 'max_features': 0.6, 'max_lea...   \n",
       "563                     10  {'max_depth': 9, 'max_features': 0.8, 'max_lea...   \n",
       "507                     10  {'max_depth': 8, 'max_features': 0.8, 'max_lea...   \n",
       "379                     10  {'max_depth': 6, 'max_features': 0.8, 'max_lea...   \n",
       "503                     10  {'max_depth': 8, 'max_features': 0.8, 'max_lea...   \n",
       "231                     10  {'max_depth': 4, 'max_features': 0.6, 'max_lea...   \n",
       "383                     10  {'max_depth': 6, 'max_features': 0.8, 'max_lea...   \n",
       "499                     10  {'max_depth': 8, 'max_features': 0.8, 'max_lea...   \n",
       "311                     10  {'max_depth': 5, 'max_features': 0.8, 'max_lea...   \n",
       "443                     10  {'max_depth': 7, 'max_features': 0.8, 'max_lea...   \n",
       "\n",
       "     split0_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "555           1.000000  ...            0.956000            0.965333   \n",
       "563           0.989333  ...            0.962667            0.956000   \n",
       "507           0.997333  ...            0.993333            0.960000   \n",
       "379           0.993333  ...            0.956000            0.994667   \n",
       "503           1.000000  ...            0.957333            0.994667   \n",
       "231           0.990667  ...            0.952000            0.965333   \n",
       "383           0.997333  ...            0.953333            1.000000   \n",
       "499           0.978667  ...            0.950667            0.922667   \n",
       "311           0.998667  ...            0.932000            0.984000   \n",
       "443           1.000000  ...            0.957333            0.956000   \n",
       "\n",
       "     split25_test_score  split26_test_score  split27_test_score  \\\n",
       "555            0.948000            0.997333            0.994667   \n",
       "563            0.974667            0.997333            0.994667   \n",
       "507            0.964000            1.000000            0.994667   \n",
       "379            0.937333            1.000000            0.969333   \n",
       "503            0.950667            0.970667            0.952000   \n",
       "231            0.974667            0.993333            0.994667   \n",
       "383            0.964000            0.970667            0.984000   \n",
       "499            0.926667            0.970667            0.972000   \n",
       "311            0.918667            0.972000            0.969333   \n",
       "443            0.976000            0.970667            0.937333   \n",
       "\n",
       "     split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "555            0.907143            0.987500         0.975183        0.023286   \n",
       "563            0.905714            0.994444         0.974895        0.023623   \n",
       "507            0.900000            0.973611         0.974724        0.027291   \n",
       "379            0.944286            0.986111         0.972661        0.024171   \n",
       "503            0.905714            0.986111         0.971325        0.030036   \n",
       "231            0.938571            0.988889         0.970907        0.026905   \n",
       "383            0.910000            0.986111         0.970777        0.025163   \n",
       "499            0.970000            0.994444         0.970275        0.027695   \n",
       "311            0.978571            0.979167         0.970223        0.024462   \n",
       "443            0.897143            0.991667         0.969390        0.028835   \n",
       "\n",
       "     rank_test_score  \n",
       "555                1  \n",
       "563                2  \n",
       "507                3  \n",
       "379                4  \n",
       "503                5  \n",
       "231                6  \n",
       "383                7  \n",
       "499                8  \n",
       "311                9  \n",
       "443               10  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949748743718593\n",
      "0.9415204678362573\n",
      "Training RMSE:  0.22416791983111017\n",
      "Test RMSE:  0.2418254167033372\n",
      "Training ROC_AUC:  0.9328859060402684\n",
      "Test ROC_AUC:  0.9305555555555556\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(max_depth= 9, max_features= 0.6, max_leaf_nodes= 40, min_samples_leaf= 10)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'max_features': 0.6, 'max_leaf_nodes': 40, 'min_samples_leaf': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9726941798941798"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxDepth=clf_tree.tree_.max_depth\n",
    "param_grid = {'max_depth':range(1, maxDepth+1),\n",
    "              'max_features':[0.2,0.4,0.6,0.8], \n",
    "              'max_leaf_nodes':[20,30,40,50],\n",
    "             'min_samples_leaf': [1,2,5,10]}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train_full, y_train)\n",
    "print(grid_search.best_params_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9597989949748744\n",
      "0.935672514619883\n",
      "Training RMSE:  0.2005018828468342\n",
      "Test RMSE:  0.25362863675089403\n",
      "Training ROC_AUC:  0.9611331230964124\n",
      "Test ROC_AUC:  0.9358465608465609\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(random_state=42, max_depth= 6, max_features= 0.6, max_leaf_nodes= 40, min_samples_leaf= 10)\n",
    "clf=clf.fit(X_train_full, y_train)\n",
    "y_train_pred=clf.predict(X_train_full)\n",
    "y_test_pred=clf.predict(X_test_full)\n",
    "print(clf.score(X_train_full, y_train))\n",
    "print(clf.score(X_test_full, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9532163742690059\n",
      "Training RMSE:  0.0\n",
      "Test RMSE:  0.21629522817435004\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9707602339181286\n",
      "Training RMSE:  0.0\n",
      "Test RMSE:  0.17099639201419234\n",
      "Training ROC_AUC:  0.9611331230964124\n",
      "Test ROC_AUC:  0.9358465608465609\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf.fit(X_train_full, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train_full)\n",
    "rf_y_test_pred=clf_rf.predict(X_test_full)\n",
    "print(clf_rf.score(X_train_full, y_train))\n",
    "print(clf_rf.score(X_test_full, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=5, max_features=0.2, n_estimators=50,\n",
      "                       random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9890978835978836"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_depth':np.arange(4, 10),\n",
    "              'max_features':[0.2,0.4,0.6,0.8],\n",
    "              'n_estimators': [10,50,100,200,300,500,1000]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf_rf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.080411</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>0.007629</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989098</td>\n",
       "      <td>0.015055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.499257</td>\n",
       "      <td>0.049769</td>\n",
       "      <td>0.031053</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989070</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.775025</td>\n",
       "      <td>0.027734</td>\n",
       "      <td>0.048404</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988941</td>\n",
       "      <td>0.018010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.785903</td>\n",
       "      <td>0.060294</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>0.021426</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988808</td>\n",
       "      <td>0.018131</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.468184</td>\n",
       "      <td>0.030034</td>\n",
       "      <td>0.030772</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988804</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.453185</td>\n",
       "      <td>0.029835</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988793</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.306089</td>\n",
       "      <td>0.022111</td>\n",
       "      <td>0.021274</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988789</td>\n",
       "      <td>0.017389</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.757056</td>\n",
       "      <td>0.038540</td>\n",
       "      <td>0.048170</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988712</td>\n",
       "      <td>0.017649</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.476321</td>\n",
       "      <td>0.073647</td>\n",
       "      <td>0.030036</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988712</td>\n",
       "      <td>0.017649</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.789759</td>\n",
       "      <td>0.078979</td>\n",
       "      <td>0.049453</td>\n",
       "      <td>0.008743</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988712</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "29        0.080411      0.007810         0.007629        0.000800   \n",
       "144       0.499257      0.049769         0.031053        0.002824   \n",
       "145       0.775025      0.027734         0.048404        0.003294   \n",
       "33        0.785903      0.060294         0.053105        0.021426   \n",
       "32        0.468184      0.030034         0.030772        0.003233   \n",
       "60        0.453185      0.029835         0.033536        0.021233   \n",
       "59        0.306089      0.022111         0.021274        0.002123   \n",
       "89        0.757056      0.038540         0.048170        0.003813   \n",
       "88        0.476321      0.073647         0.030036        0.003936   \n",
       "117       0.789759      0.078979         0.049453        0.008743   \n",
       "\n",
       "    param_max_depth param_max_features param_n_estimators  \\\n",
       "29                5                0.2                 50   \n",
       "144               9                0.2                300   \n",
       "145               9                0.2                500   \n",
       "33                5                0.2                500   \n",
       "32                5                0.2                300   \n",
       "60                6                0.2                300   \n",
       "59                6                0.2                200   \n",
       "89                7                0.2                500   \n",
       "88                7                0.2                300   \n",
       "117               8                0.2                500   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "29   {'max_depth': 5, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "144  {'max_depth': 9, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "145  {'max_depth': 9, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "33   {'max_depth': 5, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "32   {'max_depth': 5, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "60   {'max_depth': 6, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "59   {'max_depth': 6, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "89   {'max_depth': 7, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "88   {'max_depth': 7, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "117  {'max_depth': 8, 'max_features': 0.2, 'n_estim...                1.0   \n",
       "\n",
       "     split1_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "29            0.997333  ...            0.986667                 1.0   \n",
       "144           0.997333  ...            0.976000                 1.0   \n",
       "145           0.997333  ...            0.973333                 1.0   \n",
       "33            0.997333  ...            0.973333                 1.0   \n",
       "32            0.997333  ...            0.976000                 1.0   \n",
       "60            0.997333  ...            0.976000                 1.0   \n",
       "59            0.997333  ...            0.976000                 1.0   \n",
       "89            0.997333  ...            0.976000                 1.0   \n",
       "88            0.997333  ...            0.976000                 1.0   \n",
       "117           0.997333  ...            0.976000                 1.0   \n",
       "\n",
       "     split25_test_score  split26_test_score  split27_test_score  \\\n",
       "29             0.986667                 1.0            0.997333   \n",
       "144            0.992000                 1.0            0.997333   \n",
       "145            0.989333                 1.0            0.997333   \n",
       "33             0.986667                 1.0            0.997333   \n",
       "32             0.986667                 1.0            0.997333   \n",
       "60             0.986667                 1.0            0.997333   \n",
       "59             0.986667                 1.0            0.997333   \n",
       "89             0.989333                 1.0            0.997333   \n",
       "88             0.989333                 1.0            0.997333   \n",
       "117            0.989333                 1.0            0.997333   \n",
       "\n",
       "     split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "29             0.945714                 1.0         0.989098        0.015055   \n",
       "144            0.930000                 1.0         0.989070        0.018181   \n",
       "145            0.930000                 1.0         0.988941        0.018010   \n",
       "33             0.928571                 1.0         0.988808        0.018131   \n",
       "32             0.928571                 1.0         0.988804        0.018054   \n",
       "60             0.928571                 1.0         0.988793        0.017532   \n",
       "59             0.928571                 1.0         0.988789        0.017389   \n",
       "89             0.928571                 1.0         0.988712        0.017649   \n",
       "88             0.928571                 1.0         0.988712        0.017649   \n",
       "117            0.928571                 1.0         0.988712        0.017862   \n",
       "\n",
       "     rank_test_score  \n",
       "29                 1  \n",
       "144                2  \n",
       "145                3  \n",
       "33                 4  \n",
       "32                 5  \n",
       "60                 6  \n",
       "59                 7  \n",
       "89                 8  \n",
       "88                 8  \n",
       "117                8  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949748743718593\n",
      "0.9649122807017544\n",
      "Training RMSE:  0.0708881205008336\n",
      "Test RMSE:  0.1873171623163388\n",
      "Training ROC_AUC:  0.9611331230964124\n",
      "Test ROC_AUC:  0.9358465608465609\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "clf_rf = RandomForestClassifier(max_depth=5, max_features=0.2, n_estimators=50,random_state=42)\n",
    "clf_rf.fit(X_train_full, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train_full)\n",
    "rf_y_test_pred=clf_rf.predict(X_test_full)\n",
    "print(clf_rf.score(X_train_full, y_train))\n",
    "print(clf_rf.score(X_test_full, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824120603015075\n",
      "0.9590643274853801\n",
      "Training RMSE:  0.13261952985323264\n",
      "Test RMSE:  0.20232565955562798\n",
      "Training ROC_AUC:  0.9611331230964124\n",
      "Test ROC_AUC:  0.9358465608465609\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "clf_rf = RandomForestClassifier(max_depth=5, max_features=0.2, n_estimators=50,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.678391959798995\n",
      "0.672514619883041\n",
      "Training RMSE:  0.5671049640066688\n",
      "Test RMSE:  0.5722633835193014\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(max_iter=5, random_state=random)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(loss='log', max_iter=100, penalty='l1', random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8942721518987342"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'loss' : ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "              'penalty' : ['l2', 'l1', 'elasticnet'],\n",
    "              'max_iter' : [5,10,100,1000],\n",
    "              'random_state':[random]\n",
    "              }\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'log', 'max_iter': 1000, 'penalty': '...</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.894272</td>\n",
       "      <td>0.045877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>log</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'log', 'max_iter': 100, 'penalty': 'l...</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.894272</td>\n",
       "      <td>0.045877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'hinge', 'max_iter': 100, 'penalty': ...</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.886741</td>\n",
       "      <td>0.053229</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'hinge', 'max_iter': 1000, 'penalty':...</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.886741</td>\n",
       "      <td>0.053229</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'log', 'max_iter': 1000, 'penalty': '...</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.869335</td>\n",
       "      <td>0.039246</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>log</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'log', 'max_iter': 100, 'penalty': 'l...</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.869335</td>\n",
       "      <td>0.039246</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'squared_hinge', 'max_iter': 1000, 'p...</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.854399</td>\n",
       "      <td>0.040515</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'squared_hinge', 'max_iter': 100, 'pe...</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.854399</td>\n",
       "      <td>0.040515</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'modified_huber', 'max_iter': 100, 'p...</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.839177</td>\n",
       "      <td>0.075626</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'modified_huber', 'max_iter': 1000, '...</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.839177</td>\n",
       "      <td>0.075626</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "22       0.004800      0.000748         0.002601        0.000800   \n",
       "19       0.004599      0.000489         0.001801        0.000400   \n",
       "6        0.003000      0.000003         0.001801        0.000401   \n",
       "9        0.003600      0.000800         0.002001        0.000634   \n",
       "21       0.004400      0.000490         0.001600        0.000490   \n",
       "18       0.004200      0.000748         0.001800        0.000400   \n",
       "47       0.004202      0.000748         0.002199        0.000400   \n",
       "44       0.004199      0.001165         0.001801        0.000400   \n",
       "31       0.003401      0.000490         0.001599        0.000490   \n",
       "34       0.006000      0.002607         0.002400        0.001356   \n",
       "\n",
       "        param_loss param_max_iter param_penalty param_random_state  \\\n",
       "22             log           1000            l1                 42   \n",
       "19             log            100            l1                 42   \n",
       "6            hinge            100            l2                 42   \n",
       "9            hinge           1000            l2                 42   \n",
       "21             log           1000            l2                 42   \n",
       "18             log            100            l2                 42   \n",
       "47   squared_hinge           1000    elasticnet                 42   \n",
       "44   squared_hinge            100    elasticnet                 42   \n",
       "31  modified_huber            100            l1                 42   \n",
       "34  modified_huber           1000            l1                 42   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "22  {'loss': 'log', 'max_iter': 1000, 'penalty': '...             0.9375   \n",
       "19  {'loss': 'log', 'max_iter': 100, 'penalty': 'l...             0.9375   \n",
       "6   {'loss': 'hinge', 'max_iter': 100, 'penalty': ...             0.9250   \n",
       "9   {'loss': 'hinge', 'max_iter': 1000, 'penalty':...             0.9250   \n",
       "21  {'loss': 'log', 'max_iter': 1000, 'penalty': '...             0.8000   \n",
       "18  {'loss': 'log', 'max_iter': 100, 'penalty': 'l...             0.8000   \n",
       "47  {'loss': 'squared_hinge', 'max_iter': 1000, 'p...             0.8000   \n",
       "44  {'loss': 'squared_hinge', 'max_iter': 100, 'pe...             0.8000   \n",
       "31  {'loss': 'modified_huber', 'max_iter': 100, 'p...             0.7250   \n",
       "34  {'loss': 'modified_huber', 'max_iter': 1000, '...             0.7250   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "22             0.8750             0.9500           0.822785   \n",
       "19             0.8750             0.9500           0.822785   \n",
       "6              0.8625             0.9500           0.797468   \n",
       "9              0.8625             0.9500           0.797468   \n",
       "21             0.9000             0.9125           0.873418   \n",
       "18             0.9000             0.9125           0.873418   \n",
       "47             0.8875             0.8250           0.848101   \n",
       "44             0.8875             0.8250           0.848101   \n",
       "31             0.8375             0.9625           0.822785   \n",
       "34             0.8375             0.9625           0.822785   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "22           0.886076         0.894272        0.045877                1  \n",
       "19           0.886076         0.894272        0.045877                1  \n",
       "6            0.898734         0.886741        0.053229                3  \n",
       "9            0.898734         0.886741        0.053229                3  \n",
       "21           0.860759         0.869335        0.039246                5  \n",
       "18           0.860759         0.869335        0.039246                5  \n",
       "47           0.911392         0.854399        0.040515                7  \n",
       "44           0.911392         0.854399        0.040515                7  \n",
       "31           0.848101         0.839177        0.075626                9  \n",
       "34           0.848101         0.839177        0.075626                9  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9346733668341709\n",
      "0.9473684210526315\n",
      "Training RMSE:  0.2555907532870255\n",
      "Test RMSE:  0.22941573387056177\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log', max_iter=100, penalty='l1', random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8165829145728644\n",
      "0.8245614035087719\n",
      "Training RMSE:  0.4282722094966421\n",
      "Test RMSE:  0.4188539082916955\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', max_iter=100, penalty='l2', random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9707602339181286\n",
      "Training RMSE:  0.0\n",
      "Test RMSE:  0.17099639201419234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(subsample=0.7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9598101265822784"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators' : [10, 100, 1000],\n",
    "              'learning_rate' : [0.001, 0.01, 0.1],\n",
    "              'subsample' : [0.5, 0.7, 1.0],\n",
    "              'max_depth' : [3, 7, 9]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.118609</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.959810</td>\n",
       "      <td>0.021522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.131758</td>\n",
       "      <td>0.099346</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.959778</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.808336</td>\n",
       "      <td>0.159826</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.959747</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.220215</td>\n",
       "      <td>0.012056</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.957310</td>\n",
       "      <td>0.025734</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.319774</td>\n",
       "      <td>0.083062</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.957278</td>\n",
       "      <td>0.028137</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.110582</td>\n",
       "      <td>0.100556</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.954810</td>\n",
       "      <td>0.023158</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3.439545</td>\n",
       "      <td>0.191416</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 9, 'n_est...</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.954778</td>\n",
       "      <td>0.026983</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.874465</td>\n",
       "      <td>0.047949</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.954778</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2.330774</td>\n",
       "      <td>0.133451</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 9, 'n_esti...</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.954747</td>\n",
       "      <td>0.012850</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.030552</td>\n",
       "      <td>0.121324</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.954715</td>\n",
       "      <td>0.029273</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "58       0.118609      0.014278         0.002399        0.000490   \n",
       "70       2.131758      0.099346         0.006200        0.000748   \n",
       "69       1.808336      0.159826         0.006000        0.001095   \n",
       "67       0.220215      0.012056         0.002401        0.000488   \n",
       "43       2.319774      0.083062         0.006001        0.000894   \n",
       "34       1.110582      0.100556         0.004199        0.000981   \n",
       "52       3.439545      0.191416         0.008801        0.001939   \n",
       "33       0.874465      0.047949         0.003600        0.000490   \n",
       "78       2.330774      0.133451         0.007202        0.000402   \n",
       "42       2.030552      0.121324         0.005801        0.001166   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_subsample  \\\n",
       "58                 0.1               3                100             0.7   \n",
       "70                 0.1               7               1000             0.7   \n",
       "69                 0.1               7               1000             0.5   \n",
       "67                 0.1               7                100             0.7   \n",
       "43                0.01               7               1000             0.7   \n",
       "34                0.01               3               1000             0.7   \n",
       "52                0.01               9               1000             0.7   \n",
       "33                0.01               3               1000             0.5   \n",
       "78                 0.1               9               1000             0.5   \n",
       "42                0.01               7               1000             0.5   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "58  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...             0.9875   \n",
       "70  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...             0.9625   \n",
       "69  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...             0.9750   \n",
       "67  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...             0.9625   \n",
       "43  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...             0.9750   \n",
       "34  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...             0.9750   \n",
       "52  {'learning_rate': 0.01, 'max_depth': 9, 'n_est...             0.9625   \n",
       "33  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...             0.9750   \n",
       "78  {'learning_rate': 0.1, 'max_depth': 9, 'n_esti...             0.9750   \n",
       "42  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...             0.9875   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "58             0.9250             0.9625           0.974684   \n",
       "70             0.9625             0.9625           0.962025   \n",
       "69             0.9625             0.9625           0.962025   \n",
       "67             0.9125             0.9875           0.974684   \n",
       "43             0.9125             0.9875           0.974684   \n",
       "34             0.9125             0.9625           0.974684   \n",
       "52             0.9125             0.9875           0.974684   \n",
       "33             0.9125             0.9750           0.974684   \n",
       "78             0.9375             0.9625           0.949367   \n",
       "42             0.9125             0.9875           0.949367   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "58           0.949367         0.959810        0.021522                1  \n",
       "70           0.949367         0.959778        0.005209                2  \n",
       "69           0.936709         0.959747        0.012520                3  \n",
       "67           0.949367         0.957310        0.025734                4  \n",
       "43           0.936709         0.957278        0.028137                5  \n",
       "34           0.949367         0.954810        0.023158                6  \n",
       "52           0.936709         0.954778        0.026983                7  \n",
       "33           0.936709         0.954778        0.025799                7  \n",
       "78           0.949367         0.954747        0.012850                9  \n",
       "42           0.936709         0.954715        0.029273               10  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9649122807017544\n",
      "Training RMSE:  0.0\n",
      "Test RMSE:  0.1873171623163388\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, subsample=0.7, max_depth=3)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9649122807017544\n",
      "Training RMSE:  0.0\n",
      "Test RMSE:  0.1873171623163388\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.1, subsample=0.7, max_depth=7)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
