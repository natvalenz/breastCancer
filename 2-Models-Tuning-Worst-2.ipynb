{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Diagnostic\n",
    "## The goal of this project is to build a model able to predict the diagnosis of breast cancer tissues as malignant or benign. \n",
    "\n",
    "- Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. \n",
    "\n",
    "- Class distribution: 357 benign, 212 malignant. More info about this dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (roc_auc_score, confusion_matrix, recall_score, precision_score, RocCurveDisplay, \n",
    "                             accuracy_score, plot_confusion_matrix, auc, classification_report)\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "X= pd.read_csv(\"X.csv\")\n",
    "y=pd.read_csv(\"y.csv\")\n",
    "y=y.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xWorst=X.iloc[:,20:30].copy().drop([\"perimeter_worst\", \"area_worst\", \"concavity_worst\", \n",
    "                                    \"concave points_worst\", 'fractal_dimension_worst'], axis=1)\n",
    "random=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xWorst, y, test_size=0.30, random_state=random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.949748743718593\n",
      "Test Accuracy:  0.9649122807017544\n",
      "Training ROC_AUC:  0.9423196140265762\n",
      "Test ROC_AUC:  0.958994708994709\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(random_state=random, max_iter=5000)\n",
    "lr= lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "print(\"Training Accuracy: \", lr.score(X_train, y_train))\n",
    "print(\"Test Accuracy: \", lr.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000, max_iter=5000, random_state=42, solver='newton-cg')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9884126984126984"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models and parameters\n",
    "# define grid search\n",
    "param_grid={'solver': ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "            'penalty':['l2'],\n",
    "            'C':[100, 10, 1.0, 0.1, 0.01, 1000],\n",
    "           'max_iter': [5000]}\n",
    "\n",
    "#why? keep the balance in the splits\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(lr, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=3000, max_iter=5000, random_state=42, solver='newton-cg')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9886857142857143"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models and parameters\n",
    "# define grid search\n",
    "param_grid={'solver': ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "            'penalty':['l2'],\n",
    "            'C':[900, 1000,2000,3000,3100, 3500],\n",
    "           'max_iter': [5000]}\n",
    "\n",
    "#why? keep the balance in the splits\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(lr, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.067550</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>3000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 3000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988686</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.065882</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>3000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 3000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988686</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.068779</td>\n",
       "      <td>0.014274</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>3100</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 3100, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988686</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.076554</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>3100</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 3100, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988686</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011055</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>2000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988597</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.055427</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>2000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988597</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.040397</td>\n",
       "      <td>0.008558</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>2000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988597</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.076429</td>\n",
       "      <td>0.020433</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>3500</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 3500, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988502</td>\n",
       "      <td>0.017979</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>900</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 900, 'max_iter': 5000, 'penalty': 'l2', ...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988502</td>\n",
       "      <td>0.018201</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.067549</td>\n",
       "      <td>0.014022</td>\n",
       "      <td>0.007348</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>3500</td>\n",
       "      <td>5000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 3500, 'max_iter': 5000, 'penalty': 'l2',...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988502</td>\n",
       "      <td>0.017979</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "9        0.067550      0.013429         0.005602        0.001598    3000   \n",
       "10       0.065882      0.008355         0.007305        0.001869    3000   \n",
       "12       0.068779      0.014274         0.005837        0.001726    3100   \n",
       "13       0.076554      0.031859         0.006319        0.001137    3100   \n",
       "8        0.011055      0.004811         0.008732        0.003252    2000   \n",
       "6        0.055427      0.009468         0.004521        0.000934    2000   \n",
       "7        0.040397      0.008558         0.004703        0.001269    2000   \n",
       "15       0.076429      0.020433         0.006359        0.001891    3500   \n",
       "2        0.010097      0.001759         0.008764        0.001728     900   \n",
       "16       0.067549      0.014022         0.007348        0.001817    3500   \n",
       "\n",
       "   param_max_iter param_penalty param_solver  \\\n",
       "9            5000            l2    newton-cg   \n",
       "10           5000            l2        lbfgs   \n",
       "12           5000            l2    newton-cg   \n",
       "13           5000            l2        lbfgs   \n",
       "8            5000            l2    liblinear   \n",
       "6            5000            l2    newton-cg   \n",
       "7            5000            l2        lbfgs   \n",
       "15           5000            l2    newton-cg   \n",
       "2            5000            l2    liblinear   \n",
       "16           5000            l2        lbfgs   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "9   {'C': 3000, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "10  {'C': 3000, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "12  {'C': 3100, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "13  {'C': 3100, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "8   {'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "6   {'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "7   {'C': 2000, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "15  {'C': 3500, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "2   {'C': 900, 'max_iter': 5000, 'penalty': 'l2', ...           0.994667  ...   \n",
       "16  {'C': 3500, 'max_iter': 5000, 'penalty': 'l2',...           0.994667  ...   \n",
       "\n",
       "    split23_test_score  split24_test_score  split25_test_score  \\\n",
       "9             0.978667                 1.0                 1.0   \n",
       "10            0.978667                 1.0                 1.0   \n",
       "12            0.978667                 1.0                 1.0   \n",
       "13            0.978667                 1.0                 1.0   \n",
       "8             0.976000                 1.0                 1.0   \n",
       "6             0.976000                 1.0                 1.0   \n",
       "7             0.976000                 1.0                 1.0   \n",
       "15            0.978667                 1.0                 1.0   \n",
       "2             0.973333                 1.0                 1.0   \n",
       "16            0.978667                 1.0                 1.0   \n",
       "\n",
       "    split26_test_score  split27_test_score  split28_test_score  \\\n",
       "9                  1.0                 1.0            0.948571   \n",
       "10                 1.0                 1.0            0.948571   \n",
       "12                 1.0                 1.0            0.948571   \n",
       "13                 1.0                 1.0            0.948571   \n",
       "8                  1.0                 1.0            0.948571   \n",
       "6                  1.0                 1.0            0.948571   \n",
       "7                  1.0                 1.0            0.948571   \n",
       "15                 1.0                 1.0            0.945714   \n",
       "2                  1.0                 1.0            0.945714   \n",
       "16                 1.0                 1.0            0.945714   \n",
       "\n",
       "    split29_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "9                  1.0         0.988686        0.017795                1  \n",
       "10                 1.0         0.988686        0.017795                1  \n",
       "12                 1.0         0.988686        0.017795                1  \n",
       "13                 1.0         0.988686        0.017795                1  \n",
       "8                  1.0         0.988597        0.017851                5  \n",
       "6                  1.0         0.988597        0.017851                5  \n",
       "7                  1.0         0.988597        0.017851                5  \n",
       "15                 1.0         0.988502        0.017979                8  \n",
       "2                  1.0         0.988502        0.018201                8  \n",
       "16                 1.0         0.988502        0.017979                8  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9723618090452262\n",
      "0.9707602339181286\n",
      "Training ROC_AUC:  0.9684779386000378\n",
      "Test ROC_AUC:  0.9702380952380952\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(C=3000, max_iter=5000, random_state=42, solver='newton-cg')\n",
    "lr= lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "print(lr.score(X_train, y_train))\n",
    "print(lr.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 97.08\n",
      "precision : 95.31\n",
      "recall : 96.83\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Accuracy :', round(accuracy_score(y_test,y_test_pred)*100,2))\n",
    "print('precision :', round(precision_score(y_test,y_test_pred)*100,2))\n",
    "print('recall :', round(recall_score(y_test,y_test_pred)*100,2))\n",
    "plot_confusion_matrix(lr, X_test, y_test, cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.98      0.97      0.98       108\n",
      "   Malignant       0.95      0.97      0.96        63\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Benign', 'Malignant']\n",
    "print(classification_report(y_test, y_test_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'False Positive Rate')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_test_pred)\n",
    "auc_sc = auc(fpr, tpr)\n",
    "# Draw ROC curve:\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, label=\"AUC = %0.2f\"%auc_sc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Receiver Operating Characteristic(ROC) for Support Vector Machine\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100, max_iter=5000, penalty='l1', random_state=42,\n",
      "                   solver='liblinear')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9880507936507936"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models and parameters\n",
    "# define grid search\n",
    "param_grid={'solver': ['liblinear'], \n",
    "            'penalty':['l1'],\n",
    "            'C':[100, 10, 1.0, 0.1, 0.01, 1000],\n",
    "           'max_iter': [5000]}\n",
    "\n",
    "#why? keep the balance in the splits\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(lr, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027761</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>100</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'max_iter': 5000, 'penalty': 'l1', ...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988051</td>\n",
       "      <td>0.018678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028348</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000, 'max_iter': 5000, 'penalty': 'l1',...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987968</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>10</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'max_iter': 5000, 'penalty': 'l1', '...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987962</td>\n",
       "      <td>0.018893</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.0, 'max_iter': 5000, 'penalty': 'l1', ...</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986646</td>\n",
       "      <td>0.018949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 5000, 'penalty': 'l1', ...</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.854286</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.960571</td>\n",
       "      <td>0.032155</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 5000, 'penalty': 'l1',...</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.581333</td>\n",
       "      <td>0.538667</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0.885333</td>\n",
       "      <td>0.602857</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.660958</td>\n",
       "      <td>0.100771</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.027761      0.007298         0.005152        0.001331     100   \n",
       "5       0.028348      0.006640         0.005399        0.002057    1000   \n",
       "1       0.020310      0.002921         0.004671        0.000760      10   \n",
       "2       0.011922      0.001566         0.005633        0.001177       1   \n",
       "3       0.006744      0.001085         0.004401        0.000786     0.1   \n",
       "4       0.005778      0.001068         0.004348        0.001125    0.01   \n",
       "\n",
       "  param_max_iter param_penalty param_solver  \\\n",
       "0           5000            l1    liblinear   \n",
       "5           5000            l1    liblinear   \n",
       "1           5000            l1    liblinear   \n",
       "2           5000            l1    liblinear   \n",
       "3           5000            l1    liblinear   \n",
       "4           5000            l1    liblinear   \n",
       "\n",
       "                                              params  split0_test_score  ...  \\\n",
       "0  {'C': 100, 'max_iter': 5000, 'penalty': 'l1', ...           0.994667  ...   \n",
       "5  {'C': 1000, 'max_iter': 5000, 'penalty': 'l1',...           0.992000  ...   \n",
       "1  {'C': 10, 'max_iter': 5000, 'penalty': 'l1', '...           0.994667  ...   \n",
       "2  {'C': 1.0, 'max_iter': 5000, 'penalty': 'l1', ...           0.997333  ...   \n",
       "3  {'C': 0.1, 'max_iter': 5000, 'penalty': 'l1', ...           0.961333  ...   \n",
       "4  {'C': 0.01, 'max_iter': 5000, 'penalty': 'l1',...           0.626667  ...   \n",
       "\n",
       "   split23_test_score  split24_test_score  split25_test_score  \\\n",
       "0            0.978667            1.000000            1.000000   \n",
       "5            0.978667            1.000000            1.000000   \n",
       "1            0.965333            1.000000            1.000000   \n",
       "2            0.960000            1.000000            0.997333   \n",
       "3            0.960000            0.952000            0.957333   \n",
       "4            0.712000            0.581333            0.538667   \n",
       "\n",
       "   split26_test_score  split27_test_score  split28_test_score  \\\n",
       "0            1.000000            1.000000            0.942857   \n",
       "5            1.000000            1.000000            0.945714   \n",
       "1            1.000000            1.000000            0.942857   \n",
       "2            1.000000            1.000000            0.922857   \n",
       "3            0.994667            0.994667            0.854286   \n",
       "4            0.634667            0.885333            0.602857   \n",
       "\n",
       "   split29_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            1.000000         0.988051        0.018678                1  \n",
       "5            1.000000         0.987968        0.018403                2  \n",
       "1            1.000000         0.987962        0.018893                3  \n",
       "2            1.000000         0.986646        0.018949                4  \n",
       "3            0.983333         0.960571        0.032155                5  \n",
       "4            0.708333         0.660958        0.100771                6  \n",
       "\n",
       "[6 rows x 42 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.9698492462311558\n",
      "Test Score:  0.9707602339181286\n",
      "Training ROC_AUC:  0.9651222339020512\n",
      "Test ROC_AUC:  0.9702380952380952\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(penalty='l1', C=100, solver='liblinear', random_state=random)\n",
    "lr= lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "print(\"Training Score: \",lr.score(X_train, y_train))\n",
    "print(\"Test Score: \", lr.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 97.08\n",
      "precision : 95.31\n",
      "recall : 96.83\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Accuracy :', round(accuracy_score(y_test,y_test_pred)*100,2))\n",
    "print('precision :', round(precision_score(y_test,y_test_pred)*100,2))\n",
    "print('recall :', round(recall_score(y_test,y_test_pred)*100,2))\n",
    "plot_confusion_matrix(lr, X_test, y_test, cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>resid</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>14.97</td>\n",
       "      <td>24.64</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.116159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>14.35</td>\n",
       "      <td>34.23</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.125634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>14.80</td>\n",
       "      <td>27.20</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>0.2666</td>\n",
       "      <td>0.128981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>15.33</td>\n",
       "      <td>30.28</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.139683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>17.73</td>\n",
       "      <td>25.21</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>-0.156472</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>16.11</td>\n",
       "      <td>29.11</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>0.1766</td>\n",
       "      <td>0.2522</td>\n",
       "      <td>0.160591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>16.51</td>\n",
       "      <td>32.29</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.408350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15.53</td>\n",
       "      <td>26.02</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.4225</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>-0.420177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>16.21</td>\n",
       "      <td>29.25</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.3020</td>\n",
       "      <td>-0.439861</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>14.55</td>\n",
       "      <td>29.16</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.4402</td>\n",
       "      <td>0.4128</td>\n",
       "      <td>0.452389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>16.39</td>\n",
       "      <td>22.07</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.3262</td>\n",
       "      <td>0.3068</td>\n",
       "      <td>-0.500131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>15.53</td>\n",
       "      <td>23.19</td>\n",
       "      <td>0.1536</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>0.3527</td>\n",
       "      <td>0.506876</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>15.75</td>\n",
       "      <td>40.54</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.2426</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.550843</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>15.35</td>\n",
       "      <td>25.16</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>0.3124</td>\n",
       "      <td>0.3518</td>\n",
       "      <td>0.625865</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>16.57</td>\n",
       "      <td>20.86</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>-0.761232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_worst  texture_worst  smoothness_worst  compactness_worst  \\\n",
       "204         14.97          24.64            0.1426             0.2378   \n",
       "457         14.35          34.23            0.1289             0.1063   \n",
       "396         14.80          27.20            0.1428             0.2570   \n",
       "235         15.33          30.28            0.1287             0.1513   \n",
       "329         17.73          25.21            0.1426             0.2116   \n",
       "90          16.11          29.11            0.1115             0.1766   \n",
       "542         16.51          32.29            0.1060             0.1376   \n",
       "39          15.53          26.02            0.1610             0.4225   \n",
       "86          16.21          29.25            0.1306             0.1976   \n",
       "208         14.55          29.16            0.1349             0.4402   \n",
       "255         16.39          22.07            0.1512             0.3262   \n",
       "81          15.53          23.19            0.1536             0.4791   \n",
       "238         15.75          40.54            0.1081             0.2426   \n",
       "526         15.35          25.16            0.1624             0.3124   \n",
       "73          16.57          20.86            0.1411             0.3542   \n",
       "\n",
       "     symmetry_worst     resid  y_true  y_pred  \n",
       "204          0.3014  0.116159       0       0  \n",
       "457          0.2444  0.125634       0       0  \n",
       "396          0.2666  0.128981       0       0  \n",
       "235          0.2226  0.139683       0       0  \n",
       "329          0.2736 -0.156472       1       1  \n",
       "90           0.2522  0.160591       0       0  \n",
       "542          0.2722  0.408350       0       0  \n",
       "39           0.2807 -0.420177       1       1  \n",
       "86           0.3020 -0.439861       1       1  \n",
       "208          0.4128  0.452389       0       0  \n",
       "255          0.3068 -0.500131       1       0  \n",
       "81           0.3527  0.506876       0       1  \n",
       "238          0.1890  0.550843       0       1  \n",
       "526          0.3518  0.625865       0       1  \n",
       "73           0.2589 -0.761232       1       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last 5 are what was predicted incorrectly\n",
    "residuals = lr.predict_proba(X_test)[:,1] - y_test\n",
    "sortIdx=np.argsort(np.abs(residuals))\n",
    "residDF=X_test.iloc[sortIdx].copy()\n",
    "residDF[\"resid\"]=residuals[sortIdx]\n",
    "residDF['y_true']=y_test[sortIdx]\n",
    "residDF['y_pred']=y_test_pred[sortIdx]\n",
    "# print(residDF.std())\n",
    "outliers=residDF.tail(15)\n",
    "outliers\n",
    "# outliers.std()\n",
    "#sns.regplot(x = residuals, y = y_test_pred, scatter = True, color = 'red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>resid</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_true</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.188380</td>\n",
       "      <td>23.808611</td>\n",
       "      <td>0.125902</td>\n",
       "      <td>0.183516</td>\n",
       "      <td>0.276775</td>\n",
       "      <td>0.042306</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.436032</td>\n",
       "      <td>29.965079</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0.408268</td>\n",
       "      <td>0.324095</td>\n",
       "      <td>-0.042840</td>\n",
       "      <td>0.968254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        radius_worst  texture_worst  smoothness_worst  compactness_worst  \\\n",
       "y_true                                                                     \n",
       "0          13.188380      23.808611          0.125902           0.183516   \n",
       "1          21.436032      29.965079          0.147222           0.408268   \n",
       "\n",
       "        symmetry_worst     resid    y_pred  \n",
       "y_true                                      \n",
       "0             0.276775  0.042306  0.027778  \n",
       "1             0.324095 -0.042840  0.968254  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residDF.groupby('y_true').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlEklEQVR4nO3de2xc130n8O+PM3yTIilKlGhStOjWcewkcuIwdtI0jWNvtpZ3sd4CRe2k23SDpIKxcdDtAt64LZINHCy23XQXcWEXquA43SC7MRaukXgDa4NNnaRFE7uW8vBLfsiSJVIURT34Gr6GM/ztH785njvDGc4dcmbuzL3fD3Awj3s5Opea+fLMueeeI6oKIiIKh6agK0BERJXDUCciChGGOhFRiDDUiYhChKFORBQi8aD+4V27dun+/fuD+ueJiBrS8ePHL6nq7mLbAwv1/fv349ixY0H980REDUlEzmy2nd0vREQhwlAnIgoRhjoRUYgw1ImIQoShTkQUIiVDXUQeE5FpEXmpyHYRkb8UkZMi8oKI3FT5ahKOHgVuuw0YHbXbo0cLPxcVlT72Bx8E+vqAeNxuH3ww99/p6wOamwERu+3sBLq6bP9YzJ4vVih8ynn/Veq9mnmdA8B7NttNSs3SKCK/ASAB4Juq+u4C2+8E8HkAdwK4BcBDqnpLqfqNjY0phzT6dPQocN99QEsL0NEBLC0Bs7OAqoWNey6ZBB5+GDh4MOgaV1eh38d2jv3BB4GvfAVoarKATqeB9XXg7ruBn/4UmJ8HLl3aXp05G2p4lPP+q9R71fM673711aWXVDuL7Voy1AFARPYD+F6RUP9rAD9S1W9nHr8G4FZVPb/ZazLUy3DbbcD589Y6dE6csNvrr88+t7gIDA4CzzxT2/rVWqHfx3aOva/PPmxxz2UbqZQF+6/+KvDGG3Z/O8HMUA+Pct5/lXqvel7n3cePbxrqlbj4aAjAuOfxROa5DaEuIocAHAKAkeFh4PJlt8G7U/HbYs/lbwvbV+HTp4GdO3OfW1vbeDwdHcBbb9WsWoEp9PvYzrEvLFhLyisWsxZVR4e13Bv1vUOVV877r1Lv1UKvU0QlQr3Qu71gs0RVjwA4AgBjBw7o26FeSyL2NduFvLvvvc2/7y2x2Mb71TY6uvGvfXPzxv2WloAoTL1Q6PexnWPv7t7YUk+n7fHSkv0/r69vq8oUIuW8/yr1Xi30OkVUIpEmAOzzPB4GMFmB160OVfvAplLW2l1dBVZW7Be9uGittrk567O+csX6UqengakpYHISGB8Hzpyxv5wnT9pX8zfftL+84+O2z4UL9i1kdhZIJOz119a2/hX8/vut1bi4aK+xuAjs2GFh5H0umbR9w67Q72M7x/5Hf2ShnUrZ67mul7vvttft62P3CWWV8/6r1HvV+zolVCLUnwLwqcwomA8CmCvVnx4q7o9EMgksL1uIz81ZqE9PW8ifPWt/BN54Azh1yh6fPw9cvGjBv7hooV/MwYN2YmVwEJiZsdvHHgO+8Y3c56JwkhQo/PvYzrF/6UvAF79oX4vX1uz2i18EvvUte933vAfo7c225ONx26ez09+3Nf5BCJdy3n+Veq96XidWoofFz+iXbwO4FcAuABcA/CcAzQCgqodFRAA8DOAOAEsAPq2qJc+Ajh04oMeeeMLH0USIGy7X0mKltTV7n326RARARI6r6lix7SX71FX1EyW2K4DPbaFulE/VWvzJZO7zIhbwra1AW5uV1tZg6khEdS2wqXepDKrWL7+yYl07gH3lb2uzboD2drvP1jxR5DHUG9X6up3cXVqyx01NFu6dnRb0+UP0iCgSGOphsb5uJ1zd2fGWFgv4zk4Le7biiSKBoR5Wrm9+ZsZGaHR22hDIjg4GPFGIMdSjIJ22+Uvm5y3gu7qAnh7rhyeiUGGoR006bSdb5+asi6anx0otrowloqpjqEdZMmkXQF26ZFeo9vZyqCRRg2Ookw2ZdK33zk6bOKi9PehaEdEWMNQplxtB094O9PfbiVUiahjsSKXClpeBiQkrKytB14aIfGKo0+aWlmwCssnJzScdI6K6wO4X8ieRsG6Zvj7rluFYd6K6xJY6+adqc8yfPu1rXmciqj2GOpUvlQLOnbM54dPpoGtDRB4Mddq6hQVb8SmRCLomRJTBUKftSaezS/hxhR+iwDHUqTLm5mzt1tXVoGtCFGkMdaqcZNKGP87PB10ToshiqFNlqQJTU7boNrtjiGqOoU7VMTtrV6NydAxRTTHUqXqWl607Jn8hbSKqGoY6VdfaGjA+bgFPRFXHUKfqS6etK4bj2YmqjqFOtaFq49k5MoaoqhjqVFtTUzamnYiqgqFOtXfhgo2OIaKKY6hTMKanGexEVcBQp+BMT7OPnajCGOoUrKkpm+2RiCqCoU7Bm5riohtEFcJQp+Cp2oIbnOGRaNt8hbqI3CEir4nISRF5oMD2HhH5PyLySxF5WUQ+XfmqUqitr9tqSlzcmmhbSoa6iMQAPALgIIAbAHxCRG7I2+1zAF5R1RsB3Argv4lIS4XrSmHnlsnjJGBEW+anpX4zgJOqekpVkwAeB3BX3j4KoFtEBEAXgCsAUhWtKUVDMmldMZy2l2hL/IT6EIBxz+OJzHNeDwO4HsAkgBcB/KGqrue/kIgcEpFjInLs4pUrW6wyhd7SEnDxYtC1IGpIfkJdCjyX34z6TQC/AHAVgPcCeFhEdmz4IdUjqjqmqmO7d+4ss6oUKbOznE6AaAv8hPoEgH2ex8OwFrnXpwE8qeYkgNMA3lmZKlJkTU9zyl6iMvkJ9ecBXCsio5mTn/cAeCpvn7MAbgcAEdkD4DoApypZUYogN7NjiqdniPwqGeqqmgJwH4DvAzgB4H+r6ssicq+I3JvZ7SsAfk1EXgTwdwC+oKqXqlVpipB02oKdJ06JfIn72UlVnwbwdN5zhz33JwH888pWjShjZcVOnA4MBF0TorrHK0qpMczOco4YIh8Y6tQ4pqY4lQBRCQx1ahzuxOn6hksgiCiDoU6NZW3NrjglooIY6tR4FheBy5eDrgVRXWKoU2O6fJlzsBMVwFCnxnX+vE0ARkRvY6hT43JzsHOqXqK3MdSpsa2t8YpTIg+GOjW+5WWb/IuIGOoUEnNzwMxM0LUgChxDncLj0iVbYIMowhjqFB6qNiKGi1dThDHUKVw4VS9FHEOdwmd1FbhwIehaEAWCoU7hND9v0/USRQxDncLr4kVbYIMoQhjqFF7uxCmvOKUIYahTuK2tsX+dIoWhTuGXSLAbhiKDoU7RwPnXKSIY6hQNi4tc35QigaFO0XHlStA1IKo6hjpFx8ICF9Wg0GOoU7SwtU4hx1CnaFlY4IRfFGoMdYoWVc67TqHGUKfomZ+39U2JQoihTtGzvs7Jvqgx+TjRH69BNYjqz+ws0NcHiARdE6LNLS/bVdGLi75C3VdLXUTuEJHXROSkiDxQZJ9bReQXIvKyiPy4zGoT1VYqZSdNieqNqgX4hQvAm28C4+N2HsjncNySLXURiQF4BMDHAUwAeF5EnlLVVzz79AL4KwB3qOpZERnYyrEQ1dTMDLBjR9C1ILIuwUTCytLSts75+Ol+uRnASVU9BQAi8jiAuwC84tnnkwCeVNWzAKCq01uuEVGtrK7aB6ijI+iaUBSlUtkgX16u2BKMfkJ9CMC45/EEgFvy9nkHgGYR+RGAbgAPqeo3819IRA4BOAQAI0NDW6kvUWXNzDDUqXaSyWyQV2nmUD+hXuhMUv6flDiA9wO4HUA7gJ+KyLOq+nrOD6keAXAEAMYOHODKwBQ8N9FXa2vQNaGwWl218zeJRE2mqfAT6hMA9nkeDwOYLLDPJVVdBLAoIn8P4EYAr4Oo3s3MAHv3Bl0LChM3YiWRqPkVzH5GvzwP4FoRGRWRFgD3AHgqb5/vAviIiMRFpAPWPXOislUlqpKFBevfJNqO5WVgeho4dSo7YiWAKSlKttRVNSUi9wH4PoAYgMdU9WURuTez/bCqnhCR/wvgBQDrAB5V1ZeqWXGiinFTB+zeHXRNqNEkk3aF8vx83TQMfF18pKpPA3g677nDeY+/CuCrlasaUQ3NzQH9/UATL7KmEtyoqYWFulwmkVeUEgHZqQN27gy6JlRv0unsFZ3Ly/a4jjHUiZzZWaC3l611yh1DvrQUdG3KwlAnclIpuzR7cDDomlAQ1tYsxOu0W8UvhjqR18KCXYzU0xN0TagW3MVACwuhWZicoU6Ub3oaaG8HWlqCrglVQ40vBqo1hjpRPlXg/HlgZIRT84bFyko2yEO+nCFDnaiQ1VVrse/ZE3RNaCuSSTvBubTUECNWKomhTlTM3BzQ1sb+9UaQSmVDfGmpbi4ECgJDnWgz09M22VdbW9A1Ia902lrgLsRD2De+VQx1os14+9djsaBrE12qFuKLixbiIRmpUg0MdaJS1taAqSmAawDUlmp2uOE2VwOKkuBC/aWXgLvuAq6+GhgdBfbvt/v793NBYKo/i4tWOjuDrkm4qWbnVUkkGORbEFyoqwKvvmol344duSE/Opq939VV44oSZVy8aBcmscFROar2TSiZtD+aiUSkRqpUQ3ChPjIC/M7vAG+9ZeXMGfvQADaN5QsvWMm3a5eFe34ZGeHqNVRdyaSNiOntDbomjc2NGV9ctECv0NqcZIIL9Z4e4A/+IPe5RCIb8KdP260L/fl52+fSJSvHjuX+rAhw1VW5LXxXhoaAOE8fUAVcvgx0d/OkabnW123O+rm5SA83rIX6SrquLuDd77bi5RYxcIH/1lsW+u7xyortc+6clX/8x9yfj8eB4eFs370L/tFRYGCAs/KRf+m0BfvAQNA1aQzptM1+OTPD/vEaqa9QL0bE5rneuRO46abcbevrNpbYtey9rfzxcft6l0plW/z52tpyW/befnyesKVC5ubsvA/HrheXTluQz84yzGusMUJ9M01Ntmjw3r3Ahz6Uuy2VAiYncwPfhfu5c9a6X1kBXnvNSr7u7txWvTf8u7urfmhUp9y3wpERoLk56NrUl2TSgnxujn3lAWn8UN9MPG4fvJGRjdtWV4GzZ3OD3hV3wnZhAXjxRSv5+vs39t9ffbWV9vYqHRDVjXQ6G+xR775LpeyzMj/Pi4LqQLhDfTOtrcC111rJl0hsbNm7Mjdn+1y+bOX48Y0/v3dv4eGYw8OczjVMkkn7Jjg0FI1uuvV1O2ZXVlftmy6HINaV6Ib6Zrq6gHe9y0q+/BO23vtu2aupKSvPPZf7s7FYdoROfiv/qqs4oqIRLS3ZNAIDA+EbYZVM2qX5roR8ytqwCNm7sAb6+qy87325z6tat02hwD9zxj4g6bSdvB0fB/7hH3J/vrkZ2Lcvt/+eI3Qag1vHsr/f3huNLJm0rpSFBU6S1aAY6pUiYuE7MADcfHPutnTaWnMu7L234+O2fW0NOHXKyg9/mPvz3hE6+bf9/dH46l/v1tftj/r8vHW/1fuFcK77ZHXV7q+tWeFIlYbHUK+FWMz604eHgQ9/OHfb2howMVE48CcnS4/Q6erKDXrv/UZvNTYidwK+v9+G4NaDVMrqtbxs76WVFYZ3iDHUg9bcbF0so6MbtxUaoePuT0/bPokE8PLLVvL19BQOew7JrC5Vu+p5cdGmtWhrq923qfX17BzjrhXOE5mRwlCvZ5uN0FlctMDPD/szZ4ArV2yfuTngl7+0km/nzuItfM5EWBnLy9a9BmQX2mhvt0nBtnpSdW3NQjqVsltvcV0qHB8eaQz1RtXZCVx/vZV88/Mbh2S6x25I5pUrVn7+840/v3v3xqDnGPztcf3X7vff3GzDW2MxC/imJgtjV7zW17OtbnabUAkM9TDasQN4z3us5JuZyW3Ve+8nErbPxYtW8idNA2whZm/Iu9AfGeFl8+VwJyaJKoyhHjVuSOZ735v7vKq13AuF/Zkz2TH4Fy5Y+ad/2vja3ouuRkaygb9vHwOfqEYY6mREbMRGfz/w/vfnbnNj8F0fvjf0z561vmOg+EVXItnAzy+cB5+oohjqVJp3DP7YWO42VRuJkx/07tZNi3z+vJVnn9342nv3Zlv2IyO5gc8WPlFZfIW6iNwB4CEAMQCPquqfFdnvAwCeBXC3qj5RsVpS/RKxfvY9ezZedOUC3xv0LvwLBX5+Cx/IBn6hFj5P2hJtUDLURSQG4BEAHwcwAeB5EXlKVV8psN+fA/h+NSpKDcgb+LfckrvNXYGZH/TeFj6Q7dIp1Ic/MJDbune3+/ZxLVuKLD8t9ZsBnFTVUwAgIo8DuAvAK3n7fR7A3wL4QEVrSOHU1FQ68F3Yu8B3t+6k7fS0lUKBv2vXxrB3tzt2VP/4iALiJ9SHAIx7Hk8AyPkUisgQgN8CcBs2CXUROQTgEACMDA2VW1eKCm/gF+rSuXQp238/Pp4b/ouLtp9by/ZnP9v4+r29G8Pe3edqV9Tg/IR6oXd4/iVrXwPwBVVNyyYfCFU9AuAIAIwdOMDL3qh8InZx1O7dhU/aunH4hbp03OLls7NWCl1p6+bScUHvDfzduzlbJtU9P6E+AWCf5/EwgMm8fcYAPJ4J9F0A7hSRlKp+pxKVJPLFu5Zt/tTIgAW5tyvHtfLPnrUFT4DN59JpbbWAd1Mku9uREZsPP2zzqVND8vMufB7AtSIyCuAcgHsAfNK7g6q+PRuViPwNgO8x0Knu9PZaufHGjdsSCQt3V1zYnz1rJ2oBu1T/jTes5IvHLdi9rft9+7K3HKlDNVIy1FU1JSL3wUa1xAA8pqovi8i9me2Hq1xHourr6gJuuMFKvpWVbMC71r27nZzMTrDl9ilkYGBj2Lv7vb3sx6eKEQ1oRrexAwf02BMcyk4Nbm3Ngt0b+t4Wv5+FmLu7N3bruMd79nCZQ8oh1113XFXHim1nJyDRdjQ3Zy+IyueGZnpD3hv+bsbGhYXi/fjNzbawdaFW/vAwr7ilDRjqRNXiHZr5gQIjfefmNrbu3Rq2U1M2mmdtLTt9ciEDA9mgHx7ODf6dO9mtE0EMdaKg9PQUnyJ5ddWWOcwP/LNn7Xm3KLS7AOv48Y2v0dFhQe/tznHBPzRk87lT6DDUiepRayvwK79iJd/6ugW5t2XvDXy38tXSEvD661byuYnUXNDv25db2MpvWAx1okbT1GSBvHfvxituARueOT5uAe9a+a7Vf+6cjdTxTqRWaJoFbyvfG/puAXX25dcthjpR2HR1FV/qMJ22IHch78Lf3Z+Zsf02a+UDdnWtN/C9t3v28MrbADHUiaIkFsu2tj/4wY3bE4ncvnxv4J87l12Czy15WGhuHTdix/073sAfHrZzCezaqRqGOhFldXUB73ynlXzptPXlu6DPb+1fvGj7lRqx09WVDfr88B8e5tW328RQJyJ/YjFgcNBKoSGaKyvWmp+Y2Bj4ExPZhc0TCeDVV60U0t+fDfj80B8c5KidEhjqRFQZbW3FR+yo2oRqLuDzi7dr5/JlK4Vm0XQLr3gD33u7d2/kJ1aL9tETUW2I2Fz1fX2Fx+W7q2+9LXvX6j93zk7urq/bHwe3GtaxYxtfJxazYC8U+ENDkZh2gaFORMHzXn2bP08+YK34qalsyHu7ec6ds75+Vev3d9sLDdWMx7Oh74o39AcGGr6l39i1J6oUEWvBxWJ2v6nJSnOzlXjcWorptJW1NetDdl0GVF3Nzdmx8oUkkxbkk5O5LXx3353ETaWyfwwK8bb0veWqq7LdO83N1TnGCmGoU3S0tNjIitZWC2wX4vH41ltn6bQFiqoVwE4Ezs9nH1P1tbQAo6NWCllZyQ38/Psu9L0t/ULcN4qrrsoGvQt9VwK+MIuhTuEUj9uHq7XVSltbdb5Wx2Ibh+B1dtrC13NzdnIwlar8v0vlaWsDrrnGSiGrq9mgL9Tav3jR/kivr2evxC003w5go3e8oZ//B6C7u3rHCYY6hUEsZi21tjYr7e3B94vGYjZ/Sl+fBfvMDMO9nrW2bt7STyYtyF3ge8N/ctL6+9Np29eN3nnxxcKv1dWVG/iDg7kt/W2uhctQp8bR1GQfvpaW7G1LS/ABvhk36qO31ybacmuhUmNpaSk+bz5gf7AvXMgNelfc6B23YEoisfkUDM3N1nc/OGjB7w39wcGSVa3jTwNFXlOTtbrb222CqdbWxr28XMS+lqdS2cUxKDzi8Wz3SqELs1TtD7o37F1x3wBmZ23ftbXshVtbqcrWj4KogtwoE9f6dic0w2ZgwFpsKytB14RqScTOs+zaBRw4UHifRCIb8N6wd/cvXMh28WyCoU7BELHg7uqyUs9dKJUkYl+jz5zx9QGlCOnqAq691kohqZSNx//YxzZ9mYh8kqgutLZaN4rrTonq9KzxuAX7Fr9eU0S5902p3WpQFYqqtrZsiLe1hf7y7LK0t9sJVDd/OVGFMNSpcuJx+wrZ0RHtlrhf/f3Wj8qrUqmCGOq0Ne4qzOZm61bp7Aznic1qamqyE6fFrl4k2gKGOpXmvbDHXaHJVnhldHbaFYYLC0HXhEKCoU65RHJPaLIvvPoGBmxNUI6GoQpgqEddLJZ7eX1bG1vhtRaLWbCfPx90TSgEGOpR4yagci1x9oPXh+5uuyCJo2FomxjqYReL5Y4N5/qO9WvXLmB5mVeb0rYw1MOmuTk7X0p7O0O8kfBqU6oAX52nInKHiLwmIidF5IEC239XRF7IlJ+IyI2VryoV1NIC9PTYrG7XXGNTh+7da88x0BtPPO5rJj6iYkq21EUkBuARAB8HMAHgeRF5SlVf8ex2GsBHVXVGRA4COALglmpUONJEsic0OTIlvDo6bC72K1eCrgk1ID/dLzcDOKmqpwBARB4HcBeAt0NdVX/i2f9ZAMOVrGRkxePZ8HYnNRt16lkqT3+/DXNk/zqVyU+oDwHwzjw0gc1b4Z8BcLTQBhE5BOAQAIwMDfmsYkS48eHeEI/KzIW0kYh1w5w5Y0uoEfnkJzUKNQ0LrqgrIh+DhfqvF9quqkdgXTMYO3AguqvyNjVlV+/xXqXJVjh5uRVwJieDrgk1ED+hPgFgn+fxMIAN7zIROQDgUQAHVZVrdgHW0s5ffq25mf3g5F9XF2dzpLL4CfXnAVwrIqMAzgG4B8AnvTuIyAiAJwH8nqoWWXgvxLwr9njXzuSVmVQJu3fbTI6JRNA1oQZQMtRVNSUi9wH4PoAYgMdU9WURuTez/TCALwHoB/BXYl0IKVUdq161A+Qmt/J2nTC8qdoGB21RDZ44pRJ8nYlT1acBPJ333GHP/c8C+GxlqxYwkcL93gxwCoK7MOnsWVvWjKgIDq8ALKhdaHsLT1xSPXEr1o+Pc0QMFRW9UHcnL72FV15So2ht5YgY2lQ4Q13EwtuNNnHdKOw+oTDo6rLJvy5dCromVIcaO9S94729Qwabm4OuGVF17dwJJJPA/HzQNaE60zih7lre3pOW7DahKNuzx4KdI2LIo/5CPRbLHevtWuK8YIcoF6fqpQKCDXU337f3qkuGN5F/8bgF+8QEoNGdeYOyggv1lhZg377S+xHR5trb7arT6emga0J1gENBiMKgt9fmiKHIY6gThcXu3VYo0hjqRGHS12fzxPBq6MhiqBOFTXc3MDzMQQcRxVAnCqP2duDqq+2WIoWhThRW8bi12HkCNVIY6kRhJmInT4eGuOZtRDDUiaKgs9O6Y7q6gq4JVRlDnSgqYjG7+nTvXp5EDTF+HyOKmh07rOV+6RIwNxd0bajC2FIniqJYzGZ5HBmxmU8pNBjqRFHW1mbBPjjIdQhCgt0vRGQXLHV1WXfMlStc3LqBMdSJyIjYxGA9Pbai0pUrwNpa0LWiMjHUiSiXiAV7Tw+QSACzs8DSUtC1Ip8Y6kRUXFeXldVV65pZWOAqS3WOoU5EpbW2AgMDdnVqImHdM0tLXG2pDjHUicg/ETup2t1tLfZEwlrvy8sM+DrBUCeirYnFsn3v6+vA4qKVpSWOngkQQ52Itq+pKduCB4Bk0sJ9acla8eyHrxmGOhFVXkuLld5ee5xMAisrFvCrq1bYXVMVDHUiqj4X8jt22GNVC3oX8O4+u222jaFORLUnYiNqWltzn3dhn0zahU/ekkqxde+Dr1AXkTsAPAQgBuBRVf2zvO2S2X4ngCUA/1ZVf7bpi774InDbbcD99wMHD26l7o3n6FHgq18FTp8GRkejdexRsdUFn5ubgZ07s7Mm7t1rXRXT0xZkra02P4vrvlC1f8sFYDptj0XstQYHrX97fj77XgPq//1XLOydVGpjSaezt6788IfA178OTEzY6k+f+Qzw0Y8Wfs0f/9j/vg1AtMRfPhGJAXgdwMcBTAB4HsAnVPUVzz53Avg8LNRvAfCQqt6y2euOdXbqsZERe0M+/HD9vbkq7ehR4L777CtoR4edQIrKsUfFVgPdq6nJSrFuCBHbvtmJRxEL/VgM2L/fQn521p7r6wv/++/oUeBzn7PPWnt79lj/4i+A22+33936upUf/AD4kz+x35Hbd20N+PKXgY98pC6/Gch11x1X1bGi232E+ocAfFlVfzPz+I8BQFX/i2efvwbwI1X9dubxawBuVdXzxV53rLNTj11/vQ2BGhwEnnmmnONqPLfdBpw/b/NYO1E59qioRKgDFtrr61vf7q1LVxfwjncAJ07Y4+uvz+4T1vdfOZ81P/uq2u9bNVvc7z//ebd/secK3S90u8lzMjy8aaj76X4ZAjDueTwBa42X2mcIQE6oi8ghAIcAYKSlxZ7s6ADeestHNRrc6dP29dorKsdO5SnVOvTbelS1rhrAWp/5f3TC+v4r57PmZ1+Rhlopys986oWaH/nvKj/7QFWPqOqYqo7tdovgLi3ZV8SwGx3dOClSVI6dylOqxe/3G4HrnwaseyF/4emwvv/K+ayF8HPpJ9QnAOzzPB4GMLmFfTZaXLS+LncSJ8zuv9+OdXHRWlBROnbyz/WpF+NOhm7G9ak3Ndl8LYuLNpSwuzsa779yPmsh/Fz6CfXnAVwrIqMi0gLgHgBP5e3zFIBPifkggLnN+tMB2ImgwcFwnqgp5OBBO9bBQWBmJlrHHhXbOanW3GzLy7W0WIt6/3577EK8tdWeGxiwcO7psQt7Ojpsf3cCNRazfUdHgXe9y/p8BweBxx4DvvGNaLz/yvmshfBzWfJEKfD26JavwYY0Pqaq/1lE7gUAVT2cGdL4MIA7YEMaP62qxzZ7zbGxMT12bNNdiIgoj4hs+0QpVPVpAE/nPXfYc18BfG6rlSQiosrgwtNERCHCUCciChGGOhFRiDDUiYhCxNfol6r8wyIXAZwJ5B8vbReAS0FXYhsavf5A4x8D6x+sRq8/UPwYrlbV3cV+KLBQr2cicmyzIUP1rtHrDzT+MbD+wWr0+gNbPwZ2vxARhQhDnYgoRBjqhR0JugLb1Oj1Bxr/GFj/YDV6/YEtHgP71ImIQoQtdSKiEGGoExGFCEMdgIjsFJH/JyJvZG77iuzXKyJPiMirInIis9Rf4PzWP7NvTER+LiLfq2UdS/FzDCKyT0R+mPndvywifxhEXfPqdIeIvCYiJ0XkgQLbRUT+MrP9BRG5KYh6FuOj/r+bqfcLIvITEbkxiHoWU6r+nv0+ICJpEfntWtavFD/1F5FbReQXmff8j0u+qKpGvgD4rwAeyNx/AMCfF9nvfwD4bOZ+C4DeoOteTv0z2/8DgP8F4HtB17vcYwAwCOCmzP1u2ILoNwRY5xiANwFck3k//DK/PrDF2I/CVgf7IIDngv5dl1n/XwPQl7l/sNHq79nvGdhMs78ddL3L/P33AngFwEjm8UCp12VL3dwFC2xkbv91/g4isgPAbwD4OgCoalJVZ2tUv1JK1h8ARGQYwL8A8GhtqlWWksegqudV9WeZ+wsATsDWwg3KzQBOquopVU0CeBx2HF53AfimmmcB9IrIYK0rWkTJ+qvqT1R1JvPwWdiqZvXCz+8fAD4P4G8BTNeycj74qf8nATypqmcBQFVLHgND3ezRzEpNmduBAvtcA+AigG9kui8eFZHOAvsFwU/9AVvo5D8CKLEUfSD8HgMAQET2A3gfgOeqX7Wiii24Xu4+QSm3bp+BfeuoFyXrLyJDAH4LwGHUHz+//3cA6BORH4nIcRH5VKkX9bVIRhiIyA8A7C2w6U99vkQcwE0APq+qz4nIQ7Bugi9WqIqb2m79ReRfAphW1eMicmsFq+ZbBf4P3Ot0wVpe/15V5ytRty2q2KLsAfFdNxH5GCzUf72qNSqPn/p/DcAXVDUtfhfsrh0/9Y8DeD+A2wG0A/ipiDyrqq8Xe9HIhLqq/rNi20TkgogMqur5zFfjQl9xJgBMqKprGT4BC/WaqED9PwzgX2WWJmwDsENEvqWq/6ZKVd6gAscAEWmGBfr/VNUnq1RVv6q3KHtt+KqbiByAddkdVNXLNaqbH37qPwbg8Uyg7wJwp4ikVPU7Nanh5vy+fy6p6iKARRH5ewA3ws4nFcTuF/MUgN/P3P99AN/N30FVpwCMi8h1maduh53AqAd+6v/Hqjqsqvthi4c/U8tA96HkMWTWwv06gBOq+t9rWLdiqrMoe+2UrL+IjAB4EsDvbdY6DEjJ+qvqqKruz7zvnwDw7+ok0AF/75/vAviIiMRFpAPALbBzScUFfQa4HgqAfgB/B+CNzO3OzPNXAXjas997ARwD8AKA7yAzKiDo4rf+nv1vRf2Nfil5DLCv/pr5/f8iU+4MuN53wlpNbwL408xz9wK4N3NfADyS2f4igLGgf9dl1v9RADOe3/exoOtcTv3z9v0b1NHoF7/1B3A/rAH5EqzLcdPX5DQBREQhwu4XIqIQYagTEYUIQ52IKEQY6kREIcJQJyIKEYY6EVGIMNSJiELk/wNqXs/Y2SLLSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x = residuals, y = y_test_pred, logistic=True, scatter = True, color = 'red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9472361809045227\n",
      "0.9473684210526315\n",
      "Training ROC_AUC:  0.9389639093285894\n",
      "Test ROC_AUC:  0.9451058201058201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#normal data helped this\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "y_train_pred=gnb.predict(X_train)\n",
    "y_test_pred=gnb.predict(X_test)\n",
    "print(gnb.score(X_train, y_train))\n",
    "print(gnb.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6256281407035176\n",
      "0.631578947368421\n",
      "Training RMSE:  0.6118593460073013\n",
      "Test RMSE:  0.6069769786668839\n",
      "Training ROC_AUC:  0.5\n",
      "Test ROC_AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=0.0006579332246575676)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9873111111111111"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'var_smoothing': np.logspace(0,-9, num=100)\n",
    "        }\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(gnb, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var_smoothing is a stability calculation to widen (or smooth) the curve and therefore account for more samples that are further away from the distribution mean. In this case, np.logspace returns numbers spaced evenly on a log scale, starts from 0, ends at -9, and generates 100 samples.\n",
    "from https://medium.com/analytics-vidhya/how-to-improve-naive-bayes-9fa698e14cba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000657933</td>\n",
       "      <td>{'var_smoothing': 0.0006579332246575676}</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.987311</td>\n",
       "      <td>0.017343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.004351</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.000284804</td>\n",
       "      <td>{'var_smoothing': 0.0002848035868435802}</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987230</td>\n",
       "      <td>0.017501</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.00053367</td>\n",
       "      <td>{'var_smoothing': 0.0005336699231206307}</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.987226</td>\n",
       "      <td>0.017768</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.000811131</td>\n",
       "      <td>{'var_smoothing': 0.0008111308307896872}</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.987222</td>\n",
       "      <td>0.017170</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.003967</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000432876</td>\n",
       "      <td>{'var_smoothing': 0.0004328761281083057}</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.987131</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000231013</td>\n",
       "      <td>{'var_smoothing': 0.0002310129700083158}</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986944</td>\n",
       "      <td>0.018012</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'var_smoothing': 0.001}</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.986939</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000187382</td>\n",
       "      <td>{'var_smoothing': 0.0001873817422860383}</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986938</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.003957</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000351119</td>\n",
       "      <td>{'var_smoothing': 0.0003511191734215131}</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986868</td>\n",
       "      <td>0.018191</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000151991</td>\n",
       "      <td>{'var_smoothing': 0.0001519911082952933}</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986849</td>\n",
       "      <td>0.017823</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "35       0.003934      0.000627         0.004322        0.000768   \n",
       "39       0.004351      0.001133         0.004616        0.000688   \n",
       "36       0.004285      0.000821         0.004444        0.000937   \n",
       "34       0.005052      0.000960         0.005081        0.000986   \n",
       "37       0.003967      0.000727         0.004274        0.000707   \n",
       "40       0.004150      0.000654         0.004405        0.000666   \n",
       "33       0.005300      0.001487         0.005858        0.001334   \n",
       "41       0.003421      0.000621         0.003610        0.000555   \n",
       "38       0.003957      0.000750         0.004326        0.000736   \n",
       "42       0.003951      0.000717         0.004278        0.000790   \n",
       "\n",
       "   param_var_smoothing                                    params  \\\n",
       "35         0.000657933  {'var_smoothing': 0.0006579332246575676}   \n",
       "39         0.000284804  {'var_smoothing': 0.0002848035868435802}   \n",
       "36          0.00053367  {'var_smoothing': 0.0005336699231206307}   \n",
       "34         0.000811131  {'var_smoothing': 0.0008111308307896872}   \n",
       "37         0.000432876  {'var_smoothing': 0.0004328761281083057}   \n",
       "40         0.000231013  {'var_smoothing': 0.0002310129700083158}   \n",
       "33               0.001                  {'var_smoothing': 0.001}   \n",
       "41         0.000187382  {'var_smoothing': 0.0001873817422860383}   \n",
       "38         0.000351119  {'var_smoothing': 0.0003511191734215131}   \n",
       "42         0.000151991  {'var_smoothing': 0.0001519911082952933}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "35           0.997333           0.994667                1.0   \n",
       "39           0.994667           0.997333                1.0   \n",
       "36           0.997333           0.994667                1.0   \n",
       "34           0.997333           0.994667                1.0   \n",
       "37           0.994667           0.994667                1.0   \n",
       "40           0.994667           0.997333                1.0   \n",
       "33           0.997333           0.994667                1.0   \n",
       "41           0.994667           0.997333                1.0   \n",
       "38           0.994667           0.994667                1.0   \n",
       "42           0.992000           1.000000                1.0   \n",
       "\n",
       "    split3_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "35           0.968000  ...            0.957333            1.000000   \n",
       "39           0.970667  ...            0.962667            1.000000   \n",
       "36           0.970667  ...            0.957333            1.000000   \n",
       "34           0.968000  ...            0.960000            1.000000   \n",
       "37           0.973333  ...            0.960000            1.000000   \n",
       "40           0.970667  ...            0.960000            1.000000   \n",
       "33           0.970667  ...            0.960000            1.000000   \n",
       "41           0.968000  ...            0.965333            1.000000   \n",
       "38           0.973333  ...            0.957333            1.000000   \n",
       "42           0.965333  ...            0.965333            0.997333   \n",
       "\n",
       "    split25_test_score  split26_test_score  split27_test_score  \\\n",
       "35            1.000000            1.000000                 1.0   \n",
       "39            0.994667            0.994667                 1.0   \n",
       "36            1.000000            1.000000                 1.0   \n",
       "34            1.000000            1.000000                 1.0   \n",
       "37            0.997333            1.000000                 1.0   \n",
       "40            0.994667            0.994667                 1.0   \n",
       "33            1.000000            1.000000                 1.0   \n",
       "41            0.994667            0.994667                 1.0   \n",
       "38            0.994667            0.997333                 1.0   \n",
       "42            0.992000            0.994667                 1.0   \n",
       "\n",
       "    split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "35            0.945714            0.997222         0.987311        0.017343   \n",
       "39            0.948571            1.000000         0.987230        0.017501   \n",
       "36            0.948571            0.997222         0.987226        0.017768   \n",
       "34            0.942857            0.997222         0.987222        0.017170   \n",
       "37            0.945714            0.997222         0.987131        0.017769   \n",
       "40            0.945714            1.000000         0.986944        0.018012   \n",
       "33            0.940000            0.997222         0.986939        0.016995   \n",
       "41            0.945714            1.000000         0.986938        0.017904   \n",
       "38            0.945714            1.000000         0.986868        0.018191   \n",
       "42            0.945714            1.000000         0.986849        0.017823   \n",
       "\n",
       "    rank_test_score  \n",
       "35                1  \n",
       "39                2  \n",
       "36                3  \n",
       "34                4  \n",
       "37                5  \n",
       "40                6  \n",
       "33                7  \n",
       "41                8  \n",
       "38                9  \n",
       "42               10  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9472361809045227\n",
      "0.9707602339181286\n",
      "Training RMSE:  0.2297037637816964\n",
      "Test RMSE:  0.17099639201419234\n",
      "Training ROC_AUC:  0.9362685641896445\n",
      "Test ROC_AUC:  0.9636243386243386\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(var_smoothing=0.0006579332246575676)\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "y_train_pred=gnb.predict(X_train)\n",
    "y_test_pred=gnb.predict(X_test)\n",
    "print(gnb.score(X_train, y_train))\n",
    "print(gnb.score(X_test, y_test))\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'False Positive Rate')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_test_pred)\n",
    "auc_sc = auc(fpr, tpr)\n",
    "# Draw ROC curve:\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, label=\"AUC = %0.2f\"%auc_sc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Receiver Operating Characteristic(ROC) for Support Vector Machine\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221105527638191\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  0.9067545349181962\n",
      "Test ROC_AUC:  0.9477513227513227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#KNN is more sensititve to noise\n",
    "transformer = RobustScaler().fit(X)\n",
    "X_scaled=transformer.transform(X)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=random)\n",
    "#scaling didn't help*****************************\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_train_pred=knn.predict(X_train_scaled)\n",
    "y_test_pred=knn.predict(X_test_scaled)\n",
    "print(knn.score(X_train_scaled, y_train))\n",
    "print(knn.score(X_test_scaled, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221105527638191\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  0.9067545349181962\n",
      "Test ROC_AUC:  0.9477513227513227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#KNN is more sensititve to noise\n",
    "transformer = MinMaxScaler().fit(X)\n",
    "X_scaled=transformer.transform(X)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=random)\n",
    "#scaling didn't help*****************************\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_train_pred=knn.predict(X_train_scaled)\n",
    "y_test_pred=knn.predict(X_test_scaled)\n",
    "print(knn.score(X_train_scaled, y_train))\n",
    "print(knn.score(X_test_scaled, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=21, p=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9708566137566137"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'n_neighbors': np.arange(1,40),\n",
    "            'p':[1,2]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(knn, param_grid, cv=cv, scoring='roc_auc')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003529</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 21, 'p': 1}</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.970857</td>\n",
       "      <td>0.030315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 20, 'p': 1}</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.970729</td>\n",
       "      <td>0.030571</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 19, 'p': 1}</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.970589</td>\n",
       "      <td>0.030254</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 22, 'p': 1}</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.970053</td>\n",
       "      <td>0.030255</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 24, 'p': 1}</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.969385</td>\n",
       "      <td>0.031476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.004650</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 23, 'p': 1}</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.969299</td>\n",
       "      <td>0.030338</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 25, 'p': 1}</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.968854</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 26, 'p': 1}</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.861429</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.968135</td>\n",
       "      <td>0.032153</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.003603</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 29, 'p': 1}</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.967857</td>\n",
       "      <td>0.032761</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 17, 'p': 1}</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.967585</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "40       0.003529      0.000773         0.004284        0.000747   \n",
       "38       0.003457      0.000875         0.004106        0.000746   \n",
       "36       0.003359      0.000606         0.004541        0.000773   \n",
       "42       0.003675      0.000806         0.004503        0.000994   \n",
       "46       0.003293      0.000448         0.004422        0.000869   \n",
       "44       0.003661      0.000593         0.004650        0.001047   \n",
       "48       0.003582      0.000605         0.004464        0.000921   \n",
       "50       0.004212      0.000962         0.005480        0.000898   \n",
       "56       0.003603      0.000563         0.004882        0.000881   \n",
       "32       0.003911      0.000776         0.004749        0.000863   \n",
       "\n",
       "   param_n_neighbors param_p                       params  split0_test_score  \\\n",
       "40                21       1  {'n_neighbors': 21, 'p': 1}           0.978667   \n",
       "38                20       1  {'n_neighbors': 20, 'p': 1}           0.978667   \n",
       "36                19       1  {'n_neighbors': 19, 'p': 1}           0.978667   \n",
       "42                22       1  {'n_neighbors': 22, 'p': 1}           0.978667   \n",
       "46                24       1  {'n_neighbors': 24, 'p': 1}           0.974667   \n",
       "44                23       1  {'n_neighbors': 23, 'p': 1}           0.974667   \n",
       "48                25       1  {'n_neighbors': 25, 'p': 1}           0.969333   \n",
       "50                26       1  {'n_neighbors': 26, 'p': 1}           0.968000   \n",
       "56                29       1  {'n_neighbors': 29, 'p': 1}           0.970667   \n",
       "32                17       1  {'n_neighbors': 17, 'p': 1}           0.981333   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  split23_test_score  \\\n",
       "40           0.996000           0.992000  ...            0.965333   \n",
       "38           0.993333           0.989333  ...            0.941333   \n",
       "36           0.994667           0.993333  ...            0.941333   \n",
       "42           0.996000           0.992000  ...            0.961333   \n",
       "46           0.997333           0.993333  ...            0.958667   \n",
       "44           0.994667           0.990667  ...            0.960000   \n",
       "48           0.997333           0.992000  ...            0.958667   \n",
       "50           0.998667           0.993333  ...            0.958667   \n",
       "56           1.000000           0.990667  ...            0.952000   \n",
       "32           0.994667           0.993333  ...            0.941333   \n",
       "\n",
       "    split24_test_score  split25_test_score  split26_test_score  \\\n",
       "40            0.977333            0.980000            0.993333   \n",
       "38            0.976000            0.985333            0.997333   \n",
       "36            0.977333            0.986667            0.992000   \n",
       "42            0.974667            0.977333            0.993333   \n",
       "46            0.973333            0.976000            0.993333   \n",
       "44            0.973333            0.977333            0.990667   \n",
       "48            0.973333            0.973333            0.994667   \n",
       "50            0.969333            0.972000            0.994667   \n",
       "56            0.969333            0.970667            0.993333   \n",
       "32            0.981333            0.985333            0.989333   \n",
       "\n",
       "    split27_test_score  split28_test_score  split29_test_score  \\\n",
       "40            0.996000            0.868571            0.972222   \n",
       "38            0.997333            0.868571            0.972222   \n",
       "36            0.997333            0.874286            0.972222   \n",
       "42            0.994667            0.868571            0.972222   \n",
       "46            0.994667            0.862857            0.986111   \n",
       "44            0.994667            0.868571            0.972222   \n",
       "48            0.994667            0.862857            0.986111   \n",
       "50            0.994667            0.861429            0.986111   \n",
       "56            0.994667            0.858571            0.986111   \n",
       "32            0.997333            0.880000            0.972222   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "40         0.970857        0.030315                1  \n",
       "38         0.970729        0.030571                2  \n",
       "36         0.970589        0.030254                3  \n",
       "42         0.970053        0.030255                4  \n",
       "46         0.969385        0.031476                5  \n",
       "44         0.969299        0.030338                6  \n",
       "48         0.968854        0.031651                7  \n",
       "50         0.968135        0.032153                8  \n",
       "56         0.967857        0.032761                9  \n",
       "32         0.967585        0.032415               10  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914572864321608\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  0.895339748254764\n",
      "Test ROC_AUC:  0.9477513227513227\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=21, p=1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_train_pred=knn.predict(X_train_scaled)\n",
    "y_test_pred=knn.predict(X_test_scaled)\n",
    "print(knn.score(X_train_scaled, y_train))\n",
    "print(knn.score(X_test_scaled, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914572864321608\n",
      "0.9649122807017544\n",
      "Training ROC_AUC:  0.895339748254764\n",
      "Test ROC_AUC:  0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=17, p=1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_train_pred=knn.predict(X_train_scaled)\n",
    "y_test_pred=knn.predict(X_test_scaled)\n",
    "print(knn.score(X_train_scaled, y_train))\n",
    "print(knn.score(X_test_scaled, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'False Positive Rate')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_test_pred)\n",
    "auc_sc = auc(fpr, tpr)\n",
    "# Draw ROC curve:\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, label=\"AUC = %0.2f\"%auc_sc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Receiver Operating Characteristic(ROC) for Support Vector Machine\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9195979899497487\n",
      "0.9473684210526315\n",
      "Training ROC_AUC:  0.8980081399423196\n",
      "Test ROC_AUC:  0.9351851851851851\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=50, kernel='poly')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9862777777777778"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'kernel' : ['poly', 'rbf', 'sigmoid'],\n",
    "             'C' : [50, 10, 1.0, 0.1, 0.01],\n",
    "             'gamma' : ['scale']}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.004332</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>50</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 50, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986278</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983478</td>\n",
       "      <td>0.020502</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>50</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.983326</td>\n",
       "      <td>0.019882</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.982346</td>\n",
       "      <td>0.019148</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980999</td>\n",
       "      <td>0.020477</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.980888</td>\n",
       "      <td>0.020688</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980222</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.938667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975154</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.007347</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.917333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970744</td>\n",
       "      <td>0.021926</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.930667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.960805</td>\n",
       "      <td>0.025259</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.006887      0.001516         0.004332        0.001161      50   \n",
       "3        0.007412      0.001116         0.005143        0.000912      10   \n",
       "1        0.005234      0.001084         0.003652        0.000643      50   \n",
       "4        0.006000      0.001075         0.004371        0.000620      10   \n",
       "6        0.004986      0.000964         0.004238        0.000830       1   \n",
       "7        0.005681      0.001020         0.004087        0.000817       1   \n",
       "9        0.005029      0.000911         0.004116        0.000739     0.1   \n",
       "10       0.006926      0.001018         0.004310        0.000685     0.1   \n",
       "13       0.007347      0.001277         0.004500        0.000998    0.01   \n",
       "12       0.005628      0.000841         0.004007        0.000545    0.01   \n",
       "\n",
       "   param_gamma param_kernel                                           params  \\\n",
       "0        scale         poly    {'C': 50, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "3        scale         poly    {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "1        scale          rbf     {'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "4        scale          rbf     {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "6        scale         poly   {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "7        scale          rbf    {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "9        scale         poly   {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "10       scale          rbf    {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "13       scale          rbf   {'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "12       scale         poly  {'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  ...  split23_test_score  \\\n",
       "0            1.000000           0.989333  ...            0.962667   \n",
       "3            1.000000           0.989333  ...            0.960000   \n",
       "1            1.000000           0.989333  ...            0.960000   \n",
       "4            0.994667           0.989333  ...            0.957333   \n",
       "6            0.992000           0.984000  ...            0.957333   \n",
       "7            0.986667           0.976000  ...            0.957333   \n",
       "9            0.989333           0.962667  ...            0.960000   \n",
       "10           0.970667           0.938667  ...            0.952000   \n",
       "13           0.962667           0.917333  ...            0.949333   \n",
       "12           0.957333           0.880000  ...            0.944000   \n",
       "\n",
       "    split24_test_score  split25_test_score  split26_test_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "3             0.997333            1.000000            1.000000   \n",
       "1             1.000000            1.000000            1.000000   \n",
       "4             0.986667            0.997333            1.000000   \n",
       "6             0.984000            0.997333            0.994667   \n",
       "7             0.984000            0.997333            1.000000   \n",
       "9             0.981333            0.997333            0.989333   \n",
       "10            0.978667            0.989333            0.981333   \n",
       "13            0.976000            0.986667            0.960000   \n",
       "12            0.970667            0.984000            0.930667   \n",
       "\n",
       "    split27_test_score  split28_test_score  split29_test_score  \\\n",
       "0             1.000000            0.922857            1.000000   \n",
       "3             1.000000            0.914286            1.000000   \n",
       "1             1.000000            0.928571            0.997222   \n",
       "4             1.000000            0.925714            0.997222   \n",
       "6             1.000000            0.920000            1.000000   \n",
       "7             1.000000            0.914286            0.997222   \n",
       "9             1.000000            0.928571            1.000000   \n",
       "10            1.000000            0.911429            1.000000   \n",
       "13            0.997333            0.914286            1.000000   \n",
       "12            0.989333            0.914286            0.994444   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "0          0.986278        0.018328                1  \n",
       "3          0.983478        0.020502                2  \n",
       "1          0.983326        0.019882                3  \n",
       "4          0.982346        0.019148                4  \n",
       "6          0.980999        0.020477                5  \n",
       "7          0.980888        0.020688                6  \n",
       "9          0.980222        0.019763                7  \n",
       "10         0.975154        0.022669                8  \n",
       "13         0.970744        0.021926                9  \n",
       "12         0.960805        0.025259               10  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957286432160804\n",
      "0.9707602339181286\n",
      "Training ROC_AUC:  0.9510390555510634\n",
      "Test ROC_AUC:  0.966931216931217\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=50, kernel='poly')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447236180904522\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  0.9356082046306029\n",
      "Test ROC_AUC:  0.9543650793650793\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=10, kernel='poly')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7663739411866044\n",
      "0.7428791076062854\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore',sparse=False)\n",
    "trainy_p = enc.fit_transform(y_train.reshape(-1,1))\n",
    "testy_p = enc.transform(y_test.reshape(-1,1))\n",
    "\n",
    "pls=PLSRegression(n_components=8)\n",
    "pls.fit(X_train_full, trainy_p)\n",
    "y_train_pred=pls.predict(X_train_full)\n",
    "#print(y_train_pred)\n",
    "y_test_pred=pls.predict(X_test_full)\n",
    "print(pls.score(X_train_full, trainy_p))\n",
    "print(pls.score(X_test_full, testy_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9649122807017544\n",
      "Training RMSE:  0.0\n",
      "Test RMSE:  0.1873171623163388\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.958994708994709\n"
     ]
    }
   ],
   "source": [
    "# Decision trees\n",
    "from sklearn import tree\n",
    "clf=tree.DecisionTreeClassifier(random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'max_features': 0.6, 'max_leaf_nodes': 50, 'min_samples_leaf': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9670354497354499"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxDepth=clf.tree_.max_depth\n",
    "param_grid = {'max_depth':range(1, maxDepth+1),\n",
    "              'max_features':[0.2,0.4,0.6,0.8], \n",
    "              'max_leaf_nodes':[20,30,40,50],\n",
    "             'min_samples_leaf': [1,2,5,10]}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>0.973611</td>\n",
       "      <td>0.967035</td>\n",
       "      <td>0.024762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.909333</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.941429</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.967008</td>\n",
       "      <td>0.027184</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.966211</td>\n",
       "      <td>0.027668</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.965324</td>\n",
       "      <td>0.030196</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.937143</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.965319</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.894286</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.964898</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.925333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.964890</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.909333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.875714</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.964814</td>\n",
       "      <td>0.031569</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.915714</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.964231</td>\n",
       "      <td>0.028463</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918667</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.934286</td>\n",
       "      <td>0.976389</td>\n",
       "      <td>0.964057</td>\n",
       "      <td>0.030533</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "367       0.003080      0.000584         0.003047        0.000633   \n",
       "307       0.003307      0.000577         0.003037        0.000486   \n",
       "191       0.002494      0.000520         0.002341        0.000468   \n",
       "447       0.003550      0.000693         0.003499        0.000740   \n",
       "239       0.002871      0.000818         0.002840        0.000672   \n",
       "443       0.002932      0.000591         0.002652        0.000626   \n",
       "375       0.003254      0.000508         0.003045        0.000673   \n",
       "363       0.003626      0.001030         0.003708        0.000955   \n",
       "379       0.003034      0.000567         0.002964        0.000699   \n",
       "419       0.003015      0.000688         0.002621        0.000543   \n",
       "\n",
       "    param_max_depth param_max_features param_max_leaf_nodes  \\\n",
       "367               6                0.6                   50   \n",
       "307               5                0.8                   20   \n",
       "191               3                0.8                   50   \n",
       "447               7                0.8                   50   \n",
       "239               4                0.6                   50   \n",
       "443               7                0.8                   40   \n",
       "375               6                0.8                   30   \n",
       "363               6                0.6                   40   \n",
       "379               6                0.8                   40   \n",
       "419               7                0.6                   20   \n",
       "\n",
       "    param_min_samples_leaf                                             params  \\\n",
       "367                     10  {'max_depth': 6, 'max_features': 0.6, 'max_lea...   \n",
       "307                     10  {'max_depth': 5, 'max_features': 0.8, 'max_lea...   \n",
       "191                     10  {'max_depth': 3, 'max_features': 0.8, 'max_lea...   \n",
       "447                     10  {'max_depth': 7, 'max_features': 0.8, 'max_lea...   \n",
       "239                     10  {'max_depth': 4, 'max_features': 0.6, 'max_lea...   \n",
       "443                     10  {'max_depth': 7, 'max_features': 0.8, 'max_lea...   \n",
       "375                     10  {'max_depth': 6, 'max_features': 0.8, 'max_lea...   \n",
       "363                     10  {'max_depth': 6, 'max_features': 0.6, 'max_lea...   \n",
       "379                     10  {'max_depth': 6, 'max_features': 0.8, 'max_lea...   \n",
       "419                     10  {'max_depth': 7, 'max_features': 0.6, 'max_lea...   \n",
       "\n",
       "     split0_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "367           0.957333  ...            0.945333            0.994667   \n",
       "307           0.961333  ...            0.904000            0.994667   \n",
       "191           0.913333  ...            0.941333            1.000000   \n",
       "447           0.994667  ...            0.932000            0.966667   \n",
       "239           0.941333  ...            0.942667            0.980000   \n",
       "443           0.910667  ...            0.906667            0.994667   \n",
       "375           0.910667  ...            0.905333            0.996000   \n",
       "363           0.954667  ...            0.940000            0.994667   \n",
       "379           0.910667  ...            0.902667            0.976000   \n",
       "419           0.978667  ...            0.918667            0.964000   \n",
       "\n",
       "     split25_test_score  split26_test_score  split27_test_score  \\\n",
       "367            0.920000            0.956000            0.996000   \n",
       "307            0.909333            0.981333            0.996000   \n",
       "191            0.984000            0.993333            0.992000   \n",
       "447            0.920000            0.996000            0.988000   \n",
       "239            0.922667            0.993333            0.994667   \n",
       "443            0.989333            1.000000            0.990667   \n",
       "375            0.925333            0.997333            0.990667   \n",
       "363            0.909333            0.980000            0.996000   \n",
       "379            0.920000            0.941333            0.994667   \n",
       "419            0.985333            0.968000            0.994667   \n",
       "\n",
       "     split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "367            0.945714            0.973611         0.967035        0.024762   \n",
       "307            0.941429            0.991667         0.967008        0.027184   \n",
       "191            0.922857            0.997222         0.966211        0.027668   \n",
       "447            0.871429            0.997222         0.965324        0.030196   \n",
       "239            0.937143            0.987500         0.965319        0.025318   \n",
       "443            0.894286            0.997222         0.964898        0.029870   \n",
       "375            0.981429            0.991667         0.964890        0.027711   \n",
       "363            0.875714            0.988889         0.964814        0.031569   \n",
       "379            0.915714            0.997222         0.964231        0.028463   \n",
       "419            0.934286            0.976389         0.964057        0.030533   \n",
       "\n",
       "     rank_test_score  \n",
       "367                1  \n",
       "307                2  \n",
       "191                3  \n",
       "447                4  \n",
       "239                5  \n",
       "443                6  \n",
       "375                7  \n",
       "363                8  \n",
       "379                9  \n",
       "419               10  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9371859296482412\n",
      "0.935672514619883\n",
      "Training ROC_AUC:  0.9214980728282257\n",
      "Test ROC_AUC:  0.925925925925926\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(max_depth= 6, max_features= 0.6, max_leaf_nodes= 50, min_samples_leaf= 10)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9649122807017544\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.958994708994709\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_train_pred=clf_rf.predict(X_train)\n",
    "y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=7, max_features=0.2, n_estimators=200,\n",
      "                       random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9871079365079365"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_depth':np.arange(4, 10),\n",
    "              'max_features':[0.2,0.4,0.6,0.8],\n",
    "              'n_estimators': [10,50,100,200,300,500,1000]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf_rf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.325436</td>\n",
       "      <td>0.031475</td>\n",
       "      <td>0.022424</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.987108</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.517340</td>\n",
       "      <td>0.097194</td>\n",
       "      <td>0.032994</td>\n",
       "      <td>0.007745</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987063</td>\n",
       "      <td>0.019881</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.164920</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987063</td>\n",
       "      <td>0.015817</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.633161</td>\n",
       "      <td>0.117708</td>\n",
       "      <td>0.039335</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986930</td>\n",
       "      <td>0.019405</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.357192</td>\n",
       "      <td>0.059880</td>\n",
       "      <td>0.023687</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986844</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.002752</td>\n",
       "      <td>0.129898</td>\n",
       "      <td>0.058044</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986841</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.307728</td>\n",
       "      <td>0.033625</td>\n",
       "      <td>0.020871</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986838</td>\n",
       "      <td>0.020286</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.156512</td>\n",
       "      <td>0.013385</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986760</td>\n",
       "      <td>0.020148</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.161962</td>\n",
       "      <td>0.017280</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986683</td>\n",
       "      <td>0.016613</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.468708</td>\n",
       "      <td>0.052515</td>\n",
       "      <td>0.029991</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986672</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "87        0.325436      0.031475         0.022424        0.003710   \n",
       "143       0.517340      0.097194         0.032994        0.007745   \n",
       "93        0.164920      0.017420         0.011776        0.001141   \n",
       "144       0.633161      0.117708         0.039335        0.006985   \n",
       "115       0.357192      0.059880         0.023687        0.005692   \n",
       "117       1.002752      0.129898         0.058044        0.011429   \n",
       "59        0.307728      0.033625         0.020871        0.003151   \n",
       "86        0.156512      0.013385         0.011919        0.001138   \n",
       "65        0.161962      0.017280         0.012112        0.001871   \n",
       "60        0.468708      0.052515         0.029991        0.002372   \n",
       "\n",
       "    param_max_depth param_max_features param_n_estimators  \\\n",
       "87                7                0.2                200   \n",
       "143               9                0.2                200   \n",
       "93                7                0.4                100   \n",
       "144               9                0.2                300   \n",
       "115               8                0.2                200   \n",
       "117               8                0.2                500   \n",
       "59                6                0.2                200   \n",
       "86                7                0.2                100   \n",
       "65                6                0.4                100   \n",
       "60                6                0.2                300   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "87   {'max_depth': 7, 'max_features': 0.2, 'n_estim...           0.989333   \n",
       "143  {'max_depth': 9, 'max_features': 0.2, 'n_estim...           0.989333   \n",
       "93   {'max_depth': 7, 'max_features': 0.4, 'n_estim...           0.992000   \n",
       "144  {'max_depth': 9, 'max_features': 0.2, 'n_estim...           0.984000   \n",
       "115  {'max_depth': 8, 'max_features': 0.2, 'n_estim...           0.986667   \n",
       "117  {'max_depth': 8, 'max_features': 0.2, 'n_estim...           0.986667   \n",
       "59   {'max_depth': 6, 'max_features': 0.2, 'n_estim...           0.984000   \n",
       "86   {'max_depth': 7, 'max_features': 0.2, 'n_estim...           0.989333   \n",
       "65   {'max_depth': 6, 'max_features': 0.4, 'n_estim...           0.994667   \n",
       "60   {'max_depth': 6, 'max_features': 0.2, 'n_estim...           0.984000   \n",
       "\n",
       "     split1_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "87                 1.0  ...            0.952000                 1.0   \n",
       "143                1.0  ...            0.949333                 1.0   \n",
       "93                 1.0  ...            0.960000                 1.0   \n",
       "144                1.0  ...            0.949333                 1.0   \n",
       "115                1.0  ...            0.949333                 1.0   \n",
       "117                1.0  ...            0.949333                 1.0   \n",
       "59                 1.0  ...            0.946667                 1.0   \n",
       "86                 1.0  ...            0.949333                 1.0   \n",
       "65                 1.0  ...            0.960000                 1.0   \n",
       "60                 1.0  ...            0.949333                 1.0   \n",
       "\n",
       "     split25_test_score  split26_test_score  split27_test_score  \\\n",
       "87             0.978667                 1.0                 1.0   \n",
       "143            0.986667                 1.0                 1.0   \n",
       "93             0.976000                 1.0                 1.0   \n",
       "144            0.984000                 1.0                 1.0   \n",
       "115            0.978667                 1.0                 1.0   \n",
       "117            0.978667                 1.0                 1.0   \n",
       "59             0.984000                 1.0                 1.0   \n",
       "86             0.976000                 1.0                 1.0   \n",
       "65             0.981333                 1.0                 1.0   \n",
       "60             0.981333                 1.0                 1.0   \n",
       "\n",
       "     split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "87             0.928571            0.997222         0.987108        0.019313   \n",
       "143            0.928571            1.000000         0.987063        0.019881   \n",
       "93             0.945714            1.000000         0.987063        0.015817   \n",
       "144            0.928571            1.000000         0.986930        0.019405   \n",
       "115            0.931429            1.000000         0.986844        0.019544   \n",
       "117            0.928571            1.000000         0.986841        0.019642   \n",
       "59             0.928571            1.000000         0.986838        0.020286   \n",
       "86             0.928571            1.000000         0.986760        0.020148   \n",
       "65             0.942857            1.000000         0.986683        0.016613   \n",
       "60             0.934286            1.000000         0.986672        0.019604   \n",
       "\n",
       "     rank_test_score  \n",
       "87                 1  \n",
       "143                2  \n",
       "93                 3  \n",
       "144                4  \n",
       "115                5  \n",
       "117                6  \n",
       "59                 7  \n",
       "86                 8  \n",
       "65                 9  \n",
       "60                10  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974874371859297\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  0.9966442953020134\n",
      "Test ROC_AUC:  0.9576719576719577\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "clf_rf = RandomForestClassifier(max_depth=7, max_features=0.2, n_estimators=200,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_train_pred=clf_rf.predict(X_train)\n",
    "y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9649122807017544\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.9623015873015873\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "clf_rf = RandomForestClassifier(max_depth=9, max_features=0.2, n_estimators=200,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_train_pred=clf_rf.predict(X_train)\n",
    "y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9396984924623115\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  0.9342874855125199\n",
      "Test ROC_AUC:  0.9576719576719577\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(max_iter=5000, random_state=random)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(loss='squared_hinge', max_iter=5000, penalty='l1',\n",
      "              random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9832333333333333"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'loss' : ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "              'penalty' : ['l2', 'l1', 'elasticnet'],\n",
    "              'random_state':[random]\n",
    "              }\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'squared_hinge', 'penalty': 'l1', 'ra...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.934286</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.983233</td>\n",
       "      <td>0.017198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'hinge', 'penalty': 'l1', 'random_sta...</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981743</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>log</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'log', 'penalty': 'elasticnet', 'rand...</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980950</td>\n",
       "      <td>0.022535</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004313</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'perceptron', 'penalty': 'l1', 'rando...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.980465</td>\n",
       "      <td>0.023868</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>log</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'log', 'penalty': 'l1', 'random_state...</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.979566</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'modified_huber', 'penalty': 'l1', 'r...</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.978121</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'modified_huber', 'penalty': 'elastic...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.969444</td>\n",
       "      <td>0.977824</td>\n",
       "      <td>0.021467</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'perceptron', 'penalty': 'elasticnet'...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.976526</td>\n",
       "      <td>0.029269</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>log</td>\n",
       "      <td>l2</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'log', 'penalty': 'l2', 'random_state...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.976079</td>\n",
       "      <td>0.022337</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>42</td>\n",
       "      <td>{'loss': 'squared_hinge', 'penalty': 'elasticn...</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.975529</td>\n",
       "      <td>0.027583</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "10       0.004542      0.000710         0.002679        0.000641   \n",
       "1        0.003629      0.000516         0.002350        0.000442   \n",
       "5        0.005550      0.001147         0.002695        0.000603   \n",
       "13       0.004313      0.000984         0.002847        0.000624   \n",
       "4        0.005067      0.000814         0.002850        0.001024   \n",
       "7        0.003897      0.000693         0.002684        0.000572   \n",
       "8        0.004445      0.001001         0.002575        0.000724   \n",
       "14       0.004538      0.000887         0.002754        0.000677   \n",
       "3        0.004673      0.000906         0.002680        0.000615   \n",
       "11       0.004036      0.000579         0.002832        0.000692   \n",
       "\n",
       "        param_loss param_penalty param_random_state  \\\n",
       "10   squared_hinge            l1                 42   \n",
       "1            hinge            l1                 42   \n",
       "5              log    elasticnet                 42   \n",
       "13      perceptron            l1                 42   \n",
       "4              log            l1                 42   \n",
       "7   modified_huber            l1                 42   \n",
       "8   modified_huber    elasticnet                 42   \n",
       "14      perceptron    elasticnet                 42   \n",
       "3              log            l2                 42   \n",
       "11   squared_hinge    elasticnet                 42   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "10  {'loss': 'squared_hinge', 'penalty': 'l1', 'ra...           0.989333   \n",
       "1   {'loss': 'hinge', 'penalty': 'l1', 'random_sta...           0.997333   \n",
       "5   {'loss': 'log', 'penalty': 'elasticnet', 'rand...           0.986667   \n",
       "13  {'loss': 'perceptron', 'penalty': 'l1', 'rando...           0.989333   \n",
       "4   {'loss': 'log', 'penalty': 'l1', 'random_state...           0.997333   \n",
       "7   {'loss': 'modified_huber', 'penalty': 'l1', 'r...           0.997333   \n",
       "8   {'loss': 'modified_huber', 'penalty': 'elastic...           1.000000   \n",
       "14  {'loss': 'perceptron', 'penalty': 'elasticnet'...           0.992000   \n",
       "3   {'loss': 'log', 'penalty': 'l2', 'random_state...           0.992000   \n",
       "11  {'loss': 'squared_hinge', 'penalty': 'elasticn...           0.994667   \n",
       "\n",
       "    split1_test_score  ...  split23_test_score  split24_test_score  \\\n",
       "10           0.994667  ...            0.965333            1.000000   \n",
       "1            0.994667  ...            0.962667            0.997333   \n",
       "5            1.000000  ...            0.960000            0.997333   \n",
       "13           1.000000  ...            0.960000            1.000000   \n",
       "4            1.000000  ...            0.965333            1.000000   \n",
       "7            0.994667  ...            0.962667            1.000000   \n",
       "8            0.997333  ...            0.962667            0.981333   \n",
       "14           1.000000  ...            0.962667            0.994667   \n",
       "3            0.976000  ...            0.962667            0.997333   \n",
       "11           0.992000  ...            0.965333            0.992000   \n",
       "\n",
       "    split25_test_score  split26_test_score  split27_test_score  \\\n",
       "10            0.997333            1.000000            0.994667   \n",
       "1             0.986667            1.000000            1.000000   \n",
       "5             1.000000            0.994667            0.994667   \n",
       "13            0.976000            0.978667            1.000000   \n",
       "4             0.994667            0.941333            0.997333   \n",
       "7             0.994667            1.000000            1.000000   \n",
       "8             0.992000            0.986667            0.997333   \n",
       "14            1.000000            1.000000            1.000000   \n",
       "3             1.000000            1.000000            0.997333   \n",
       "11            0.984000            0.994667            1.000000   \n",
       "\n",
       "    split28_test_score  split29_test_score  mean_test_score  std_test_score  \\\n",
       "10            0.934286            0.994444         0.983233        0.017198   \n",
       "1             0.914286            1.000000         0.981743        0.021233   \n",
       "5             0.920000            1.000000         0.980950        0.022535   \n",
       "13            0.885714            0.997222         0.980465        0.023868   \n",
       "4             0.914286            0.994444         0.979566        0.023431   \n",
       "7             0.880000            0.988889         0.978121        0.028400   \n",
       "8             0.914286            0.969444         0.977824        0.021467   \n",
       "14            0.862857            0.997222         0.976526        0.029269   \n",
       "3             0.920000            0.988889         0.976079        0.022337   \n",
       "11            0.862857            0.994444         0.975529        0.027583   \n",
       "\n",
       "    rank_test_score  \n",
       "10                1  \n",
       "1                 2  \n",
       "5                 3  \n",
       "13                4  \n",
       "4                 5  \n",
       "7                 6  \n",
       "8                 7  \n",
       "14                8  \n",
       "3                 9  \n",
       "11               10  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.457286432160804\n",
      "0.4502923976608187\n",
      "Training ROC_AUC:  0.5662650602409638\n",
      "Test ROC_AUC:  0.5648148148148149\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='squared_hinge', penalty='l1', random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7085427135678392\n",
      "0.7485380116959064\n",
      "Training ROC_AUC:  0.7657206005228969\n",
      "Test ROC_AUC:  0.8009259259259259\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log', max_iter=100, penalty='elasticnet', random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9532163742690059\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.953042328042328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(learning_rate=0.01, n_estimators=1000, subsample=0.5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9863714285714287"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators' : [10, 100, 1000],\n",
    "              'learning_rate' : [0.001, 0.01, 0.1],\n",
    "              'subsample' : [0.5, 0.7, 1.0],\n",
    "              'max_depth' : [3, 7, 9]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search= GridSearchCV(clf, param_grid, cv=cv , scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.963024</td>\n",
       "      <td>0.087401</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986371</td>\n",
       "      <td>0.020993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.979547</td>\n",
       "      <td>0.083060</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.986298</td>\n",
       "      <td>0.021119</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.096372</td>\n",
       "      <td>0.070979</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986117</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.090707</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985965</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.039237</td>\n",
       "      <td>0.079257</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937143</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.985591</td>\n",
       "      <td>0.019066</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.116666</td>\n",
       "      <td>0.016974</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985174</td>\n",
       "      <td>0.021623</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.212883</td>\n",
       "      <td>0.030067</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985140</td>\n",
       "      <td>0.022165</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.288822</td>\n",
       "      <td>0.036853</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 9, 'n_esti...</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984947</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.151479</td>\n",
       "      <td>0.146531</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984856</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.243688</td>\n",
       "      <td>0.034215</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 7, 'n_es...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984696</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "33       0.963024      0.087401         0.004077        0.000558   \n",
       "60       0.979547      0.083060         0.004354        0.001030   \n",
       "34       1.096372      0.070979         0.004297        0.000854   \n",
       "57       0.090707      0.011881         0.002939        0.000651   \n",
       "61       1.039237      0.079257         0.004148        0.000706   \n",
       "58       0.116666      0.016974         0.003629        0.000886   \n",
       "66       0.212883      0.030067         0.003318        0.000869   \n",
       "75       0.288822      0.036853         0.003276        0.000627   \n",
       "42       2.151479      0.146531         0.005697        0.000698   \n",
       "12       0.243688      0.034215         0.003620        0.000950   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_subsample  \\\n",
       "33                0.01               3               1000             0.5   \n",
       "60                 0.1               3               1000             0.5   \n",
       "34                0.01               3               1000             0.7   \n",
       "57                 0.1               3                100             0.5   \n",
       "61                 0.1               3               1000             0.7   \n",
       "58                 0.1               3                100             0.7   \n",
       "66                 0.1               7                100             0.5   \n",
       "75                 0.1               9                100             0.5   \n",
       "42                0.01               7               1000             0.5   \n",
       "12               0.001               7                100             0.5   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "33  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.992000  ...   \n",
       "60  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.989333  ...   \n",
       "34  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.992000  ...   \n",
       "57  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.992000  ...   \n",
       "61  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.992000  ...   \n",
       "58  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.992000  ...   \n",
       "66  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.989333  ...   \n",
       "75  {'learning_rate': 0.1, 'max_depth': 9, 'n_esti...           0.989333  ...   \n",
       "42  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...           0.992000  ...   \n",
       "12  {'learning_rate': 0.001, 'max_depth': 7, 'n_es...           0.976000  ...   \n",
       "\n",
       "    split23_test_score  split24_test_score  split25_test_score  \\\n",
       "33            0.962667                 1.0            0.989333   \n",
       "60            0.957333                 1.0            0.992000   \n",
       "34            0.962667                 1.0            0.989333   \n",
       "57            0.960000                 1.0            0.994667   \n",
       "61            0.954667                 1.0            0.989333   \n",
       "58            0.965333                 1.0            0.986667   \n",
       "66            0.954667                 1.0            0.981333   \n",
       "75            0.952000                 1.0            0.970667   \n",
       "42            0.952000                 1.0            0.989333   \n",
       "12            0.960000                 1.0            0.981333   \n",
       "\n",
       "    split26_test_score  split27_test_score  split28_test_score  \\\n",
       "33            1.000000            0.997333            0.922857   \n",
       "60            1.000000            1.000000            0.925714   \n",
       "34            1.000000            0.997333            0.925714   \n",
       "57            1.000000            0.997333            0.917143   \n",
       "61            1.000000            1.000000            0.937143   \n",
       "58            1.000000            0.997333            0.922857   \n",
       "66            1.000000            1.000000            0.917143   \n",
       "75            1.000000            0.997333            0.940000   \n",
       "42            1.000000            0.997333            0.925714   \n",
       "12            0.994667            1.000000            0.954286   \n",
       "\n",
       "    split29_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "33            1.000000         0.986371        0.020993                1  \n",
       "60            0.997222         0.986298        0.021119                2  \n",
       "34            1.000000         0.986117        0.020945                3  \n",
       "57            1.000000         0.985965        0.022092                4  \n",
       "61            0.991667         0.985591        0.019066                5  \n",
       "58            1.000000         0.985174        0.021623                6  \n",
       "66            1.000000         0.985140        0.022165                7  \n",
       "75            1.000000         0.984947        0.019590                8  \n",
       "42            1.000000         0.984856        0.022232                9  \n",
       "12            1.000000         0.984696        0.017297               10  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9590643274853801\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.9543650793650793\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.01, subsample=0.5, max_depth=3)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9649122807017544\n",
      "Training ROC_AUC:  1.0\n",
      "Test ROC_AUC:  0.958994708994709\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, subsample=0.5, max_depth=7)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training ROC_AUC: \", roc_auc_score(y_train, y_train_pred))\n",
    "print(\"Test ROC_AUC: \", roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
